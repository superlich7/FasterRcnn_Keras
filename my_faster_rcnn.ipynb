{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/superlee/anaconda3/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "import pprint\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import pickle\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras_frcnn import config, data_generators\n",
    "from keras_frcnn import losses as losses\n",
    "import keras_frcnn.roi_helpers as roi_helpers\n",
    "from keras.utils import generic_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Option at 0x7f8c72e2f4a8: --input_weight_path>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.setrecursionlimit(40000)\n",
    "\n",
    "parser = OptionParser()\n",
    "\n",
    "parser.add_option(\"-p\", \"--path\", dest=\"train_path\", help=\"Path to training data.\")\n",
    "parser.add_option(\"-o\", \"--parser\", dest=\"parser\", help=\"Parser to use. One of simple or pascal_voc\",\n",
    "\t\t\t\tdefault=\"pascal_voc\")\n",
    "parser.add_option(\"-n\", \"--num_rois\", type=\"int\", dest=\"num_rois\", help=\"Number of RoIs to process at once.\", default=32)\n",
    "parser.add_option(\"--network\", dest=\"network\", help=\"Base network to use. Supports vgg or resnet50.\", default='resnet50')\n",
    "parser.add_option(\"--hf\", dest=\"horizontal_flips\", help=\"Augment with horizontal flips in training. (Default=false).\", action=\"store_true\", default=False)\n",
    "parser.add_option(\"--vf\", dest=\"vertical_flips\", help=\"Augment with vertical flips in training. (Default=false).\", action=\"store_true\", default=False)\n",
    "parser.add_option(\"--rot\", \"--rot_90\", dest=\"rot_90\", help=\"Augment with 90 degree rotations in training. (Default=false).\",\n",
    "\t\t\t\t  action=\"store_true\", default=False)\n",
    "parser.add_option(\"--num_epochs\", type=\"int\", dest=\"num_epochs\", help=\"Number of epochs.\", default=2000)\n",
    "parser.add_option(\"--config_filename\", dest=\"config_filename\", help=\n",
    "\t\t\t\t\"Location to store all the metadata related to the training (to be used when testing).\",\n",
    "\t\t\t\tdefault=\"config.pickle\")\n",
    "parser.add_option(\"--output_weight_path\", dest=\"output_weight_path\", help=\"Output path for weights.\", default='./model_frcnn.hdf5')\n",
    "parser.add_option(\"--input_weight_path\", dest=\"input_weight_path\", help=\"Input path for weights. If not specified, will try to load default weights provided by keras.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_frcnn.pascal_voc_parser import get_data\n",
    "from keras_frcnn import vgg as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = config.Config()\n",
    "\n",
    "C.use_horizontal_flips = False\n",
    "C.use_vertical_flips = False\n",
    "C.rot_90 = False\n",
    "\n",
    "C.num_rois = 32\n",
    "C.network = 'vgg'\n",
    "C.base_net_weights = './input/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "C.model_path = \"./output/model_frcnn.hdf5\"\n",
    "train_path = \"./input/dataset/VOCdevkit2007\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing annotation files\n",
      "syntax error: line 1, column 0\n"
     ]
    }
   ],
   "source": [
    "all_imgs, classes_count, class_mapping = get_data(train_path)  #function get_data muse be above, otherwise comes a FILE_NOT_FOUND error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'bg' not in classes_count:\n",
    "\tclasses_count['bg'] = 0\n",
    "\tclass_mapping['bg'] = len(class_mapping)\n",
    "\n",
    "C.class_mapping = class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images per class:\n",
      "{'aeroplane': 331,\n",
      " 'bg': 0,\n",
      " 'bicycle': 418,\n",
      " 'bird': 599,\n",
      " 'boat': 398,\n",
      " 'bottle': 634,\n",
      " 'bus': 272,\n",
      " 'car': 1644,\n",
      " 'cat': 389,\n",
      " 'chair': 1432,\n",
      " 'cow': 356,\n",
      " 'diningtable': 310,\n",
      " 'dog': 538,\n",
      " 'horse': 406,\n",
      " 'motorbike': 390,\n",
      " 'person': 5447,\n",
      " 'pottedplant': 625,\n",
      " 'sheep': 353,\n",
      " 'sofa': 425,\n",
      " 'train': 328,\n",
      " 'tvmonitor': 367}\n",
      "Num classes (including bg) = 21\n"
     ]
    }
   ],
   "source": [
    "inv_map = {v: k for k, v in class_mapping.items()}\n",
    "\n",
    "print('Training images per class:')\n",
    "pprint.pprint(classes_count)\n",
    "print('Num classes (including bg) = {}'.format(len(classes_count)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config has been written to ./output/config.pickle, and can be loaded when testing to ensure correct results\n"
     ]
    }
   ],
   "source": [
    "config_output_filename = \"./output/config.pickle\"\n",
    "\n",
    "with open(config_output_filename, 'wb') as config_f:\n",
    "\tpickle.dump(C,config_f)\n",
    "\tprint('Config has been written to {}, and can be loaded when testing to ensure correct results'.format(config_output_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train samples 5011\n",
      "Num val samples 0\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(all_imgs)\n",
    "\n",
    "num_imgs = len(all_imgs)\n",
    "\n",
    "train_imgs = [s for s in all_imgs if s['imageset'] == 'trainval']\n",
    "val_imgs = [s for s in all_imgs if s['imageset'] == 'test']\n",
    "\n",
    "print('Num train samples {}'.format(len(train_imgs)))\n",
    "print('Num val samples {}'.format(len(val_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 87,\n",
       "    'x2': 391,\n",
       "    'y1': 38,\n",
       "    'y2': 335},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 221,\n",
       "    'x2': 317,\n",
       "    'y1': 40,\n",
       "    'y2': 180}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004589.jpg',\n",
       "  'height': 364,\n",
       "  'imageset': 'test',\n",
       "  'width': 480},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 5,\n",
       "    'x2': 481,\n",
       "    'y1': 95,\n",
       "    'y2': 250},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 4,\n",
       "    'x2': 166,\n",
       "    'y1': 197,\n",
       "    'y2': 245}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007993.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 220,\n",
       "    'x2': 496,\n",
       "    'y1': 103,\n",
       "    'y2': 333},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 18,\n",
       "    'x2': 491,\n",
       "    'y1': 74,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 123,\n",
       "    'y1': 100,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008964.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 172,\n",
       "    'x2': 394,\n",
       "    'y1': 174,\n",
       "    'y2': 269},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 393,\n",
       "    'x2': 429,\n",
       "    'y1': 153,\n",
       "    'y2': 267}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009593.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 100,\n",
       "    'x2': 166,\n",
       "    'y1': 50,\n",
       "    'y2': 114},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 320,\n",
       "    'x2': 363,\n",
       "    'y1': 65,\n",
       "    'y2': 121},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 348,\n",
       "    'x2': 426,\n",
       "    'y1': 9,\n",
       "    'y2': 138},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 217,\n",
       "    'x2': 267,\n",
       "    'y1': 151,\n",
       "    'y2': 220},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 82,\n",
       "    'x2': 129,\n",
       "    'y1': 199,\n",
       "    'y2': 259},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 20,\n",
       "    'x2': 118,\n",
       "    'y1': 280,\n",
       "    'y2': 322},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 58,\n",
       "    'x2': 132,\n",
       "    'y1': 329,\n",
       "    'y2': 385},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 182,\n",
       "    'x2': 222,\n",
       "    'y1': 243,\n",
       "    'y2': 325},\n",
       "   {'class': 'bird',\n",
       "    'difficult': True,\n",
       "    'x1': 351,\n",
       "    'x2': 369,\n",
       "    'y1': 295,\n",
       "    'y2': 317},\n",
       "   {'class': 'bird',\n",
       "    'difficult': True,\n",
       "    'x1': 235,\n",
       "    'x2': 332,\n",
       "    'y1': 315,\n",
       "    'y2': 353},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 398,\n",
       "    'x2': 476,\n",
       "    'y1': 222,\n",
       "    'y2': 297}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002996.jpg',\n",
       "  'height': 403,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 119,\n",
       "    'x2': 500,\n",
       "    'y1': 44,\n",
       "    'y2': 308}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003843.jpg',\n",
       "  'height': 335,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 143,\n",
       "    'x2': 433,\n",
       "    'y1': 18,\n",
       "    'y2': 330}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008460.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 206,\n",
       "    'x2': 483,\n",
       "    'y1': 135,\n",
       "    'y2': 237}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001016.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 75,\n",
       "    'y1': 155,\n",
       "    'y2': 196},\n",
       "   {'class': 'bus',\n",
       "    'difficult': True,\n",
       "    'x1': 434,\n",
       "    'x2': 475,\n",
       "    'y1': 161,\n",
       "    'y2': 192},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 259,\n",
       "    'x2': 363,\n",
       "    'y1': 307,\n",
       "    'y2': 335},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 40,\n",
       "    'x2': 79,\n",
       "    'y1': 179,\n",
       "    'y2': 198}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005663.jpg',\n",
       "  'height': 335,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 22,\n",
       "    'x2': 318,\n",
       "    'y1': 24,\n",
       "    'y2': 365}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007891.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 43,\n",
       "    'x2': 221,\n",
       "    'y1': 54,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 185,\n",
       "    'x2': 433,\n",
       "    'y1': 100,\n",
       "    'y2': 353},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 95,\n",
       "    'y1': 194,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 404,\n",
       "    'x2': 469,\n",
       "    'y1': 207,\n",
       "    'y2': 322},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 426,\n",
       "    'x2': 500,\n",
       "    'y1': 243,\n",
       "    'y2': 364},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 91,\n",
       "    'x2': 500,\n",
       "    'y1': 326,\n",
       "    'y2': 375},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 327,\n",
       "    'x2': 367,\n",
       "    'y1': 284,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 446,\n",
       "    'x2': 500,\n",
       "    'y1': 36,\n",
       "    'y2': 206}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002705.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 193,\n",
       "    'x2': 238,\n",
       "    'y1': 107,\n",
       "    'y2': 164},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 29,\n",
       "    'x2': 45,\n",
       "    'y1': 126,\n",
       "    'y2': 171},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 309,\n",
       "    'x2': 327,\n",
       "    'y1': 84,\n",
       "    'y2': 143},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 125,\n",
       "    'x2': 196,\n",
       "    'y1': 210,\n",
       "    'y2': 290},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 183,\n",
       "    'x2': 245,\n",
       "    'y1': 131,\n",
       "    'y2': 174},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 124,\n",
       "    'x2': 193,\n",
       "    'y1': 238,\n",
       "    'y2': 323}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004417.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 330},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 56,\n",
       "    'x2': 309,\n",
       "    'y1': 206,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 82,\n",
       "    'x2': 284,\n",
       "    'y1': 76,\n",
       "    'y2': 289}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005724.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 179,\n",
       "    'x2': 354,\n",
       "    'y1': 96,\n",
       "    'y2': 216}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008193.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 109,\n",
       "    'x2': 168,\n",
       "    'y1': 75,\n",
       "    'y2': 264},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 294,\n",
       "    'x2': 479,\n",
       "    'y1': 128,\n",
       "    'y2': 272},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 3,\n",
       "    'x2': 497,\n",
       "    'y1': 239,\n",
       "    'y2': 474}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006086.jpg',\n",
       "  'height': 476,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 183,\n",
       "    'x2': 288,\n",
       "    'y1': 123,\n",
       "    'y2': 232},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 117,\n",
       "    'x2': 300,\n",
       "    'y1': 291,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001687.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 8,\n",
       "    'x2': 433,\n",
       "    'y1': 80,\n",
       "    'y2': 279}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002890.jpg',\n",
       "  'height': 359,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 97,\n",
       "    'x2': 294,\n",
       "    'y1': 113,\n",
       "    'y2': 480},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 119,\n",
       "    'x2': 252,\n",
       "    'y1': 85,\n",
       "    'y2': 307}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007750.jpg',\n",
       "  'height': 480,\n",
       "  'imageset': 'test',\n",
       "  'width': 391},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': True,\n",
       "    'x1': 294,\n",
       "    'x2': 341,\n",
       "    'y1': 149,\n",
       "    'y2': 186},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 118,\n",
       "    'x2': 351,\n",
       "    'y1': 189,\n",
       "    'y2': 291},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 354,\n",
       "    'x2': 500,\n",
       "    'y1': 199,\n",
       "    'y2': 285},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 412,\n",
       "    'x2': 457,\n",
       "    'y1': 162,\n",
       "    'y2': 197},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 135,\n",
       "    'x2': 166,\n",
       "    'y1': 175,\n",
       "    'y2': 193},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 40,\n",
       "    'y1': 167,\n",
       "    'y2': 241},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': True,\n",
       "    'x1': 170,\n",
       "    'x2': 197,\n",
       "    'y1': 109,\n",
       "    'y2': 193},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 196,\n",
       "    'x2': 222,\n",
       "    'y1': 169,\n",
       "    'y2': 195}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001811.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 157,\n",
       "    'x2': 327,\n",
       "    'y1': 45,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 302,\n",
       "    'x2': 376,\n",
       "    'y1': 151,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 12,\n",
       "    'x2': 185,\n",
       "    'y1': 199,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004435.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 150,\n",
       "    'x2': 438,\n",
       "    'y1': 18,\n",
       "    'y2': 330},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 176,\n",
       "    'y1': 82,\n",
       "    'y2': 367}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003132.jpg',\n",
       "  'height': 367,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 74,\n",
       "    'x2': 144,\n",
       "    'y1': 203,\n",
       "    'y2': 314},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 74,\n",
       "    'x2': 140,\n",
       "    'y1': 142,\n",
       "    'y2': 272}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002008.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 109,\n",
       "    'x2': 281,\n",
       "    'y1': 142,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 254,\n",
       "    'x2': 360,\n",
       "    'y1': 150,\n",
       "    'y2': 256},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 217,\n",
       "    'x2': 500,\n",
       "    'y1': 245,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002624.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 161,\n",
       "    'x2': 387,\n",
       "    'y1': 92,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007420.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 119,\n",
       "    'x2': 439,\n",
       "    'y1': 45,\n",
       "    'y2': 349}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006969.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 68,\n",
       "    'x2': 270,\n",
       "    'y1': 1,\n",
       "    'y2': 323},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 227,\n",
       "    'x2': 366,\n",
       "    'y1': 64,\n",
       "    'y2': 294},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 341,\n",
       "    'x2': 454,\n",
       "    'y1': 1,\n",
       "    'y2': 321},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 465,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 319},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 30,\n",
       "    'x2': 89,\n",
       "    'y1': 112,\n",
       "    'y2': 216},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 431,\n",
       "    'x2': 486,\n",
       "    'y1': 127,\n",
       "    'y2': 212}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007759.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 189,\n",
       "    'x2': 308,\n",
       "    'y1': 157,\n",
       "    'y2': 265},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 104,\n",
       "    'x2': 313,\n",
       "    'y1': 90,\n",
       "    'y2': 273}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000248.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 73,\n",
       "    'x2': 500,\n",
       "    'y1': 213,\n",
       "    'y2': 375},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 64,\n",
       "    'y1': 158,\n",
       "    'y2': 228},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 457,\n",
       "    'x2': 500,\n",
       "    'y1': 232,\n",
       "    'y2': 315},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 58,\n",
       "    'x2': 199,\n",
       "    'y1': 312,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 199,\n",
       "    'x2': 304,\n",
       "    'y1': 310,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 37,\n",
       "    'x2': 107,\n",
       "    'y1': 270,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 46,\n",
       "    'x2': 189,\n",
       "    'y1': 234,\n",
       "    'y2': 362},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 81,\n",
       "    'y1': 227,\n",
       "    'y2': 370},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 75,\n",
       "    'x2': 116,\n",
       "    'y1': 193,\n",
       "    'y2': 269},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 78,\n",
       "    'x2': 89,\n",
       "    'y1': 163,\n",
       "    'y2': 192},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 60,\n",
       "    'x2': 72,\n",
       "    'y1': 161,\n",
       "    'y2': 171},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 46,\n",
       "    'x2': 59,\n",
       "    'y1': 158,\n",
       "    'y2': 164},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 29,\n",
       "    'x2': 45,\n",
       "    'y1': 155,\n",
       "    'y2': 165},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 4,\n",
       "    'x2': 29,\n",
       "    'y1': 202,\n",
       "    'y2': 231},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 17,\n",
       "    'y1': 196,\n",
       "    'y2': 203},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 357,\n",
       "    'x2': 429,\n",
       "    'y1': 162,\n",
       "    'y2': 288},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 298,\n",
       "    'x2': 364,\n",
       "    'y1': 150,\n",
       "    'y2': 260},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 256,\n",
       "    'x2': 315,\n",
       "    'y1': 158,\n",
       "    'y2': 248},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 211,\n",
       "    'x2': 262,\n",
       "    'y1': 149,\n",
       "    'y2': 236},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 100,\n",
       "    'x2': 188,\n",
       "    'y1': 153,\n",
       "    'y2': 223},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 26,\n",
       "    'x2': 86,\n",
       "    'y1': 174,\n",
       "    'y2': 297},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 290,\n",
       "    'x2': 323,\n",
       "    'y1': 98,\n",
       "    'y2': 161}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008245.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 305,\n",
       "    'x2': 431,\n",
       "    'y1': 36,\n",
       "    'y2': 332},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 192,\n",
       "    'x2': 298,\n",
       "    'y1': 182,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 84,\n",
       "    'x2': 206,\n",
       "    'y1': 206,\n",
       "    'y2': 333},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 143,\n",
       "    'y1': 69,\n",
       "    'y2': 181}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007126.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 252,\n",
       "    'x2': 410,\n",
       "    'y1': 51,\n",
       "    'y2': 195},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 263,\n",
       "    'x2': 500,\n",
       "    'y1': 221,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 46,\n",
       "    'y1': 184,\n",
       "    'y2': 257}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006630.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 13,\n",
       "    'x2': 65,\n",
       "    'y1': 20,\n",
       "    'y2': 192},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 140,\n",
       "    'x2': 175,\n",
       "    'y1': 33,\n",
       "    'y2': 133},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 171,\n",
       "    'x2': 200,\n",
       "    'y1': 40,\n",
       "    'y2': 116},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 479,\n",
       "    'x2': 500,\n",
       "    'y1': 49,\n",
       "    'y2': 76},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 456,\n",
       "    'y1': 2,\n",
       "    'y2': 318},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 68,\n",
       "    'x2': 122,\n",
       "    'y1': 62,\n",
       "    'y2': 99}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000293.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 499,\n",
       "    'y1': 13,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003480.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 144,\n",
       "    'x2': 237,\n",
       "    'y1': 5,\n",
       "    'y2': 131},\n",
       "   {'class': 'cow',\n",
       "    'difficult': True,\n",
       "    'x1': 12,\n",
       "    'x2': 149,\n",
       "    'y1': 37,\n",
       "    'y2': 127}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006579.jpg',\n",
       "  'height': 352,\n",
       "  'imageset': 'test',\n",
       "  'width': 288},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 33,\n",
       "    'x2': 458,\n",
       "    'y1': 212,\n",
       "    'y2': 370},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': True,\n",
       "    'x1': 226,\n",
       "    'x2': 500,\n",
       "    'y1': 243,\n",
       "    'y2': 339},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 62,\n",
       "    'x2': 90,\n",
       "    'y1': 335,\n",
       "    'y2': 346},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 26,\n",
       "    'x2': 49,\n",
       "    'y1': 335,\n",
       "    'y2': 347}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007806.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 166,\n",
       "    'y1': 165,\n",
       "    'y2': 250},\n",
       "   {'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 193,\n",
       "    'x2': 331,\n",
       "    'y1': 165,\n",
       "    'y2': 234},\n",
       "   {'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 361,\n",
       "    'x2': 500,\n",
       "    'y1': 181,\n",
       "    'y2': 238}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005646.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 147,\n",
       "    'x2': 235,\n",
       "    'y1': 83,\n",
       "    'y2': 124},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 194,\n",
       "    'x2': 479,\n",
       "    'y1': 256,\n",
       "    'y2': 353},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 57,\n",
       "    'x2': 167,\n",
       "    'y1': 290,\n",
       "    'y2': 343}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006758.jpg',\n",
       "  'height': 374,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 21,\n",
       "    'x2': 37,\n",
       "    'y1': 408,\n",
       "    'y2': 445},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 22,\n",
       "    'y1': 401,\n",
       "    'y2': 450}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009714.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 287},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 259,\n",
       "    'y1': 151,\n",
       "    'y2': 375},\n",
       "   {'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 500,\n",
       "    'y1': 197,\n",
       "    'y2': 375},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 303,\n",
       "    'x2': 361,\n",
       "    'y1': 156,\n",
       "    'y2': 208}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009102.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 44,\n",
       "    'x2': 433,\n",
       "    'y1': 114,\n",
       "    'y2': 284},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 4,\n",
       "    'x2': 500,\n",
       "    'y1': 3,\n",
       "    'y2': 374},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 103,\n",
       "    'x2': 260,\n",
       "    'y1': 1,\n",
       "    'y2': 91}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006774.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 171,\n",
       "    'x2': 425,\n",
       "    'y1': 129,\n",
       "    'y2': 266},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 207,\n",
       "    'x2': 291,\n",
       "    'y1': 98,\n",
       "    'y2': 272}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001624.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 302,\n",
       "    'x2': 360,\n",
       "    'y1': 85,\n",
       "    'y2': 159},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 106,\n",
       "    'x2': 287,\n",
       "    'y1': 96,\n",
       "    'y2': 368},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 308,\n",
       "    'x2': 484,\n",
       "    'y1': 249,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008991.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 147,\n",
       "    'x2': 283,\n",
       "    'y1': 176,\n",
       "    'y2': 375},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 403,\n",
       "    'x2': 461,\n",
       "    'y1': 153,\n",
       "    'y2': 230}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001081.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 9,\n",
       "    'x2': 291,\n",
       "    'y1': 83,\n",
       "    'y2': 279}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006191.jpg',\n",
       "  'height': 357,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 426,\n",
       "    'x2': 458,\n",
       "    'y1': 273,\n",
       "    'y2': 296},\n",
       "   {'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 382,\n",
       "    'x2': 418,\n",
       "    'y1': 271,\n",
       "    'y2': 300},\n",
       "   {'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 348,\n",
       "    'x2': 384,\n",
       "    'y1': 244,\n",
       "    'y2': 296},\n",
       "   {'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 286,\n",
       "    'x2': 337,\n",
       "    'y1': 252,\n",
       "    'y2': 304},\n",
       "   {'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 245,\n",
       "    'x2': 286,\n",
       "    'y1': 248,\n",
       "    'y2': 299},\n",
       "   {'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 204,\n",
       "    'x2': 256,\n",
       "    'y1': 252,\n",
       "    'y2': 308},\n",
       "   {'class': 'cow',\n",
       "    'difficult': True,\n",
       "    'x1': 215,\n",
       "    'x2': 238,\n",
       "    'y1': 282,\n",
       "    'y2': 309}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002676.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 29,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 356}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000357.jpg',\n",
       "  'height': 357,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 185,\n",
       "    'x2': 500,\n",
       "    'y1': 152,\n",
       "    'y2': 264}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007107.jpg',\n",
       "  'height': 360,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 240,\n",
       "    'x2': 318,\n",
       "    'y1': 148,\n",
       "    'y2': 237},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 125,\n",
       "    'x2': 217,\n",
       "    'y1': 152,\n",
       "    'y2': 235},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 79,\n",
       "    'x2': 134,\n",
       "    'y1': 168,\n",
       "    'y2': 237},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 3,\n",
       "    'x2': 31,\n",
       "    'y1': 137,\n",
       "    'y2': 174},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 58,\n",
       "    'x2': 84,\n",
       "    'y1': 137,\n",
       "    'y2': 170},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 166,\n",
       "    'x2': 194,\n",
       "    'y1': 75,\n",
       "    'y2': 127},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 79,\n",
       "    'x2': 104,\n",
       "    'y1': 146,\n",
       "    'y2': 175},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': True,\n",
       "    'x1': 165,\n",
       "    'x2': 186,\n",
       "    'y1': 139,\n",
       "    'y2': 176}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007335.jpg',\n",
       "  'height': 264,\n",
       "  'imageset': 'test',\n",
       "  'width': 447},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 500,\n",
       "    'y1': 240,\n",
       "    'y2': 373},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 238,\n",
       "    'x2': 314,\n",
       "    'y1': 241,\n",
       "    'y2': 340}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001159.jpg',\n",
       "  'height': 373,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 93,\n",
       "    'x2': 427,\n",
       "    'y1': 23,\n",
       "    'y2': 327}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005534.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 68,\n",
       "    'x2': 453,\n",
       "    'y1': 87,\n",
       "    'y2': 278}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001422.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 268,\n",
       "    'x2': 362,\n",
       "    'y1': 220,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 97,\n",
       "    'x2': 375,\n",
       "    'y1': 15,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007000.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 67,\n",
       "    'x2': 478,\n",
       "    'y1': 88,\n",
       "    'y2': 361}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004871.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 165,\n",
       "    'x2': 391,\n",
       "    'y1': 135,\n",
       "    'y2': 233}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003230.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 234,\n",
       "    'x2': 373,\n",
       "    'y1': 71,\n",
       "    'y2': 333},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': True,\n",
       "    'x1': 321,\n",
       "    'x2': 389,\n",
       "    'y1': 120,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007013.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 238,\n",
       "    'x2': 273,\n",
       "    'y1': 107,\n",
       "    'y2': 141},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 237,\n",
       "    'x2': 266,\n",
       "    'y1': 120,\n",
       "    'y2': 140},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 106,\n",
       "    'x2': 394,\n",
       "    'y1': 136,\n",
       "    'y2': 234}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006137.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 175,\n",
       "    'x2': 325,\n",
       "    'y1': 76,\n",
       "    'y2': 248}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006007.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 22,\n",
       "    'x2': 379,\n",
       "    'y1': 134,\n",
       "    'y2': 494}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009199.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 178,\n",
       "    'x2': 259,\n",
       "    'y1': 188,\n",
       "    'y2': 300},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 89,\n",
       "    'x2': 160,\n",
       "    'y1': 134,\n",
       "    'y2': 300},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 154,\n",
       "    'x2': 180,\n",
       "    'y1': 205,\n",
       "    'y2': 254},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 65,\n",
       "    'y1': 155,\n",
       "    'y2': 304},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 261,\n",
       "    'x2': 376,\n",
       "    'y1': 255,\n",
       "    'y2': 296}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004317.jpg',\n",
       "  'height': 337,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 61,\n",
       "    'x2': 310,\n",
       "    'y1': 254,\n",
       "    'y2': 456},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 22,\n",
       "    'x2': 72,\n",
       "    'y1': 192,\n",
       "    'y2': 334},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 103,\n",
       "    'x2': 272,\n",
       "    'y1': 127,\n",
       "    'y2': 436},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 65,\n",
       "    'x2': 104,\n",
       "    'y1': 185,\n",
       "    'y2': 332}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008074.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 117,\n",
       "    'x2': 242,\n",
       "    'y1': 415,\n",
       "    'y2': 452}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002038.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 355},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 500,\n",
       "    'y1': 103,\n",
       "    'y2': 275}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003702.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 17,\n",
       "    'x2': 186,\n",
       "    'y1': 27,\n",
       "    'y2': 270},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 222,\n",
       "    'x2': 500,\n",
       "    'y1': 2,\n",
       "    'y2': 268}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007689.jpg',\n",
       "  'height': 272,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 8,\n",
       "    'x2': 242,\n",
       "    'y1': 123,\n",
       "    'y2': 244},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 242,\n",
       "    'x2': 259,\n",
       "    'y1': 169,\n",
       "    'y2': 208},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 420,\n",
       "    'x2': 486,\n",
       "    'y1': 229,\n",
       "    'y2': 281},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 315,\n",
       "    'x2': 394,\n",
       "    'y1': 226,\n",
       "    'y2': 281},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 228,\n",
       "    'x2': 314,\n",
       "    'y1': 209,\n",
       "    'y2': 279},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 72,\n",
       "    'x2': 177,\n",
       "    'y1': 201,\n",
       "    'y2': 280},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 47,\n",
       "    'x2': 137,\n",
       "    'y1': 203,\n",
       "    'y2': 273},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 31,\n",
       "    'y1': 219,\n",
       "    'y2': 263},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 379,\n",
       "    'x2': 392,\n",
       "    'y1': 178,\n",
       "    'y2': 207}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002920.jpg',\n",
       "  'height': 281,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 125,\n",
       "    'x2': 371,\n",
       "    'y1': 134,\n",
       "    'y2': 236}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007407.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 192,\n",
       "    'x2': 380,\n",
       "    'y1': 89,\n",
       "    'y2': 332}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003454.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 100,\n",
       "    'x2': 269,\n",
       "    'y1': 30,\n",
       "    'y2': 179},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 2,\n",
       "    'x2': 115,\n",
       "    'y1': 47,\n",
       "    'y2': 220},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 7,\n",
       "    'x2': 107,\n",
       "    'y1': 47,\n",
       "    'y2': 265},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 123,\n",
       "    'x2': 282,\n",
       "    'y1': 93,\n",
       "    'y2': 458}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003190.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 354},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 159,\n",
       "    'x2': 374,\n",
       "    'y1': 320,\n",
       "    'y2': 498},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 4,\n",
       "    'x2': 60,\n",
       "    'y1': 378,\n",
       "    'y2': 473},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 133,\n",
       "    'x2': 177,\n",
       "    'y1': 376,\n",
       "    'y2': 447},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 7,\n",
       "    'x2': 60,\n",
       "    'y1': 327,\n",
       "    'y2': 448},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 183,\n",
       "    'x2': 322,\n",
       "    'y1': 213,\n",
       "    'y2': 461},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 134,\n",
       "    'x2': 185,\n",
       "    'y1': 325,\n",
       "    'y2': 398}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003851.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 379},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 500,\n",
       "    'y1': 22,\n",
       "    'y2': 260},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 58,\n",
       "    'x2': 118,\n",
       "    'y1': 206,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 417,\n",
       "    'x2': 500,\n",
       "    'y1': 206,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003494.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 199,\n",
       "    'x2': 359,\n",
       "    'y1': 81,\n",
       "    'y2': 296},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 100,\n",
       "    'x2': 426,\n",
       "    'y1': 120,\n",
       "    'y2': 315}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000655.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 113,\n",
       "    'x2': 221,\n",
       "    'y1': 51,\n",
       "    'y2': 201},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 154,\n",
       "    'x2': 196,\n",
       "    'y1': 25,\n",
       "    'y2': 120}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000623.jpg',\n",
       "  'height': 212,\n",
       "  'imageset': 'test',\n",
       "  'width': 320},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 131,\n",
       "    'x2': 257,\n",
       "    'y1': 231,\n",
       "    'y2': 497},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 143,\n",
       "    'x2': 252,\n",
       "    'y1': 150,\n",
       "    'y2': 341},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 233,\n",
       "    'x2': 335,\n",
       "    'y1': 340,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 29,\n",
       "    'x2': 58,\n",
       "    'y1': 1,\n",
       "    'y2': 56},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 336,\n",
       "    'x2': 375,\n",
       "    'y1': 1,\n",
       "    'y2': 43}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005882.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 206,\n",
       "    'x2': 365,\n",
       "    'y1': 101,\n",
       "    'y2': 351},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 73,\n",
       "    'x2': 417,\n",
       "    'y1': 1,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008641.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 348,\n",
       "    'x2': 441,\n",
       "    'y1': 16,\n",
       "    'y2': 123},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 235,\n",
       "    'x2': 394,\n",
       "    'y1': 68,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 105,\n",
       "    'x2': 235,\n",
       "    'y1': 68,\n",
       "    'y2': 375},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 24,\n",
       "    'x2': 42,\n",
       "    'y1': 340,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008458.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 55,\n",
       "    'y1': 65,\n",
       "    'y2': 290},\n",
       "   {'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 15,\n",
       "    'x2': 500,\n",
       "    'y1': 35,\n",
       "    'y2': 306}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005626.jpg',\n",
       "  'height': 339,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 22,\n",
       "    'x2': 196,\n",
       "    'y1': 91,\n",
       "    'y2': 268},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 24,\n",
       "    'y1': 153,\n",
       "    'y2': 187},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 244,\n",
       "    'x2': 264,\n",
       "    'y1': 154,\n",
       "    'y2': 241},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 315,\n",
       "    'x2': 337,\n",
       "    'y1': 133,\n",
       "    'y2': 215},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 367,\n",
       "    'x2': 388,\n",
       "    'y1': 109,\n",
       "    'y2': 169},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 415,\n",
       "    'x2': 460,\n",
       "    'y1': 164,\n",
       "    'y2': 270},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 382,\n",
       "    'x2': 422,\n",
       "    'y1': 162,\n",
       "    'y2': 263},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 373,\n",
       "    'x2': 404,\n",
       "    'y1': 154,\n",
       "    'y2': 257},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 436,\n",
       "    'x2': 485,\n",
       "    'y1': 175,\n",
       "    'y2': 288}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000719.jpg',\n",
       "  'height': 323,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 54,\n",
       "    'x2': 444,\n",
       "    'y1': 138,\n",
       "    'y2': 284}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007155.jpg',\n",
       "  'height': 400,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 291,\n",
       "    'x2': 340,\n",
       "    'y1': 125,\n",
       "    'y2': 256},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 249,\n",
       "    'x2': 294,\n",
       "    'y1': 136,\n",
       "    'y2': 263},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 196,\n",
       "    'x2': 252,\n",
       "    'y1': 117,\n",
       "    'y2': 255},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 164,\n",
       "    'x2': 207,\n",
       "    'y1': 121,\n",
       "    'y2': 255},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 113,\n",
       "    'x2': 170,\n",
       "    'y1': 116,\n",
       "    'y2': 248},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 53,\n",
       "    'y1': 173,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 47,\n",
       "    'x2': 93,\n",
       "    'y1': 210,\n",
       "    'y2': 294},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 455,\n",
       "    'x2': 500,\n",
       "    'y1': 231,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006178.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 125,\n",
       "    'x2': 367,\n",
       "    'y1': 28,\n",
       "    'y2': 184},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 56,\n",
       "    'x2': 79,\n",
       "    'y1': 77,\n",
       "    'y2': 126},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 47,\n",
       "    'x2': 63,\n",
       "    'y1': 80,\n",
       "    'y2': 131},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 2,\n",
       "    'x2': 34,\n",
       "    'y1': 114,\n",
       "    'y2': 153},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 329,\n",
       "    'x2': 357,\n",
       "    'y1': 45,\n",
       "    'y2': 58},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 419,\n",
       "    'x2': 452,\n",
       "    'y1': 39,\n",
       "    'y2': 55}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007861.jpg',\n",
       "  'height': 229,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 419,\n",
       "    'y1': 162,\n",
       "    'y2': 261}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007870.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 139,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 305},\n",
       "   {'class': 'cat',\n",
       "    'difficult': True,\n",
       "    'x1': 28,\n",
       "    'x2': 298,\n",
       "    'y1': 89,\n",
       "    'y2': 329}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008594.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 397,\n",
       "    'y1': 10,\n",
       "    'y2': 354}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008473.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 295,\n",
       "    'x2': 500,\n",
       "    'y1': 96,\n",
       "    'y2': 219},\n",
       "   {'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 26,\n",
       "    'x2': 195,\n",
       "    'y1': 81,\n",
       "    'y2': 198}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005228.jpg',\n",
       "  'height': 219,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 208,\n",
       "    'x2': 332,\n",
       "    'y1': 194,\n",
       "    'y2': 259}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000135.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 204,\n",
       "    'x2': 458,\n",
       "    'y1': 138,\n",
       "    'y2': 285},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 78,\n",
       "    'x2': 241,\n",
       "    'y1': 128,\n",
       "    'y2': 258}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001285.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 93,\n",
       "    'x2': 467,\n",
       "    'y1': 36,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002262.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 166,\n",
       "    'x2': 376,\n",
       "    'y1': 80,\n",
       "    'y2': 332}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002761.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': True,\n",
       "    'x1': 229,\n",
       "    'x2': 248,\n",
       "    'y1': 175,\n",
       "    'y2': 200},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 98,\n",
       "    'x2': 123,\n",
       "    'y1': 189,\n",
       "    'y2': 225},\n",
       "   {'class': 'bird',\n",
       "    'difficult': True,\n",
       "    'x1': 20,\n",
       "    'x2': 41,\n",
       "    'y1': 369,\n",
       "    'y2': 405},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 138,\n",
       "    'x2': 170,\n",
       "    'y1': 439,\n",
       "    'y2': 486},\n",
       "   {'class': 'bird',\n",
       "    'difficult': True,\n",
       "    'x1': 281,\n",
       "    'x2': 300,\n",
       "    'y1': 310,\n",
       "    'y2': 337}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007397.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 328},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 84,\n",
       "    'x2': 105,\n",
       "    'y1': 244,\n",
       "    'y2': 287},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 83,\n",
       "    'x2': 101,\n",
       "    'y1': 202,\n",
       "    'y2': 236},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 69,\n",
       "    'x2': 82,\n",
       "    'y1': 248,\n",
       "    'y2': 287},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 61,\n",
       "    'x2': 71,\n",
       "    'y1': 248,\n",
       "    'y2': 286},\n",
       "   {'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 98,\n",
       "    'x2': 500,\n",
       "    'y1': 2,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007349.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 80,\n",
       "    'x2': 171,\n",
       "    'y1': 172,\n",
       "    'y2': 409},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 172,\n",
       "    'x2': 277,\n",
       "    'y1': 176,\n",
       "    'y2': 359},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 156,\n",
       "    'x2': 280,\n",
       "    'y1': 137,\n",
       "    'y2': 459},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 254,\n",
       "    'x2': 479,\n",
       "    'y1': 137,\n",
       "    'y2': 462},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 312,\n",
       "    'x2': 426,\n",
       "    'y1': 150,\n",
       "    'y2': 413},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 12,\n",
       "    'x2': 477,\n",
       "    'y1': 195,\n",
       "    'y2': 390}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007929.jpg',\n",
       "  'height': 488,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 284,\n",
       "    'x2': 423,\n",
       "    'y1': 43,\n",
       "    'y2': 354},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 190,\n",
       "    'x2': 320,\n",
       "    'y1': 46,\n",
       "    'y2': 261},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 97,\n",
       "    'x2': 176,\n",
       "    'y1': 90,\n",
       "    'y2': 295},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 9,\n",
       "    'x2': 97,\n",
       "    'y1': 94,\n",
       "    'y2': 353},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 61,\n",
       "    'x2': 214,\n",
       "    'y1': 53,\n",
       "    'y2': 288},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 432,\n",
       "    'x2': 477,\n",
       "    'y1': 108,\n",
       "    'y2': 178}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005921.jpg',\n",
       "  'height': 354,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 414,\n",
       "    'x2': 473,\n",
       "    'y1': 1,\n",
       "    'y2': 205},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 34,\n",
       "    'y1': 1,\n",
       "    'y2': 197},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 68,\n",
       "    'x2': 429,\n",
       "    'y1': 29,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001891.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 154,\n",
       "    'x2': 248,\n",
       "    'y1': 274,\n",
       "    'y2': 382}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007103.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 336},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 146,\n",
       "    'x2': 387,\n",
       "    'y1': 143,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 196,\n",
       "    'x2': 317,\n",
       "    'y1': 26,\n",
       "    'y2': 337},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 146,\n",
       "    'x2': 360,\n",
       "    'y1': 1,\n",
       "    'y2': 297},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 80,\n",
       "    'y1': 69,\n",
       "    'y2': 155}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003482.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 142,\n",
       "    'x2': 415,\n",
       "    'y1': 67,\n",
       "    'y2': 275}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009399.jpg',\n",
       "  'height': 335,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 92,\n",
       "    'x2': 238,\n",
       "    'y1': 83,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 146,\n",
       "    'x2': 368,\n",
       "    'y1': 56,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001735.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 179,\n",
       "    'x2': 358,\n",
       "    'y1': 89,\n",
       "    'y2': 196}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008589.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 234,\n",
       "    'x2': 319,\n",
       "    'y1': 108,\n",
       "    'y2': 184}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006244.jpg',\n",
       "  'height': 342,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 65,\n",
       "    'x2': 243,\n",
       "    'y1': 193,\n",
       "    'y2': 373},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 43,\n",
       "    'y1': 103,\n",
       "    'y2': 167},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 266,\n",
       "    'x2': 311,\n",
       "    'y1': 48,\n",
       "    'y2': 106},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 250,\n",
       "    'x2': 479,\n",
       "    'y1': 115,\n",
       "    'y2': 373},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 57,\n",
       "    'x2': 189,\n",
       "    'y1': 82,\n",
       "    'y2': 364},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 34,\n",
       "    'x2': 94,\n",
       "    'y1': 36,\n",
       "    'y2': 142},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 153,\n",
       "    'x2': 273,\n",
       "    'y1': 66,\n",
       "    'y2': 198},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 217,\n",
       "    'x2': 295,\n",
       "    'y1': 53,\n",
       "    'y2': 154},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 79,\n",
       "    'x2': 140,\n",
       "    'y1': 36,\n",
       "    'y2': 92},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 150,\n",
       "    'x2': 203,\n",
       "    'y1': 1,\n",
       "    'y2': 72},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 111,\n",
       "    'x2': 159,\n",
       "    'y1': 12,\n",
       "    'y2': 68}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004128.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 342,\n",
       "    'x2': 427,\n",
       "    'y1': 88,\n",
       "    'y2': 170},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 281,\n",
       "    'x2': 402,\n",
       "    'y1': 161,\n",
       "    'y2': 357}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008563.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 157,\n",
       "    'x2': 327,\n",
       "    'y1': 61,\n",
       "    'y2': 297}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009233.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 500,\n",
       "    'y1': 6,\n",
       "    'y2': 281},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 154,\n",
       "    'y1': 182,\n",
       "    'y2': 288}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002489.jpg',\n",
       "  'height': 288,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 52,\n",
       "    'x2': 446,\n",
       "    'y1': 48,\n",
       "    'y2': 338}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007055.jpg',\n",
       "  'height': 379,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 63,\n",
       "    'x2': 483,\n",
       "    'y1': 94,\n",
       "    'y2': 289},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 252,\n",
       "    'x2': 401,\n",
       "    'y1': 259,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 403,\n",
       "    'x2': 472,\n",
       "    'y1': 241,\n",
       "    'y2': 285},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 59,\n",
       "    'x2': 183,\n",
       "    'y1': 128,\n",
       "    'y2': 353},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 3,\n",
       "    'x2': 83,\n",
       "    'y1': 218,\n",
       "    'y2': 290},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 385,\n",
       "    'x2': 401,\n",
       "    'y1': 102,\n",
       "    'y2': 122}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006882.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 5,\n",
       "    'x2': 500,\n",
       "    'y1': 75,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 152,\n",
       "    'x2': 488,\n",
       "    'y1': 2,\n",
       "    'y2': 140}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005758.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 213,\n",
       "    'x2': 374,\n",
       "    'y1': 186,\n",
       "    'y2': 340},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 148,\n",
       "    'x2': 432,\n",
       "    'y1': 119,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 87,\n",
       "    'x2': 283,\n",
       "    'y1': 85,\n",
       "    'y2': 359},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 480,\n",
       "    'y1': 109,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004465.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 125,\n",
       "    'x2': 348,\n",
       "    'y1': 91,\n",
       "    'y2': 298},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 146,\n",
       "    'x2': 345,\n",
       "    'y1': 41,\n",
       "    'y2': 283},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 54,\n",
       "    'y1': 32,\n",
       "    'y2': 104},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 33,\n",
       "    'x2': 93,\n",
       "    'y1': 26,\n",
       "    'y2': 102},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 82,\n",
       "    'x2': 134,\n",
       "    'y1': 35,\n",
       "    'y2': 102},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 128,\n",
       "    'x2': 164,\n",
       "    'y1': 28,\n",
       "    'y2': 106},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 166,\n",
       "    'x2': 265,\n",
       "    'y1': 42,\n",
       "    'y2': 100},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': True,\n",
       "    'x1': 325,\n",
       "    'x2': 342,\n",
       "    'y1': 41,\n",
       "    'y2': 98},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 343,\n",
       "    'x2': 366,\n",
       "    'y1': 43,\n",
       "    'y2': 100},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 360,\n",
       "    'x2': 397,\n",
       "    'y1': 42,\n",
       "    'y2': 98},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 390,\n",
       "    'x2': 462,\n",
       "    'y1': 35,\n",
       "    'y2': 99},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': True,\n",
       "    'x1': 447,\n",
       "    'x2': 470,\n",
       "    'y1': 43,\n",
       "    'y2': 101},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': True,\n",
       "    'x1': 468,\n",
       "    'x2': 489,\n",
       "    'y1': 60,\n",
       "    'y2': 95}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006796.jpg',\n",
       "  'height': 331,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 129,\n",
       "    'x2': 320,\n",
       "    'y1': 153,\n",
       "    'y2': 224},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 398,\n",
       "    'x2': 492,\n",
       "    'y1': 177,\n",
       "    'y2': 214},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': True,\n",
       "    'x1': 90,\n",
       "    'x2': 164,\n",
       "    'y1': 176,\n",
       "    'y2': 216}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007290.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 65,\n",
       "    'x2': 481,\n",
       "    'y1': 96,\n",
       "    'y2': 277},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 424,\n",
       "    'x2': 500,\n",
       "    'y1': 212,\n",
       "    'y2': 245}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007837.jpg',\n",
       "  'height': 400,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 134,\n",
       "    'y1': 84,\n",
       "    'y2': 234},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 74,\n",
       "    'x2': 437,\n",
       "    'y1': 84,\n",
       "    'y2': 271}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007617.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 293,\n",
       "    'y1': 1,\n",
       "    'y2': 373},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 443,\n",
       "    'x2': 490,\n",
       "    'y1': 252,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000238.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 410,\n",
       "    'x2': 500,\n",
       "    'y1': 139,\n",
       "    'y2': 369},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 328,\n",
       "    'x2': 435,\n",
       "    'y1': 135,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 243,\n",
       "    'x2': 301,\n",
       "    'y1': 299,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 202,\n",
       "    'x2': 302,\n",
       "    'y1': 164,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 157,\n",
       "    'x2': 220,\n",
       "    'y1': 200,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002726.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 146,\n",
       "    'x2': 302,\n",
       "    'y1': 39,\n",
       "    'y2': 310},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 263,\n",
       "    'x2': 340,\n",
       "    'y1': 40,\n",
       "    'y2': 219}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006273.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 429,\n",
       "    'x2': 499,\n",
       "    'y1': 176,\n",
       "    'y2': 211},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 78,\n",
       "    'x2': 259,\n",
       "    'y1': 182,\n",
       "    'y2': 215},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 291,\n",
       "    'x2': 383,\n",
       "    'y1': 162,\n",
       "    'y2': 193},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 373,\n",
       "    'x2': 433,\n",
       "    'y1': 171,\n",
       "    'y2': 214},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 351,\n",
       "    'x2': 373,\n",
       "    'y1': 165,\n",
       "    'y2': 211},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 388,\n",
       "    'x2': 418,\n",
       "    'y1': 156,\n",
       "    'y2': 175},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 316,\n",
       "    'x2': 356,\n",
       "    'y1': 165,\n",
       "    'y2': 213},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 295,\n",
       "    'x2': 310,\n",
       "    'y1': 157,\n",
       "    'y2': 164},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 281,\n",
       "    'x2': 309,\n",
       "    'y1': 158,\n",
       "    'y2': 206},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 274,\n",
       "    'x2': 282,\n",
       "    'y1': 158,\n",
       "    'y2': 171},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 259,\n",
       "    'x2': 291,\n",
       "    'y1': 172,\n",
       "    'y2': 214},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 235,\n",
       "    'x2': 260,\n",
       "    'y1': 164,\n",
       "    'y2': 186},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 252,\n",
       "    'x2': 266,\n",
       "    'y1': 159,\n",
       "    'y2': 169},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 174,\n",
       "    'x2': 208,\n",
       "    'y1': 163,\n",
       "    'y2': 180},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 117,\n",
       "    'x2': 179,\n",
       "    'y1': 179,\n",
       "    'y2': 213},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 97,\n",
       "    'x2': 129,\n",
       "    'y1': 165,\n",
       "    'y2': 189},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 123,\n",
       "    'x2': 134,\n",
       "    'y1': 164,\n",
       "    'y2': 174},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 85,\n",
       "    'x2': 94,\n",
       "    'y1': 161,\n",
       "    'y2': 189},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 53,\n",
       "    'x2': 79,\n",
       "    'y1': 162,\n",
       "    'y2': 211},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 458,\n",
       "    'x2': 495,\n",
       "    'y1': 136,\n",
       "    'y2': 175},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 47,\n",
       "    'x2': 77,\n",
       "    'y1': 139,\n",
       "    'y2': 164},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 37,\n",
       "    'x2': 51,\n",
       "    'y1': 140,\n",
       "    'y2': 167},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 12,\n",
       "    'x2': 37,\n",
       "    'y1': 140,\n",
       "    'y2': 172}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000126.jpg',\n",
       "  'height': 215,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 93,\n",
       "    'x2': 393,\n",
       "    'y1': 197,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 366,\n",
       "    'x2': 440,\n",
       "    'y1': 332,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004567.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 201,\n",
       "    'x2': 325,\n",
       "    'y1': 57,\n",
       "    'y2': 259},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 112,\n",
       "    'x2': 441,\n",
       "    'y1': 100,\n",
       "    'y2': 409}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000783.jpg',\n",
       "  'height': 437,\n",
       "  'imageset': 'test',\n",
       "  'width': 480},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 22,\n",
       "    'x2': 101,\n",
       "    'y1': 4,\n",
       "    'y2': 113},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 129,\n",
       "    'x2': 355,\n",
       "    'y1': 84,\n",
       "    'y2': 384}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007384.jpg',\n",
       "  'height': 416,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 50,\n",
       "    'x2': 228,\n",
       "    'y1': 79,\n",
       "    'y2': 210},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 224,\n",
       "    'x2': 415,\n",
       "    'y1': 81,\n",
       "    'y2': 236},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 245,\n",
       "    'x2': 415,\n",
       "    'y1': 39,\n",
       "    'y2': 229},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 84,\n",
       "    'x2': 229,\n",
       "    'y1': 36,\n",
       "    'y2': 205}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008034.jpg',\n",
       "  'height': 331,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 15,\n",
       "    'x2': 454,\n",
       "    'y1': 51,\n",
       "    'y2': 318},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 40,\n",
       "    'x2': 438,\n",
       "    'y1': 288,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 402,\n",
       "    'x2': 466,\n",
       "    'y1': 255,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 100,\n",
       "    'x2': 196,\n",
       "    'y1': 233,\n",
       "    'y2': 298},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 2,\n",
       "    'x2': 88,\n",
       "    'y1': 252,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009355.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 391,\n",
       "    'x2': 488,\n",
       "    'y1': 235,\n",
       "    'y2': 335},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 433,\n",
       "    'x2': 500,\n",
       "    'y1': 200,\n",
       "    'y2': 304},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 422,\n",
       "    'x2': 500,\n",
       "    'y1': 186,\n",
       "    'y2': 242},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 397,\n",
       "    'x2': 454,\n",
       "    'y1': 183,\n",
       "    'y2': 241},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': True,\n",
       "    'x1': 29,\n",
       "    'x2': 47,\n",
       "    'y1': 198,\n",
       "    'y2': 226},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 259,\n",
       "    'x2': 283,\n",
       "    'y1': 129,\n",
       "    'y2': 164}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008560.jpg',\n",
       "  'height': 335,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 206,\n",
       "    'x2': 306,\n",
       "    'y1': 113,\n",
       "    'y2': 151}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007135.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 267,\n",
       "    'x2': 500,\n",
       "    'y1': 161,\n",
       "    'y2': 331},\n",
       "   {'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 179,\n",
       "    'x2': 316,\n",
       "    'y1': 150,\n",
       "    'y2': 263},\n",
       "   {'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 35,\n",
       "    'x2': 235,\n",
       "    'y1': 127,\n",
       "    'y2': 196}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007516.jpg',\n",
       "  'height': 363,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 158,\n",
       "    'x2': 334,\n",
       "    'y1': 160,\n",
       "    'y2': 263},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 19,\n",
       "    'x2': 46,\n",
       "    'y1': 179,\n",
       "    'y2': 211}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004320.jpg',\n",
       "  'height': 379,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 40,\n",
       "    'x2': 86,\n",
       "    'y1': 245,\n",
       "    'y2': 276}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007278.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 345,\n",
       "    'x2': 407,\n",
       "    'y1': 195,\n",
       "    'y2': 294},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 242,\n",
       "    'x2': 270,\n",
       "    'y1': 192,\n",
       "    'y2': 280},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 250,\n",
       "    'x2': 320,\n",
       "    'y1': 227,\n",
       "    'y2': 333},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 266,\n",
       "    'x2': 390,\n",
       "    'y1': 210,\n",
       "    'y2': 316}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009690.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 11,\n",
       "    'x2': 500,\n",
       "    'y1': 85,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 353,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 239}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000617.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 266,\n",
       "    'y1': 90,\n",
       "    'y2': 337},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 63,\n",
       "    'x2': 305,\n",
       "    'y1': 82,\n",
       "    'y2': 325},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 174,\n",
       "    'x2': 465,\n",
       "    'y1': 77,\n",
       "    'y2': 309},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 33,\n",
       "    'x2': 140,\n",
       "    'y1': 54,\n",
       "    'y2': 187},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 107,\n",
       "    'x2': 215,\n",
       "    'y1': 53,\n",
       "    'y2': 136},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 270,\n",
       "    'x2': 376,\n",
       "    'y1': 60,\n",
       "    'y2': 174}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009231.jpg',\n",
       "  'height': 355,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 256,\n",
       "    'x2': 500,\n",
       "    'y1': 231,\n",
       "    'y2': 333},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 256,\n",
       "    'y1': 255,\n",
       "    'y2': 333},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 238,\n",
       "    'x2': 302,\n",
       "    'y1': 252,\n",
       "    'y2': 300},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 160,\n",
       "    'x2': 231,\n",
       "    'y1': 251,\n",
       "    'y2': 276},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 62,\n",
       "    'y1': 267,\n",
       "    'y2': 293},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 3,\n",
       "    'x2': 53,\n",
       "    'y1': 248,\n",
       "    'y2': 273}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002543.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 158,\n",
       "    'x2': 247,\n",
       "    'y1': 158,\n",
       "    'y2': 312}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006967.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 365},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 171,\n",
       "    'x2': 467,\n",
       "    'y1': 78,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 52,\n",
       "    'x2': 171,\n",
       "    'y1': 83,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 58,\n",
       "    'y1': 131,\n",
       "    'y2': 375},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 355,\n",
       "    'y1': 138,\n",
       "    'y2': 375},\n",
       "   {'class': 'dog',\n",
       "    'difficult': True,\n",
       "    'x1': 152,\n",
       "    'x2': 313,\n",
       "    'y1': 193,\n",
       "    'y2': 278}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005100.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 128,\n",
       "    'x2': 223,\n",
       "    'y1': 241,\n",
       "    'y2': 311},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 241,\n",
       "    'x2': 321,\n",
       "    'y1': 79,\n",
       "    'y2': 142},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 175,\n",
       "    'x2': 328,\n",
       "    'y1': 115,\n",
       "    'y2': 348},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 200,\n",
       "    'x2': 330,\n",
       "    'y1': 44,\n",
       "    'y2': 212},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 308,\n",
       "    'x2': 377,\n",
       "    'y1': 43,\n",
       "    'y2': 225},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 178,\n",
       "    'x2': 205,\n",
       "    'y1': 45,\n",
       "    'y2': 164}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003619.jpg',\n",
       "  'height': 397,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 275,\n",
       "    'x2': 397,\n",
       "    'y1': 170,\n",
       "    'y2': 262},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 65,\n",
       "    'x2': 241,\n",
       "    'y1': 50,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003562.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 136,\n",
       "    'x2': 256,\n",
       "    'y1': 11,\n",
       "    'y2': 374},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 362,\n",
       "    'x2': 500,\n",
       "    'y1': 167,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 119,\n",
       "    'y1': 1,\n",
       "    'y2': 146}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004207.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 332,\n",
       "    'y1': 72,\n",
       "    'y2': 499}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007115.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 94,\n",
       "    'x2': 226,\n",
       "    'y1': 218,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 189,\n",
       "    'x2': 500,\n",
       "    'y1': 11,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000286.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 203,\n",
       "    'x2': 358,\n",
       "    'y1': 154,\n",
       "    'y2': 256}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003109.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 172,\n",
       "    'x2': 262,\n",
       "    'y1': 85,\n",
       "    'y2': 236},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 116,\n",
       "    'x2': 205,\n",
       "    'y1': 106,\n",
       "    'y2': 218}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006311.jpg',\n",
       "  'height': 252,\n",
       "  'imageset': 'test',\n",
       "  'width': 448},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 33,\n",
       "    'x2': 455,\n",
       "    'y1': 144,\n",
       "    'y2': 258},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 100,\n",
       "    'x2': 195,\n",
       "    'y1': 218,\n",
       "    'y2': 256},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 235,\n",
       "    'x2': 385,\n",
       "    'y1': 222,\n",
       "    'y2': 261},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 341,\n",
       "    'x2': 454,\n",
       "    'y1': 225,\n",
       "    'y2': 261}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002467.jpg',\n",
       "  'height': 390,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 95,\n",
       "    'x2': 261,\n",
       "    'y1': 297,\n",
       "    'y2': 393},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 132,\n",
       "    'x2': 250,\n",
       "    'y1': 265,\n",
       "    'y2': 318},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 233,\n",
       "    'x2': 296,\n",
       "    'y1': 304,\n",
       "    'y2': 407},\n",
       "   {'class': 'dog',\n",
       "    'difficult': True,\n",
       "    'x1': 236,\n",
       "    'x2': 285,\n",
       "    'y1': 276,\n",
       "    'y2': 316},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 289,\n",
       "    'x2': 305,\n",
       "    'y1': 166,\n",
       "    'y2': 207},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 18,\n",
       "    'x2': 112,\n",
       "    'y1': 111,\n",
       "    'y2': 440}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003592.jpg',\n",
       "  'height': 480,\n",
       "  'imageset': 'test',\n",
       "  'width': 320},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 331,\n",
       "    'x2': 500,\n",
       "    'y1': 12,\n",
       "    'y2': 332},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 43,\n",
       "    'x2': 157,\n",
       "    'y1': 46,\n",
       "    'y2': 218},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 259,\n",
       "    'x2': 379,\n",
       "    'y1': 97,\n",
       "    'y2': 148},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 3,\n",
       "    'x2': 39,\n",
       "    'y1': 128,\n",
       "    'y2': 221},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 5,\n",
       "    'x2': 417,\n",
       "    'y1': 130,\n",
       "    'y2': 332}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001805.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 433,\n",
       "    'y1': 3,\n",
       "    'y2': 328}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009759.jpg',\n",
       "  'height': 329,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 193,\n",
       "    'y1': 80,\n",
       "    'y2': 318},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 363,\n",
       "    'y1': 104,\n",
       "    'y2': 318},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 367,\n",
       "    'x2': 471,\n",
       "    'y1': 131,\n",
       "    'y2': 318},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 76,\n",
       "    'x2': 175,\n",
       "    'y1': 17,\n",
       "    'y2': 318},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 228,\n",
       "    'x2': 270,\n",
       "    'y1': 90,\n",
       "    'y2': 132},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 344,\n",
       "    'x2': 477,\n",
       "    'y1': 81,\n",
       "    'y2': 316}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009101.jpg',\n",
       "  'height': 318,\n",
       "  'imageset': 'test',\n",
       "  'width': 480},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 215,\n",
       "    'x2': 314,\n",
       "    'y1': 219,\n",
       "    'y2': 280},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 276,\n",
       "    'x2': 344,\n",
       "    'y1': 201,\n",
       "    'y2': 258},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 29,\n",
       "    'x2': 163,\n",
       "    'y1': 184,\n",
       "    'y2': 273}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008324.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 338,\n",
       "    'x2': 404,\n",
       "    'y1': 159,\n",
       "    'y2': 308},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 295,\n",
       "    'x2': 331,\n",
       "    'y1': 95,\n",
       "    'y2': 142},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 331,\n",
       "    'x2': 362,\n",
       "    'y1': 103,\n",
       "    'y2': 142},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 370,\n",
       "    'x2': 419,\n",
       "    'y1': 92,\n",
       "    'y2': 147},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 47,\n",
       "    'x2': 73,\n",
       "    'y1': 145,\n",
       "    'y2': 213},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 20,\n",
       "    'x2': 47,\n",
       "    'y1': 156,\n",
       "    'y2': 216}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009630.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 27,\n",
       "    'x2': 266,\n",
       "    'y1': 45,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000068.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 309,\n",
       "    'x2': 500,\n",
       "    'y1': 177,\n",
       "    'y2': 374},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 99,\n",
       "    'x2': 126,\n",
       "    'y1': 331,\n",
       "    'y2': 351},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 61,\n",
       "    'x2': 96,\n",
       "    'y1': 337,\n",
       "    'y2': 361},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 18,\n",
       "    'x2': 51,\n",
       "    'y1': 358,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001770.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cow',\n",
       "    'difficult': True,\n",
       "    'x1': 454,\n",
       "    'x2': 495,\n",
       "    'y1': 191,\n",
       "    'y2': 216},\n",
       "   {'class': 'cow',\n",
       "    'difficult': True,\n",
       "    'x1': 386,\n",
       "    'x2': 409,\n",
       "    'y1': 166,\n",
       "    'y2': 189},\n",
       "   {'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 265,\n",
       "    'x2': 321,\n",
       "    'y1': 181,\n",
       "    'y2': 234},\n",
       "   {'class': 'cow',\n",
       "    'difficult': True,\n",
       "    'x1': 274,\n",
       "    'x2': 302,\n",
       "    'y1': 150,\n",
       "    'y2': 182},\n",
       "   {'class': 'cow',\n",
       "    'difficult': True,\n",
       "    'x1': 252,\n",
       "    'x2': 273,\n",
       "    'y1': 167,\n",
       "    'y2': 210},\n",
       "   {'class': 'cow',\n",
       "    'difficult': True,\n",
       "    'x1': 213,\n",
       "    'x2': 255,\n",
       "    'y1': 176,\n",
       "    'y2': 238},\n",
       "   {'class': 'cow',\n",
       "    'difficult': True,\n",
       "    'x1': 170,\n",
       "    'x2': 206,\n",
       "    'y1': 160,\n",
       "    'y2': 223},\n",
       "   {'class': 'cow',\n",
       "    'difficult': True,\n",
       "    'x1': 122,\n",
       "    'x2': 168,\n",
       "    'y1': 148,\n",
       "    'y2': 199},\n",
       "   {'class': 'cow',\n",
       "    'difficult': True,\n",
       "    'x1': 114,\n",
       "    'x2': 171,\n",
       "    'y1': 108,\n",
       "    'y2': 163}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001716.jpg',\n",
       "  'height': 325,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 9,\n",
       "    'x2': 325,\n",
       "    'y1': 1,\n",
       "    'y2': 224}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009217.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 48,\n",
       "    'x2': 500,\n",
       "    'y1': 27,\n",
       "    'y2': 339}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008539.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 309,\n",
       "    'x2': 474,\n",
       "    'y1': 107,\n",
       "    'y2': 256}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003079.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 117,\n",
       "    'x2': 273,\n",
       "    'y1': 4,\n",
       "    'y2': 473},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 54,\n",
       "    'x2': 133,\n",
       "    'y1': 169,\n",
       "    'y2': 334}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005494.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 16,\n",
       "    'x2': 487,\n",
       "    'y1': 1,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008487.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 66,\n",
       "    'x2': 494,\n",
       "    'y1': 61,\n",
       "    'y2': 339},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 339,\n",
       "    'x2': 369,\n",
       "    'y1': 65,\n",
       "    'y2': 117},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 472,\n",
       "    'x2': 500,\n",
       "    'y1': 95,\n",
       "    'y2': 146},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 79,\n",
       "    'x2': 119,\n",
       "    'y1': 85,\n",
       "    'y2': 130},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 100,\n",
       "    'x2': 111,\n",
       "    'y1': 92,\n",
       "    'y2': 106},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 47,\n",
       "    'y1': 83,\n",
       "    'y2': 153}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003515.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 47,\n",
       "    'x2': 481,\n",
       "    'y1': 123,\n",
       "    'y2': 296},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 100,\n",
       "    'y1': 170,\n",
       "    'y2': 217},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 263,\n",
       "    'x2': 298,\n",
       "    'y1': 167,\n",
       "    'y2': 294},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 224,\n",
       "    'x2': 271,\n",
       "    'y1': 181,\n",
       "    'y2': 289}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007157.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 240,\n",
       "    'x2': 474,\n",
       "    'y1': 22,\n",
       "    'y2': 255}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008274.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 43,\n",
       "    'y1': 170,\n",
       "    'y2': 276},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 52,\n",
       "    'x2': 134,\n",
       "    'y1': 184,\n",
       "    'y2': 306},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 224,\n",
       "    'x2': 330,\n",
       "    'y1': 206,\n",
       "    'y2': 312},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 197,\n",
       "    'x2': 334,\n",
       "    'y1': 238,\n",
       "    'y2': 374},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 436,\n",
       "    'x2': 500,\n",
       "    'y1': 308,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005734.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 50,\n",
       "    'x2': 387,\n",
       "    'y1': 137,\n",
       "    'y2': 290}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005537.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 58,\n",
       "    'x2': 343,\n",
       "    'y1': 126,\n",
       "    'y2': 390},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 143,\n",
       "    'x2': 280,\n",
       "    'y1': 66,\n",
       "    'y2': 252}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005610.jpg',\n",
       "  'height': 480,\n",
       "  'imageset': 'test',\n",
       "  'width': 402},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 81,\n",
       "    'x2': 157,\n",
       "    'y1': 149,\n",
       "    'y2': 333},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 140,\n",
       "    'x2': 206,\n",
       "    'y1': 113,\n",
       "    'y2': 333},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 207,\n",
       "    'x2': 284,\n",
       "    'y1': 123,\n",
       "    'y2': 333},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 295,\n",
       "    'x2': 373,\n",
       "    'y1': 125,\n",
       "    'y2': 333},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 107,\n",
       "    'x2': 135,\n",
       "    'y1': 39,\n",
       "    'y2': 106},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 150,\n",
       "    'x2': 186,\n",
       "    'y1': 43,\n",
       "    'y2': 112},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 139,\n",
       "    'x2': 163,\n",
       "    'y1': 27,\n",
       "    'y2': 71},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 185,\n",
       "    'x2': 206,\n",
       "    'y1': 30,\n",
       "    'y2': 94},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 199,\n",
       "    'x2': 227,\n",
       "    'y1': 58,\n",
       "    'y2': 146},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 245,\n",
       "    'x2': 277,\n",
       "    'y1': 70,\n",
       "    'y2': 150},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 249,\n",
       "    'x2': 276,\n",
       "    'y1': 26,\n",
       "    'y2': 73},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 224,\n",
       "    'x2': 249,\n",
       "    'y1': 41,\n",
       "    'y2': 86},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 207,\n",
       "    'x2': 233,\n",
       "    'y1': 14,\n",
       "    'y2': 59},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 170,\n",
       "    'x2': 196,\n",
       "    'y1': 8,\n",
       "    'y2': 47},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 275,\n",
       "    'x2': 295,\n",
       "    'y1': 50,\n",
       "    'y2': 67},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 327,\n",
       "    'x2': 354,\n",
       "    'y1': 51,\n",
       "    'y2': 84},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 347,\n",
       "    'x2': 376,\n",
       "    'y1': 36,\n",
       "    'y2': 89},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 366,\n",
       "    'x2': 394,\n",
       "    'y1': 24,\n",
       "    'y2': 61},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 380,\n",
       "    'x2': 408,\n",
       "    'y1': 58,\n",
       "    'y2': 87},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 396,\n",
       "    'x2': 426,\n",
       "    'y1': 44,\n",
       "    'y2': 87},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 437,\n",
       "    'x2': 466,\n",
       "    'y1': 67,\n",
       "    'y2': 100},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 451,\n",
       "    'x2': 481,\n",
       "    'y1': 51,\n",
       "    'y2': 80},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 470,\n",
       "    'x2': 497,\n",
       "    'y1': 32,\n",
       "    'y2': 60},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 419,\n",
       "    'x2': 441,\n",
       "    'y1': 26,\n",
       "    'y2': 52}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004236.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 96,\n",
       "    'x2': 281,\n",
       "    'y1': 43,\n",
       "    'y2': 334},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 112,\n",
       "    'x2': 287,\n",
       "    'y1': 205,\n",
       "    'y2': 465}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008446.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 436,\n",
       "    'x2': 500,\n",
       "    'y1': 197,\n",
       "    'y2': 268},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 362,\n",
       "    'x2': 440,\n",
       "    'y1': 198,\n",
       "    'y2': 280},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 137,\n",
       "    'x2': 221,\n",
       "    'y1': 204,\n",
       "    'y2': 300}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000992.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 30,\n",
       "    'x2': 294,\n",
       "    'y1': 217,\n",
       "    'y2': 482},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 118,\n",
       "    'x2': 216,\n",
       "    'y1': 5,\n",
       "    'y2': 267}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006816.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 36,\n",
       "    'x2': 500,\n",
       "    'y1': 77,\n",
       "    'y2': 332}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008693.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 18,\n",
       "    'x2': 469,\n",
       "    'y1': 42,\n",
       "    'y2': 346}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005681.jpg',\n",
       "  'height': 382,\n",
       "  'imageset': 'test',\n",
       "  'width': 472},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 57,\n",
       "    'x2': 404,\n",
       "    'y1': 134,\n",
       "    'y2': 341},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 437,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 145},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 383,\n",
       "    'x2': 443,\n",
       "    'y1': 9,\n",
       "    'y2': 124},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 351,\n",
       "    'x2': 397,\n",
       "    'y1': 2,\n",
       "    'y2': 143},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 311,\n",
       "    'x2': 358,\n",
       "    'y1': 8,\n",
       "    'y2': 123},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 293,\n",
       "    'x2': 349,\n",
       "    'y1': 124,\n",
       "    'y2': 321},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 344,\n",
       "    'x2': 430,\n",
       "    'y1': 284,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 247,\n",
       "    'x2': 317,\n",
       "    'y1': 307,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 168,\n",
       "    'x2': 198,\n",
       "    'y1': 10,\n",
       "    'y2': 54},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 128,\n",
       "    'x2': 164,\n",
       "    'y1': 2,\n",
       "    'y2': 46},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 80,\n",
       "    'x2': 108,\n",
       "    'y1': 2,\n",
       "    'y2': 142},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 94,\n",
       "    'x2': 142,\n",
       "    'y1': 3,\n",
       "    'y2': 142},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 133,\n",
       "    'x2': 197,\n",
       "    'y1': 20,\n",
       "    'y2': 142},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 49,\n",
       "    'y1': 227,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 29,\n",
       "    'y1': 8,\n",
       "    'y2': 150}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003680.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 213,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 375},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 135,\n",
       "    'x2': 158,\n",
       "    'y1': 183,\n",
       "    'y2': 216},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 111,\n",
       "    'x2': 145,\n",
       "    'y1': 128,\n",
       "    'y2': 163},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 72,\n",
       "    'x2': 102,\n",
       "    'y1': 131,\n",
       "    'y2': 170}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004188.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 51,\n",
       "    'x2': 151,\n",
       "    'y1': 111,\n",
       "    'y2': 302},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 37,\n",
       "    'x2': 150,\n",
       "    'y1': 62,\n",
       "    'y2': 223}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003531.jpg',\n",
       "  'height': 320,\n",
       "  'imageset': 'test',\n",
       "  'width': 212},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 383,\n",
       "    'x2': 447,\n",
       "    'y1': 145,\n",
       "    'y2': 302},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 233,\n",
       "    'x2': 267,\n",
       "    'y1': 138,\n",
       "    'y2': 249},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 120,\n",
       "    'x2': 174,\n",
       "    'y1': 97,\n",
       "    'y2': 275},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 22,\n",
       "    'x2': 86,\n",
       "    'y1': 90,\n",
       "    'y2': 323},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 211,\n",
       "    'x2': 268,\n",
       "    'y1': 123,\n",
       "    'y2': 161},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 165,\n",
       "    'x2': 246,\n",
       "    'y1': 163,\n",
       "    'y2': 245}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007186.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 6,\n",
       "    'x2': 496,\n",
       "    'y1': 111,\n",
       "    'y2': 242}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003381.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 29,\n",
       "    'x2': 321,\n",
       "    'y1': 152,\n",
       "    'y2': 373}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007934.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 357},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 47,\n",
       "    'x2': 234,\n",
       "    'y1': 152,\n",
       "    'y2': 259}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008515.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 461,\n",
       "    'x2': 500,\n",
       "    'y1': 2,\n",
       "    'y2': 84},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 479,\n",
       "    'y1': 1,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002507.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 96,\n",
       "    'x2': 282,\n",
       "    'y1': 124,\n",
       "    'y2': 190},\n",
       "   {'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 198,\n",
       "    'x2': 258,\n",
       "    'y1': 220,\n",
       "    'y2': 238},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 205,\n",
       "    'x2': 227,\n",
       "    'y1': 193,\n",
       "    'y2': 229},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 224,\n",
       "    'x2': 258,\n",
       "    'y1': 217,\n",
       "    'y2': 229}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004665.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': True,\n",
       "    'x1': 123,\n",
       "    'x2': 295,\n",
       "    'y1': 240,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 161,\n",
       "    'x2': 251,\n",
       "    'y1': 112,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 250,\n",
       "    'x2': 339,\n",
       "    'y1': 157,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000643.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 217,\n",
       "    'x2': 458,\n",
       "    'y1': 83,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 6,\n",
       "    'x2': 323,\n",
       "    'y1': 22,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005792.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 19,\n",
       "    'x2': 196,\n",
       "    'y1': 35,\n",
       "    'y2': 375},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 140,\n",
       "    'x2': 500,\n",
       "    'y1': 110,\n",
       "    'y2': 375},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 435,\n",
       "    'x2': 500,\n",
       "    'y1': 104,\n",
       "    'y2': 134},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 274,\n",
       "    'x2': 383,\n",
       "    'y1': 92,\n",
       "    'y2': 121},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 188,\n",
       "    'x2': 271,\n",
       "    'y1': 87,\n",
       "    'y2': 115},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 139,\n",
       "    'x2': 215,\n",
       "    'y1': 95,\n",
       "    'y2': 112},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 472,\n",
       "    'x2': 500,\n",
       "    'y1': 108,\n",
       "    'y2': 146}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008363.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 12,\n",
       "    'x2': 337,\n",
       "    'y1': 1,\n",
       "    'y2': 274}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001507.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 227,\n",
       "    'x2': 335,\n",
       "    'y1': 29,\n",
       "    'y2': 244}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005426.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 170,\n",
       "    'x2': 376,\n",
       "    'y1': 88,\n",
       "    'y2': 248}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001048.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 68,\n",
       "    'x2': 454,\n",
       "    'y1': 133,\n",
       "    'y2': 224}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003144.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 59,\n",
       "    'x2': 297,\n",
       "    'y1': 234,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 138,\n",
       "    'x2': 257,\n",
       "    'y1': 142,\n",
       "    'y2': 365},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 217,\n",
       "    'x2': 263,\n",
       "    'y1': 126,\n",
       "    'y2': 213},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 253,\n",
       "    'x2': 397,\n",
       "    'y1': 128,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008901.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 330,\n",
       "    'x2': 376,\n",
       "    'y1': 12,\n",
       "    'y2': 96},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 298,\n",
       "    'x2': 403,\n",
       "    'y1': 155,\n",
       "    'y2': 266}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008471.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 326,\n",
       "    'y1': 7,\n",
       "    'y2': 472},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 245,\n",
       "    'x2': 274,\n",
       "    'y1': 458,\n",
       "    'y2': 493},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 305,\n",
       "    'x2': 327,\n",
       "    'y1': 468,\n",
       "    'y2': 494}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009292.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 327},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 486,\n",
       "    'y1': 5,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006980.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 214,\n",
       "    'x2': 256,\n",
       "    'y1': 146,\n",
       "    'y2': 298}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005206.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 24,\n",
       "    'x2': 493,\n",
       "    'y1': 22,\n",
       "    'y2': 326}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004071.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 414,\n",
       "    'x2': 484,\n",
       "    'y1': 182,\n",
       "    'y2': 237},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 338,\n",
       "    'x2': 357,\n",
       "    'y1': 189,\n",
       "    'y2': 232},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 43,\n",
       "    'x2': 62,\n",
       "    'y1': 169,\n",
       "    'y2': 231}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000271.jpg',\n",
       "  'height': 321,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 497,\n",
       "    'y1': 4,\n",
       "    'y2': 373}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008546.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 14,\n",
       "    'x2': 108,\n",
       "    'y1': 1,\n",
       "    'y2': 273},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 160,\n",
       "    'x2': 352,\n",
       "    'y1': 111,\n",
       "    'y2': 255}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001656.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 154,\n",
       "    'x2': 271,\n",
       "    'y1': 125,\n",
       "    'y2': 233},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 17,\n",
       "    'x2': 42,\n",
       "    'y1': 149,\n",
       "    'y2': 237}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003942.jpg',\n",
       "  'height': 360,\n",
       "  'imageset': 'test',\n",
       "  'width': 480},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 89,\n",
       "    'x2': 500,\n",
       "    'y1': 88,\n",
       "    'y2': 200},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 29,\n",
       "    'x2': 68,\n",
       "    'y1': 109,\n",
       "    'y2': 215},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 406,\n",
       "    'x2': 500,\n",
       "    'y1': 146,\n",
       "    'y2': 216},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 139,\n",
       "    'y1': 140,\n",
       "    'y2': 202}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000188.jpg',\n",
       "  'height': 264,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 16,\n",
       "    'x2': 281,\n",
       "    'y1': 29,\n",
       "    'y2': 450},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 10,\n",
       "    'x2': 124,\n",
       "    'y1': 74,\n",
       "    'y2': 302}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008990.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 282},\n",
       " {'bboxes': [{'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 143,\n",
       "    'x2': 349,\n",
       "    'y1': 1,\n",
       "    'y2': 347}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006700.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 51,\n",
       "    'x2': 373,\n",
       "    'y1': 135,\n",
       "    'y2': 248}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002206.jpg',\n",
       "  'height': 325,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 118,\n",
       "    'x2': 390,\n",
       "    'y1': 1,\n",
       "    'y2': 225}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003545.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 117,\n",
       "    'x2': 294,\n",
       "    'y1': 54,\n",
       "    'y2': 188}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008950.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 51,\n",
       "    'x2': 440,\n",
       "    'y1': 3,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001909.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 84,\n",
       "    'x2': 498,\n",
       "    'y1': 116,\n",
       "    'y2': 334},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 397,\n",
       "    'x2': 487,\n",
       "    'y1': 100,\n",
       "    'y2': 222},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 259,\n",
       "    'x2': 397,\n",
       "    'y1': 50,\n",
       "    'y2': 334},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 150,\n",
       "    'x2': 311,\n",
       "    'y1': 57,\n",
       "    'y2': 334}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007019.jpg',\n",
       "  'height': 344,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 40,\n",
       "    'x2': 463,\n",
       "    'y1': 71,\n",
       "    'y2': 321}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000471.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 242,\n",
       "    'x2': 421,\n",
       "    'y1': 64,\n",
       "    'y2': 314},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 37,\n",
       "    'x2': 239,\n",
       "    'y1': 51,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 14,\n",
       "    'x2': 187,\n",
       "    'y1': 322,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 280,\n",
       "    'x2': 487,\n",
       "    'y1': 285,\n",
       "    'y2': 375},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 176,\n",
       "    'x2': 304,\n",
       "    'y1': 52,\n",
       "    'y2': 185},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 119,\n",
       "    'y1': 68,\n",
       "    'y2': 202}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003314.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 191,\n",
       "    'x2': 305,\n",
       "    'y1': 119,\n",
       "    'y2': 296}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009783.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 17,\n",
       "    'x2': 212,\n",
       "    'y1': 277,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 394,\n",
       "    'x2': 500,\n",
       "    'y1': 262,\n",
       "    'y2': 373}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006422.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 392,\n",
       "    'y1': 16,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009442.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 58,\n",
       "    'x2': 380,\n",
       "    'y1': 82,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 500,\n",
       "    'y1': 9,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009646.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 86,\n",
       "    'x2': 425,\n",
       "    'y1': 118,\n",
       "    'y2': 342},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 189,\n",
       "    'x2': 304,\n",
       "    'y1': 30,\n",
       "    'y2': 222}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004177.jpg',\n",
       "  'height': 395,\n",
       "  'imageset': 'test',\n",
       "  'width': 480},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 29,\n",
       "    'x2': 500,\n",
       "    'y1': 40,\n",
       "    'y2': 317}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000785.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 77,\n",
       "    'x2': 500,\n",
       "    'y1': 2,\n",
       "    'y2': 338}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000183.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 6,\n",
       "    'x2': 330,\n",
       "    'y1': 92,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000639.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 385,\n",
       "    'x2': 465,\n",
       "    'y1': 96,\n",
       "    'y2': 360},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 344,\n",
       "    'x2': 450,\n",
       "    'y1': 127,\n",
       "    'y2': 360},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 226,\n",
       "    'x2': 347,\n",
       "    'y1': 229,\n",
       "    'y2': 360},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 305,\n",
       "    'x2': 379,\n",
       "    'y1': 92,\n",
       "    'y2': 196},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 281,\n",
       "    'x2': 382,\n",
       "    'y1': 178,\n",
       "    'y2': 360},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 237,\n",
       "    'x2': 316,\n",
       "    'y1': 146,\n",
       "    'y2': 236},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 227,\n",
       "    'x2': 303,\n",
       "    'y1': 79,\n",
       "    'y2': 178},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 159,\n",
       "    'x2': 227,\n",
       "    'y1': 113,\n",
       "    'y2': 360},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 141,\n",
       "    'x2': 189,\n",
       "    'y1': 90,\n",
       "    'y2': 173},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 80,\n",
       "    'x2': 160,\n",
       "    'y1': 126,\n",
       "    'y2': 360},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 6,\n",
       "    'x2': 85,\n",
       "    'y1': 113,\n",
       "    'y2': 360}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002781.jpg',\n",
       "  'height': 360,\n",
       "  'imageset': 'test',\n",
       "  'width': 480},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 193,\n",
       "    'x2': 346,\n",
       "    'y1': 65,\n",
       "    'y2': 278},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 33,\n",
       "    'x2': 307,\n",
       "    'y1': 33,\n",
       "    'y2': 255},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 140,\n",
       "    'x2': 416,\n",
       "    'y1': 209,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000090.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 170,\n",
       "    'x2': 193,\n",
       "    'y1': 154,\n",
       "    'y2': 247}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006408.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 151,\n",
       "    'x2': 263,\n",
       "    'y1': 110,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 73,\n",
       "    'x2': 178,\n",
       "    'y1': 135,\n",
       "    'y2': 334},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 442,\n",
       "    'x2': 500,\n",
       "    'y1': 124,\n",
       "    'y2': 334}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006857.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 79,\n",
       "    'x2': 280,\n",
       "    'y1': 179,\n",
       "    'y2': 344},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 181,\n",
       "    'x2': 208,\n",
       "    'y1': 231,\n",
       "    'y2': 265},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 288,\n",
       "    'x2': 351,\n",
       "    'y1': 245,\n",
       "    'y2': 362},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 291,\n",
       "    'x2': 342,\n",
       "    'y1': 280,\n",
       "    'y2': 368},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 341,\n",
       "    'x2': 395,\n",
       "    'y1': 275,\n",
       "    'y2': 308},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 443,\n",
       "    'x2': 465,\n",
       "    'y1': 280,\n",
       "    'y2': 294},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 8,\n",
       "    'x2': 24,\n",
       "    'y1': 281,\n",
       "    'y2': 312},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 35,\n",
       "    'y1': 285,\n",
       "    'y2': 308}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004305.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 397,\n",
       "    'x2': 480,\n",
       "    'y1': 183,\n",
       "    'y2': 233}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006974.jpg',\n",
       "  'height': 269,\n",
       "  'imageset': 'test',\n",
       "  'width': 480},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 50,\n",
       "    'x2': 269,\n",
       "    'y1': 9,\n",
       "    'y2': 143},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 194,\n",
       "    'x2': 500,\n",
       "    'y1': 150,\n",
       "    'y2': 365}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004086.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 131,\n",
       "    'x2': 214,\n",
       "    'y1': 146,\n",
       "    'y2': 211},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 211,\n",
       "    'x2': 327,\n",
       "    'y1': 146,\n",
       "    'y2': 209},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 310,\n",
       "    'x2': 424,\n",
       "    'y1': 149,\n",
       "    'y2': 208},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 335,\n",
       "    'x2': 379,\n",
       "    'y1': 127,\n",
       "    'y2': 149},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 366,\n",
       "    'x2': 465,\n",
       "    'y1': 119,\n",
       "    'y2': 163},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 456,\n",
       "    'x2': 500,\n",
       "    'y1': 141,\n",
       "    'y2': 170},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 92,\n",
       "    'x2': 248,\n",
       "    'y1': 215,\n",
       "    'y2': 328},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 129,\n",
       "    'x2': 208,\n",
       "    'y1': 192,\n",
       "    'y2': 303},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 377,\n",
       "    'x2': 500,\n",
       "    'y1': 274,\n",
       "    'y2': 378}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008824.jpg',\n",
       "  'height': 378,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 234,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 105},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 27,\n",
       "    'x2': 289,\n",
       "    'y1': 48,\n",
       "    'y2': 199},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 156,\n",
       "    'x2': 262,\n",
       "    'y1': 19,\n",
       "    'y2': 204}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004800.jpg',\n",
       "  'height': 240,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 46,\n",
       "    'x2': 148,\n",
       "    'y1': 146,\n",
       "    'y2': 179},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 224,\n",
       "    'x2': 375,\n",
       "    'y1': 97,\n",
       "    'y2': 302},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 4,\n",
       "    'x2': 273,\n",
       "    'y1': 90,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 60,\n",
       "    'y1': 102,\n",
       "    'y2': 339}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004378.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 180,\n",
       "    'x2': 454,\n",
       "    'y1': 96,\n",
       "    'y2': 243}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000478.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 111,\n",
       "    'x2': 247,\n",
       "    'y1': 114,\n",
       "    'y2': 480},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 94,\n",
       "    'x2': 273,\n",
       "    'y1': 67,\n",
       "    'y2': 294}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003235.jpg',\n",
       "  'height': 480,\n",
       "  'imageset': 'test',\n",
       "  'width': 335},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 291,\n",
       "    'y1': 107,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006053.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 185,\n",
       "    'x2': 327,\n",
       "    'y1': 142,\n",
       "    'y2': 210}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007698.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 75,\n",
       "    'y1': 88,\n",
       "    'y2': 265},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 91,\n",
       "    'x2': 169,\n",
       "    'y1': 107,\n",
       "    'y2': 371},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 157,\n",
       "    'x2': 211,\n",
       "    'y1': 114,\n",
       "    'y2': 370},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 188,\n",
       "    'x2': 260,\n",
       "    'y1': 96,\n",
       "    'y2': 363},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 236,\n",
       "    'x2': 292,\n",
       "    'y1': 88,\n",
       "    'y2': 361},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 287,\n",
       "    'x2': 352,\n",
       "    'y1': 83,\n",
       "    'y2': 351},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 329,\n",
       "    'x2': 380,\n",
       "    'y1': 90,\n",
       "    'y2': 353},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 376,\n",
       "    'x2': 425,\n",
       "    'y1': 100,\n",
       "    'y2': 342},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 114,\n",
       "    'x2': 157,\n",
       "    'y1': 26,\n",
       "    'y2': 119},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 118,\n",
       "    'x2': 165,\n",
       "    'y1': 64,\n",
       "    'y2': 117},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 153,\n",
       "    'x2': 191,\n",
       "    'y1': 35,\n",
       "    'y2': 111},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 178,\n",
       "    'x2': 239,\n",
       "    'y1': 49,\n",
       "    'y2': 134},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 233,\n",
       "    'x2': 293,\n",
       "    'y1': 47,\n",
       "    'y2': 137},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 274,\n",
       "    'x2': 305,\n",
       "    'y1': 57,\n",
       "    'y2': 129},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 302,\n",
       "    'x2': 340,\n",
       "    'y1': 58,\n",
       "    'y2': 111},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 340,\n",
       "    'x2': 382,\n",
       "    'y1': 45,\n",
       "    'y2': 124}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000784.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 185,\n",
       "    'x2': 404,\n",
       "    'y1': 116,\n",
       "    'y2': 209}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005280.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 339,\n",
       "    'y1': 99,\n",
       "    'y2': 361},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 349,\n",
       "    'x2': 362,\n",
       "    'y1': 142,\n",
       "    'y2': 204},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 365,\n",
       "    'x2': 391,\n",
       "    'y1': 138,\n",
       "    'y2': 202},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 424,\n",
       "    'x2': 451,\n",
       "    'y1': 158,\n",
       "    'y2': 229}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006577.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 21,\n",
       "    'x2': 490,\n",
       "    'y1': 123,\n",
       "    'y2': 336}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005929.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 340,\n",
       "    'x2': 468,\n",
       "    'y1': 193,\n",
       "    'y2': 366},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 75,\n",
       "    'x2': 211,\n",
       "    'y1': 181,\n",
       "    'y2': 309},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 157,\n",
       "    'x2': 229,\n",
       "    'y1': 175,\n",
       "    'y2': 252}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005324.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 54,\n",
       "    'x2': 454,\n",
       "    'y1': 25,\n",
       "    'y2': 315},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 318,\n",
       "    'x2': 489,\n",
       "    'y1': 37,\n",
       "    'y2': 161},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 369,\n",
       "    'x2': 458,\n",
       "    'y1': 1,\n",
       "    'y2': 130}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000364.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 500,\n",
       "    'y1': 2,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009506.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 52,\n",
       "    'x2': 244,\n",
       "    'y1': 272,\n",
       "    'y2': 421}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004431.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 210,\n",
       "    'x2': 236,\n",
       "    'y1': 128,\n",
       "    'y2': 197}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005382.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 95,\n",
       "    'x2': 215,\n",
       "    'y1': 215,\n",
       "    'y2': 291}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003275.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 164,\n",
       "    'x2': 500,\n",
       "    'y1': 8,\n",
       "    'y2': 285},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 500,\n",
       "    'y1': 75,\n",
       "    'y2': 283}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004918.jpg',\n",
       "  'height': 290,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 417,\n",
       "    'y1': 95,\n",
       "    'y2': 235}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003203.jpg',\n",
       "  'height': 335,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 71,\n",
       "    'x2': 322,\n",
       "    'y1': 14,\n",
       "    'y2': 316},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 25,\n",
       "    'x2': 333,\n",
       "    'y1': 158,\n",
       "    'y2': 394}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000819.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 6,\n",
       "    'x2': 351,\n",
       "    'y1': 8,\n",
       "    'y2': 292},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 97,\n",
       "    'y1': 44,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005474.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 368,\n",
       "    'y1': 16,\n",
       "    'y2': 360},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 379,\n",
       "    'x2': 447,\n",
       "    'y1': 203,\n",
       "    'y2': 283}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007975.jpg',\n",
       "  'height': 360,\n",
       "  'imageset': 'test',\n",
       "  'width': 480},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 186,\n",
       "    'x2': 306,\n",
       "    'y1': 186,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 44,\n",
       "    'x2': 500,\n",
       "    'y1': 2,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 13,\n",
       "    'x2': 285,\n",
       "    'y1': 3,\n",
       "    'y2': 188}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008740.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 64,\n",
       "    'x2': 480,\n",
       "    'y1': 60,\n",
       "    'y2': 283},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 243,\n",
       "    'y1': 7,\n",
       "    'y2': 155},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 316,\n",
       "    'x2': 405,\n",
       "    'y1': 26,\n",
       "    'y2': 59},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 419,\n",
       "    'x2': 489,\n",
       "    'y1': 30,\n",
       "    'y2': 68},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 470,\n",
       "    'x2': 500,\n",
       "    'y1': 42,\n",
       "    'y2': 109},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 459,\n",
       "    'x2': 487,\n",
       "    'y1': 48,\n",
       "    'y2': 74},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 141,\n",
       "    'x2': 265,\n",
       "    'y1': 5,\n",
       "    'y2': 60},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 285,\n",
       "    'x2': 341,\n",
       "    'y1': 17,\n",
       "    'y2': 55},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 393,\n",
       "    'x2': 440,\n",
       "    'y1': 25,\n",
       "    'y2': 60},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 266,\n",
       "    'x2': 295,\n",
       "    'y1': 11,\n",
       "    'y2': 50}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007906.jpg',\n",
       "  'height': 378,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 339,\n",
       "    'x2': 390,\n",
       "    'y1': 156,\n",
       "    'y2': 235},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 291,\n",
       "    'x2': 346,\n",
       "    'y1': 171,\n",
       "    'y2': 273},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 224,\n",
       "    'x2': 263,\n",
       "    'y1': 165,\n",
       "    'y2': 185},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 142,\n",
       "    'x2': 193,\n",
       "    'y1': 174,\n",
       "    'y2': 276},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 232,\n",
       "    'x2': 291,\n",
       "    'y1': 192,\n",
       "    'y2': 303},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 139,\n",
       "    'y1': 276,\n",
       "    'y2': 375},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 156,\n",
       "    'x2': 332,\n",
       "    'y1': 182,\n",
       "    'y2': 281}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000084.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 152,\n",
       "    'x2': 259,\n",
       "    'y1': 159,\n",
       "    'y2': 319},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 284,\n",
       "    'x2': 396,\n",
       "    'y1': 163,\n",
       "    'y2': 311},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 377,\n",
       "    'x2': 436,\n",
       "    'y1': 159,\n",
       "    'y2': 290},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 418,\n",
       "    'x2': 461,\n",
       "    'y1': 155,\n",
       "    'y2': 273},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 87,\n",
       "    'x2': 153,\n",
       "    'y1': 146,\n",
       "    'y2': 289},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 106,\n",
       "    'x2': 164,\n",
       "    'y1': 114,\n",
       "    'y2': 286},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 167,\n",
       "    'x2': 204,\n",
       "    'y1': 113,\n",
       "    'y2': 166},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 195,\n",
       "    'x2': 269,\n",
       "    'y1': 114,\n",
       "    'y2': 293},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 373,\n",
       "    'x2': 414,\n",
       "    'y1': 116,\n",
       "    'y2': 200},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 311,\n",
       "    'x2': 383,\n",
       "    'y1': 120,\n",
       "    'y2': 227},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 5,\n",
       "    'x2': 91,\n",
       "    'y1': 39,\n",
       "    'y2': 259},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 217,\n",
       "    'x2': 358,\n",
       "    'y1': 159,\n",
       "    'y2': 287},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 243,\n",
       "    'x2': 323,\n",
       "    'y1': 67,\n",
       "    'y2': 167}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009514.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 369,\n",
       "    'x2': 490,\n",
       "    'y1': 34,\n",
       "    'y2': 87},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 309,\n",
       "    'x2': 489,\n",
       "    'y1': 56,\n",
       "    'y2': 200},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 246,\n",
       "    'x2': 321,\n",
       "    'y1': 33,\n",
       "    'y2': 74},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 185,\n",
       "    'x2': 228,\n",
       "    'y1': 40,\n",
       "    'y2': 63},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 176,\n",
       "    'x2': 188,\n",
       "    'y1': 43,\n",
       "    'y2': 61},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 92,\n",
       "    'x2': 140,\n",
       "    'y1': 34,\n",
       "    'y2': 62},\n",
       "   {'class': 'car', 'difficult': True, 'x1': 20, 'x2': 66, 'y1': 40, 'y2': 62},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 102,\n",
       "    'x2': 141,\n",
       "    'y1': 10,\n",
       "    'y2': 68},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 157,\n",
       "    'x2': 176,\n",
       "    'y1': 20,\n",
       "    'y2': 73},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 61,\n",
       "    'x2': 100,\n",
       "    'y1': 15,\n",
       "    'y2': 122},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 186,\n",
       "    'x2': 293,\n",
       "    'y1': 36,\n",
       "    'y2': 133},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 27,\n",
       "    'x2': 481,\n",
       "    'y1': 66,\n",
       "    'y2': 308}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000687.jpg',\n",
       "  'height': 338,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 450,\n",
       "    'y1': 176,\n",
       "    'y2': 370},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 319,\n",
       "    'y1': 135,\n",
       "    'y2': 320},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 227,\n",
       "    'x2': 500,\n",
       "    'y1': 133,\n",
       "    'y2': 349},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 391,\n",
       "    'x2': 434,\n",
       "    'y1': 238,\n",
       "    'y2': 369}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003309.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 160,\n",
       "    'x2': 488,\n",
       "    'y1': 188,\n",
       "    'y2': 374},\n",
       "   {'class': 'dog',\n",
       "    'difficult': True,\n",
       "    'x1': 59,\n",
       "    'x2': 157,\n",
       "    'y1': 163,\n",
       "    'y2': 270},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 86,\n",
       "    'x2': 479,\n",
       "    'y1': 110,\n",
       "    'y2': 362}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008080.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 474,\n",
       "    'y1': 43,\n",
       "    'y2': 336}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004688.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 148,\n",
       "    'x2': 227,\n",
       "    'y1': 163,\n",
       "    'y2': 200}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004933.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 177,\n",
       "    'x2': 497,\n",
       "    'y1': 37,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 51,\n",
       "    'x2': 200,\n",
       "    'y1': 82,\n",
       "    'y2': 375},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 396,\n",
       "    'x2': 412,\n",
       "    'y1': 15,\n",
       "    'y2': 75},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 373,\n",
       "    'x2': 402,\n",
       "    'y1': 22,\n",
       "    'y2': 82}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009871.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 141,\n",
       "    'x2': 407,\n",
       "    'y1': 160,\n",
       "    'y2': 348},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 184,\n",
       "    'x2': 296,\n",
       "    'y1': 54,\n",
       "    'y2': 278}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005560.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 194,\n",
       "    'x2': 361,\n",
       "    'y1': 78,\n",
       "    'y2': 231}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002258.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 143,\n",
       "    'x2': 428,\n",
       "    'y1': 135,\n",
       "    'y2': 221}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007111.jpg',\n",
       "  'height': 338,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 194,\n",
       "    'x2': 418,\n",
       "    'y1': 71,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009232.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 36,\n",
       "    'x2': 443,\n",
       "    'y1': 53,\n",
       "    'y2': 309}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002829.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 129,\n",
       "    'x2': 495,\n",
       "    'y1': 287,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 259,\n",
       "    'x2': 450,\n",
       "    'y1': 146,\n",
       "    'y2': 294},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 34,\n",
       "    'x2': 172,\n",
       "    'y1': 93,\n",
       "    'y2': 357},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 181,\n",
       "    'x2': 276,\n",
       "    'y1': 107,\n",
       "    'y2': 294},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 82,\n",
       "    'x2': 166,\n",
       "    'y1': 26,\n",
       "    'y2': 194},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 330,\n",
       "    'x2': 358,\n",
       "    'y1': 216,\n",
       "    'y2': 303},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 353,\n",
       "    'x2': 394,\n",
       "    'y1': 194,\n",
       "    'y2': 319}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005226.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 7,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 308}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002556.jpg',\n",
       "  'height': 356,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 17,\n",
       "    'x2': 244,\n",
       "    'y1': 82,\n",
       "    'y2': 495}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001874.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 133,\n",
       "    'x2': 220,\n",
       "    'y1': 82,\n",
       "    'y2': 269},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 86,\n",
       "    'x2': 295,\n",
       "    'y1': 158,\n",
       "    'y2': 307}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009317.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 232,\n",
       "    'x2': 397,\n",
       "    'y1': 186,\n",
       "    'y2': 308}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004522.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 95,\n",
       "    'x2': 203,\n",
       "    'y1': 147,\n",
       "    'y2': 404},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 88,\n",
       "    'x2': 226,\n",
       "    'y1': 85,\n",
       "    'y2': 302}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002909.jpg',\n",
       "  'height': 480,\n",
       "  'imageset': 'test',\n",
       "  'width': 294},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 255,\n",
       "    'x2': 500,\n",
       "    'y1': 86,\n",
       "    'y2': 338},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 273,\n",
       "    'x2': 487,\n",
       "    'y1': 44,\n",
       "    'y2': 338},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 167,\n",
       "    'x2': 277,\n",
       "    'y1': 30,\n",
       "    'y2': 214},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': True,\n",
       "    'x1': 120,\n",
       "    'x2': 196,\n",
       "    'y1': 15,\n",
       "    'y2': 111}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007338.jpg',\n",
       "  'height': 338,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 419,\n",
       "    'y1': 2,\n",
       "    'y2': 332}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000255.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 232,\n",
       "    'y1': 162,\n",
       "    'y2': 342},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 146,\n",
       "    'x2': 435,\n",
       "    'y1': 146,\n",
       "    'y2': 367},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 40,\n",
       "    'x2': 476,\n",
       "    'y1': 150,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 459,\n",
       "    'x2': 500,\n",
       "    'y1': 307,\n",
       "    'y2': 351},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 479,\n",
       "    'x2': 500,\n",
       "    'y1': 258,\n",
       "    'y2': 302}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006686.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 123,\n",
       "    'x2': 421,\n",
       "    'y1': 1,\n",
       "    'y2': 349}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003030.jpg',\n",
       "  'height': 376,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 163,\n",
       "    'x2': 249,\n",
       "    'y1': 78,\n",
       "    'y2': 233},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 229,\n",
       "    'x2': 380,\n",
       "    'y1': 36,\n",
       "    'y2': 239},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 86,\n",
       "    'x2': 246,\n",
       "    'y1': 82,\n",
       "    'y2': 375},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 2,\n",
       "    'x2': 158,\n",
       "    'y1': 50,\n",
       "    'y2': 114},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 407,\n",
       "    'x2': 498,\n",
       "    'y1': 8,\n",
       "    'y2': 280}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004179.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 17,\n",
       "    'x2': 97,\n",
       "    'y1': 147,\n",
       "    'y2': 174},\n",
       "   {'class': 'train',\n",
       "    'difficult': True,\n",
       "    'x1': 156,\n",
       "    'x2': 213,\n",
       "    'y1': 142,\n",
       "    'y2': 169},\n",
       "   {'class': 'train',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 121,\n",
       "    'y1': 198,\n",
       "    'y2': 298},\n",
       "   {'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 171,\n",
       "    'x2': 294,\n",
       "    'y1': 163,\n",
       "    'y2': 237},\n",
       "   {'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 286,\n",
       "    'x2': 344,\n",
       "    'y1': 153,\n",
       "    'y2': 191}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003689.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 121,\n",
       "    'x2': 211,\n",
       "    'y1': 248,\n",
       "    'y2': 319},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 288,\n",
       "    'x2': 396,\n",
       "    'y1': 246,\n",
       "    'y2': 319},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 362,\n",
       "    'x2': 456,\n",
       "    'y1': 249,\n",
       "    'y2': 315},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 141,\n",
       "    'x2': 176,\n",
       "    'y1': 203,\n",
       "    'y2': 317},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 192,\n",
       "    'x2': 235,\n",
       "    'y1': 209,\n",
       "    'y2': 304},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 315,\n",
       "    'x2': 379,\n",
       "    'y1': 209,\n",
       "    'y2': 315},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 383,\n",
       "    'x2': 421,\n",
       "    'y1': 207,\n",
       "    'y2': 314},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 190,\n",
       "    'x2': 259,\n",
       "    'y1': 234,\n",
       "    'y2': 305}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006032.jpg',\n",
       "  'height': 336,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 458,\n",
       "    'y1': 44,\n",
       "    'y2': 354}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006228.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 270,\n",
       "    'x2': 318,\n",
       "    'y1': 194,\n",
       "    'y2': 273},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 321,\n",
       "    'x2': 500,\n",
       "    'y1': 216,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 237,\n",
       "    'x2': 275,\n",
       "    'y1': 195,\n",
       "    'y2': 262},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 210,\n",
       "    'x2': 244,\n",
       "    'y1': 196,\n",
       "    'y2': 260},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 143,\n",
       "    'x2': 214,\n",
       "    'y1': 220,\n",
       "    'y2': 301},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': True,\n",
       "    'x1': 324,\n",
       "    'x2': 468,\n",
       "    'y1': 116,\n",
       "    'y2': 217},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 206,\n",
       "    'x2': 284,\n",
       "    'y1': 223,\n",
       "    'y2': 330}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002777.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 166,\n",
       "    'x2': 305,\n",
       "    'y1': 107,\n",
       "    'y2': 283}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000877.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 328,\n",
       "    'x2': 500,\n",
       "    'y1': 56,\n",
       "    'y2': 265},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 142,\n",
       "    'x2': 323,\n",
       "    'y1': 61,\n",
       "    'y2': 232}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008561.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 144,\n",
       "    'x2': 274,\n",
       "    'y1': 25,\n",
       "    'y2': 443}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004909.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 124,\n",
       "    'x2': 494,\n",
       "    'y1': 24,\n",
       "    'y2': 100},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 277,\n",
       "    'y1': 44,\n",
       "    'y2': 285}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003198.jpg',\n",
       "  'height': 285,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 38,\n",
       "    'x2': 72,\n",
       "    'y1': 287,\n",
       "    'y2': 304},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 76,\n",
       "    'x2': 104,\n",
       "    'y1': 284,\n",
       "    'y2': 301},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 189,\n",
       "    'x2': 212,\n",
       "    'y1': 285,\n",
       "    'y2': 301},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 346,\n",
       "    'x2': 376,\n",
       "    'y1': 292,\n",
       "    'y2': 318},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 309,\n",
       "    'x2': 358,\n",
       "    'y1': 294,\n",
       "    'y2': 325},\n",
       "   {'class': 'bus',\n",
       "    'difficult': True,\n",
       "    'x1': 142,\n",
       "    'x2': 181,\n",
       "    'y1': 270,\n",
       "    'y2': 301},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 256,\n",
       "    'x2': 266,\n",
       "    'y1': 284,\n",
       "    'y2': 301},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 444,\n",
       "    'x2': 459,\n",
       "    'y1': 294,\n",
       "    'y2': 315},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': True,\n",
       "    'x1': 440,\n",
       "    'x2': 470,\n",
       "    'y1': 304,\n",
       "    'y2': 315}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008464.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 36,\n",
       "    'x2': 301,\n",
       "    'y1': 221,\n",
       "    'y2': 430}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003130.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 70,\n",
       "    'x2': 458,\n",
       "    'y1': 91,\n",
       "    'y2': 266}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001796.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 127,\n",
       "    'x2': 164,\n",
       "    'y1': 134,\n",
       "    'y2': 201},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 212,\n",
       "    'x2': 248,\n",
       "    'y1': 126,\n",
       "    'y2': 198}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009893.jpg',\n",
       "  'height': 326,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 214,\n",
       "    'x2': 231,\n",
       "    'y1': 156,\n",
       "    'y2': 186},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 149,\n",
       "    'x2': 189,\n",
       "    'y1': 196,\n",
       "    'y2': 297},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 231,\n",
       "    'x2': 413,\n",
       "    'y1': 155,\n",
       "    'y2': 227}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000634.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 367,\n",
       "    'x2': 426,\n",
       "    'y1': 1,\n",
       "    'y2': 149},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 187,\n",
       "    'y1': 2,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008778.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 41,\n",
       "    'x2': 453,\n",
       "    'y1': 104,\n",
       "    'y2': 430},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 351,\n",
       "    'y1': 56,\n",
       "    'y2': 183},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 178,\n",
       "    'x2': 303,\n",
       "    'y1': 29,\n",
       "    'y2': 235},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 272,\n",
       "    'x2': 407,\n",
       "    'y1': 145,\n",
       "    'y2': 299}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003677.jpg',\n",
       "  'height': 447,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 235,\n",
       "    'x2': 410,\n",
       "    'y1': 172,\n",
       "    'y2': 317},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 291,\n",
       "    'x2': 405,\n",
       "    'y1': 111,\n",
       "    'y2': 286}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007646.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 21,\n",
       "    'x2': 228,\n",
       "    'y1': 109,\n",
       "    'y2': 372},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 290,\n",
       "    'x2': 499,\n",
       "    'y1': 100,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 186,\n",
       "    'x2': 362,\n",
       "    'y1': 61,\n",
       "    'y2': 373}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007917.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 443,\n",
       "    'y1': 153,\n",
       "    'y2': 335},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 243,\n",
       "    'x2': 489,\n",
       "    'y1': 191,\n",
       "    'y2': 297},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 121,\n",
       "    'x2': 316,\n",
       "    'y1': 132,\n",
       "    'y2': 190}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007026.jpg',\n",
       "  'height': 335,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 91,\n",
       "    'x2': 341,\n",
       "    'y1': 120,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 54,\n",
       "    'x2': 121,\n",
       "    'y1': 110,\n",
       "    'y2': 209},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 47,\n",
       "    'x2': 107,\n",
       "    'y1': 137,\n",
       "    'y2': 241},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 50,\n",
       "    'x2': 185,\n",
       "    'y1': 233,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 337,\n",
       "    'x2': 428,\n",
       "    'y1': 124,\n",
       "    'y2': 225},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 342,\n",
       "    'x2': 483,\n",
       "    'y1': 143,\n",
       "    'y2': 363},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 450,\n",
       "    'x2': 500,\n",
       "    'y1': 250,\n",
       "    'y2': 375},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 413,\n",
       "    'x2': 487,\n",
       "    'y1': 79,\n",
       "    'y2': 144},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 281,\n",
       "    'x2': 404,\n",
       "    'y1': 2,\n",
       "    'y2': 341},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 107,\n",
       "    'x2': 249,\n",
       "    'y1': 135,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003323.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 260,\n",
       "    'x2': 428,\n",
       "    'y1': 55,\n",
       "    'y2': 227},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 61,\n",
       "    'x2': 194,\n",
       "    'y1': 81,\n",
       "    'y2': 232}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007888.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 274,\n",
       "    'x2': 341,\n",
       "    'y1': 199,\n",
       "    'y2': 326},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 250,\n",
       "    'x2': 313,\n",
       "    'y1': 210,\n",
       "    'y2': 284},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 115,\n",
       "    'x2': 130,\n",
       "    'y1': 40,\n",
       "    'y2': 79},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 87,\n",
       "    'x2': 102,\n",
       "    'y1': 38,\n",
       "    'y2': 81}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009014.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 121,\n",
       "    'x2': 451,\n",
       "    'y1': 64,\n",
       "    'y2': 265},\n",
       "   {'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 180,\n",
       "    'y1': 110,\n",
       "    'y2': 217}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003900.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 169,\n",
       "    'x2': 354,\n",
       "    'y1': 46,\n",
       "    'y2': 189},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 146,\n",
       "    'y1': 98,\n",
       "    'y2': 303},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 167,\n",
       "    'x2': 455,\n",
       "    'y1': 188,\n",
       "    'y2': 373}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001551.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 10,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006246.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': True,\n",
       "    'x1': 233,\n",
       "    'x2': 265,\n",
       "    'y1': 392,\n",
       "    'y2': 422},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 227,\n",
       "    'x2': 251,\n",
       "    'y1': 420,\n",
       "    'y2': 440},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 246,\n",
       "    'x2': 265,\n",
       "    'y1': 415,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 193,\n",
       "    'x2': 239,\n",
       "    'y1': 400,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 85,\n",
       "    'x2': 137,\n",
       "    'y1': 405,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 37,\n",
       "    'x2': 87,\n",
       "    'y1': 409,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 35,\n",
       "    'y1': 397,\n",
       "    'y2': 496},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 22,\n",
       "    'x2': 32,\n",
       "    'y1': 419,\n",
       "    'y2': 442},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 141,\n",
       "    'x2': 150,\n",
       "    'y1': 419,\n",
       "    'y2': 436},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 135,\n",
       "    'x2': 140,\n",
       "    'y1': 419,\n",
       "    'y2': 435}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005666.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 265},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 57,\n",
       "    'x2': 287,\n",
       "    'y1': 143,\n",
       "    'y2': 268},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 325,\n",
       "    'x2': 490,\n",
       "    'y1': 145,\n",
       "    'y2': 254},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': True,\n",
       "    'x1': 224,\n",
       "    'x2': 324,\n",
       "    'y1': 108,\n",
       "    'y2': 196},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 54,\n",
       "    'y1': 96,\n",
       "    'y2': 190},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 283,\n",
       "    'x2': 394,\n",
       "    'y1': 103,\n",
       "    'y2': 243},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 40,\n",
       "    'x2': 143,\n",
       "    'y1': 116,\n",
       "    'y2': 261},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 194,\n",
       "    'x2': 267,\n",
       "    'y1': 84,\n",
       "    'y2': 193}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006920.jpg',\n",
       "  'height': 323,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 57,\n",
       "    'x2': 309,\n",
       "    'y1': 284,\n",
       "    'y2': 496},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 114,\n",
       "    'x2': 223,\n",
       "    'y1': 174,\n",
       "    'y2': 377}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008574.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 43,\n",
       "    'x2': 437,\n",
       "    'y1': 17,\n",
       "    'y2': 263},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 82,\n",
       "    'x2': 109,\n",
       "    'y1': 33,\n",
       "    'y2': 103}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009595.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 89,\n",
       "    'x2': 270,\n",
       "    'y1': 170,\n",
       "    'y2': 361},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 128,\n",
       "    'x2': 257,\n",
       "    'y1': 147,\n",
       "    'y2': 224},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 191,\n",
       "    'x2': 286,\n",
       "    'y1': 200,\n",
       "    'y2': 282}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006705.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 441,\n",
       "    'x2': 496,\n",
       "    'y1': 175,\n",
       "    'y2': 227},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 321,\n",
       "    'x2': 387,\n",
       "    'y1': 162,\n",
       "    'y2': 220},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 316,\n",
       "    'x2': 369,\n",
       "    'y1': 211,\n",
       "    'y2': 271},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 323,\n",
       "    'x2': 369,\n",
       "    'y1': 163,\n",
       "    'y2': 245},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 366,\n",
       "    'x2': 422,\n",
       "    'y1': 160,\n",
       "    'y2': 223},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 196,\n",
       "    'x2': 274,\n",
       "    'y1': 153,\n",
       "    'y2': 246},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 74,\n",
       "    'x2': 252,\n",
       "    'y1': 131,\n",
       "    'y2': 375},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': True,\n",
       "    'x1': 33,\n",
       "    'x2': 260,\n",
       "    'y1': 276,\n",
       "    'y2': 375},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 366,\n",
       "    'x2': 500,\n",
       "    'y1': 156,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005041.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 111,\n",
       "    'y1': 73,\n",
       "    'y2': 232}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009097.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 373},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 12,\n",
       "    'x2': 253,\n",
       "    'y1': 386,\n",
       "    'y2': 497},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 255,\n",
       "    'x2': 320,\n",
       "    'y1': 370,\n",
       "    'y2': 470}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009635.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 335},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 43,\n",
       "    'x2': 355,\n",
       "    'y1': 87,\n",
       "    'y2': 280},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 84,\n",
       "    'x2': 213,\n",
       "    'y1': 41,\n",
       "    'y2': 304}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009890.jpg',\n",
       "  'height': 349,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 276,\n",
       "    'y1': 127,\n",
       "    'y2': 332},\n",
       "   {'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 164,\n",
       "    'x2': 387,\n",
       "    'y1': 75,\n",
       "    'y2': 178},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 414,\n",
       "    'x2': 500,\n",
       "    'y1': 135,\n",
       "    'y2': 196},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': True,\n",
       "    'x1': 389,\n",
       "    'x2': 414,\n",
       "    'y1': 145,\n",
       "    'y2': 164},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 345,\n",
       "    'x2': 370,\n",
       "    'y1': 127,\n",
       "    'y2': 192},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 208,\n",
       "    'x2': 264,\n",
       "    'y1': 127,\n",
       "    'y2': 328},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 244,\n",
       "    'x2': 295,\n",
       "    'y1': 120,\n",
       "    'y2': 303}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002242.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 100,\n",
       "    'x2': 240,\n",
       "    'y1': 100,\n",
       "    'y2': 270},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 51,\n",
       "    'x2': 264,\n",
       "    'y1': 128,\n",
       "    'y2': 270}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009592.jpg',\n",
       "  'height': 270,\n",
       "  'imageset': 'test',\n",
       "  'width': 360},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 100,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006820.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 73,\n",
       "    'x2': 375,\n",
       "    'y1': 165,\n",
       "    'y2': 413},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 22,\n",
       "    'x2': 303,\n",
       "    'y1': 89,\n",
       "    'y2': 268}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002319.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 413,\n",
       "    'y1': 137,\n",
       "    'y2': 317},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 427,\n",
       "    'x2': 468,\n",
       "    'y1': 116,\n",
       "    'y2': 234},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 465,\n",
       "    'x2': 489,\n",
       "    'y1': 90,\n",
       "    'y2': 162},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 415,\n",
       "    'x2': 443,\n",
       "    'y1': 91,\n",
       "    'y2': 173},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 245,\n",
       "    'x2': 292,\n",
       "    'y1': 106,\n",
       "    'y2': 139}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001923.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 261,\n",
       "    'x2': 500,\n",
       "    'y1': 69,\n",
       "    'y2': 234},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 203,\n",
       "    'x2': 340,\n",
       "    'y1': 118,\n",
       "    'y2': 351},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 23,\n",
       "    'y1': 180,\n",
       "    'y2': 306},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 14,\n",
       "    'x2': 178,\n",
       "    'y1': 192,\n",
       "    'y2': 280}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005746.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 17,\n",
       "    'x2': 333,\n",
       "    'y1': 30,\n",
       "    'y2': 443}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001054.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 50,\n",
       "    'x2': 386,\n",
       "    'y1': 104,\n",
       "    'y2': 353}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005207.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 386},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 50,\n",
       "    'x2': 473,\n",
       "    'y1': 21,\n",
       "    'y2': 327}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006278.jpg',\n",
       "  'height': 371,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 496,\n",
       "    'y1': 119,\n",
       "    'y2': 268},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': True,\n",
       "    'x1': 437,\n",
       "    'x2': 490,\n",
       "    'y1': 234,\n",
       "    'y2': 251}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003268.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 226,\n",
       "    'x2': 301,\n",
       "    'y1': 122,\n",
       "    'y2': 292}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004795.jpg',\n",
       "  'height': 360,\n",
       "  'imageset': 'test',\n",
       "  'width': 480},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 289,\n",
       "    'y1': 4,\n",
       "    'y2': 294}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008860.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 290,\n",
       "    'y1': 183,\n",
       "    'y2': 443}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000703.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 355},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 274,\n",
       "    'x2': 372,\n",
       "    'y1': 184,\n",
       "    'y2': 265},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 297,\n",
       "    'x2': 330,\n",
       "    'y1': 167,\n",
       "    'y2': 229},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 155,\n",
       "    'x2': 253,\n",
       "    'y1': 91,\n",
       "    'y2': 268},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 83,\n",
       "    'x2': 288,\n",
       "    'y1': 145,\n",
       "    'y2': 429}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003734.jpg',\n",
       "  'height': 480,\n",
       "  'imageset': 'test',\n",
       "  'width': 379},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 158,\n",
       "    'y1': 245,\n",
       "    'y2': 375},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 472,\n",
       "    'x2': 500,\n",
       "    'y1': 189,\n",
       "    'y2': 267},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 399,\n",
       "    'x2': 460,\n",
       "    'y1': 250,\n",
       "    'y2': 304},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 412,\n",
       "    'x2': 500,\n",
       "    'y1': 305,\n",
       "    'y2': 375},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 415,\n",
       "    'x2': 500,\n",
       "    'y1': 272,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009521.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 108,\n",
       "    'x2': 286,\n",
       "    'y1': 117,\n",
       "    'y2': 234},\n",
       "   {'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 230,\n",
       "    'x2': 347,\n",
       "    'y1': 50,\n",
       "    'y2': 137}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002926.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 64,\n",
       "    'x2': 319,\n",
       "    'y1': 14,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008021.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 105,\n",
       "    'x2': 500,\n",
       "    'y1': 213,\n",
       "    'y2': 375},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 133,\n",
       "    'x2': 362,\n",
       "    'y1': 181,\n",
       "    'y2': 298},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 300,\n",
       "    'x2': 440,\n",
       "    'y1': 177,\n",
       "    'y2': 245},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 110,\n",
       "    'x2': 280,\n",
       "    'y1': 148,\n",
       "    'y2': 216},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 55,\n",
       "    'x2': 111,\n",
       "    'y1': 96,\n",
       "    'y2': 252},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 88,\n",
       "    'x2': 125,\n",
       "    'y1': 90,\n",
       "    'y2': 230}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005316.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 15,\n",
       "    'x2': 479,\n",
       "    'y1': 68,\n",
       "    'y2': 293}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008714.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 193,\n",
       "    'y1': 81,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 212,\n",
       "    'x2': 298,\n",
       "    'y1': 68,\n",
       "    'y2': 192},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 353,\n",
       "    'x2': 426,\n",
       "    'y1': 70,\n",
       "    'y2': 184},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 374,\n",
       "    'x2': 500,\n",
       "    'y1': 111,\n",
       "    'y2': 332},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 421,\n",
       "    'x2': 498,\n",
       "    'y1': 2,\n",
       "    'y2': 150},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 115,\n",
       "    'x2': 213,\n",
       "    'y1': 67,\n",
       "    'y2': 213},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 114,\n",
       "    'x2': 429,\n",
       "    'y1': 163,\n",
       "    'y2': 330},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 279,\n",
       "    'x2': 332,\n",
       "    'y1': 53,\n",
       "    'y2': 117}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006771.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 73,\n",
       "    'x2': 499,\n",
       "    'y1': 1,\n",
       "    'y2': 319}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006186.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 202,\n",
       "    'x2': 464,\n",
       "    'y1': 109,\n",
       "    'y2': 279},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 274,\n",
       "    'x2': 418,\n",
       "    'y1': 70,\n",
       "    'y2': 268}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002806.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 22,\n",
       "    'x2': 482,\n",
       "    'y1': 149,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 448,\n",
       "    'x2': 500,\n",
       "    'y1': 255,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 66,\n",
       "    'y1': 253,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 115,\n",
       "    'x2': 146,\n",
       "    'y1': 168,\n",
       "    'y2': 219},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 131,\n",
       "    'x2': 157,\n",
       "    'y1': 150,\n",
       "    'y2': 199},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 306,\n",
       "    'x2': 342,\n",
       "    'y1': 107,\n",
       "    'y2': 153},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 226,\n",
       "    'x2': 271,\n",
       "    'y1': 112,\n",
       "    'y2': 146},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 86,\n",
       "    'x2': 103,\n",
       "    'y1': 160,\n",
       "    'y2': 212},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 378,\n",
       "    'x2': 500,\n",
       "    'y1': 124,\n",
       "    'y2': 303},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 290,\n",
       "    'x2': 429,\n",
       "    'y1': 85,\n",
       "    'y2': 223},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 332,\n",
       "    'x2': 383,\n",
       "    'y1': 84,\n",
       "    'y2': 175},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 220,\n",
       "    'x2': 286,\n",
       "    'y1': 46,\n",
       "    'y2': 146},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 164,\n",
       "    'y1': 115,\n",
       "    'y2': 322},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 101,\n",
       "    'x2': 173,\n",
       "    'y1': 107,\n",
       "    'y2': 213},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 145,\n",
       "    'x2': 206,\n",
       "    'y1': 85,\n",
       "    'y2': 166},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 90,\n",
       "    'x2': 134,\n",
       "    'y1': 46,\n",
       "    'y2': 140}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006546.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 420,\n",
       "    'x2': 473,\n",
       "    'y1': 98,\n",
       "    'y2': 226},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 453,\n",
       "    'x2': 498,\n",
       "    'y1': 71,\n",
       "    'y2': 184},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 498,\n",
       "    'y1': 54,\n",
       "    'y2': 369}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001429.jpg',\n",
       "  'height': 372,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 340,\n",
       "    'x2': 420,\n",
       "    'y1': 34,\n",
       "    'y2': 156},\n",
       "   {'class': 'cat',\n",
       "    'difficult': True,\n",
       "    'x1': 55,\n",
       "    'x2': 85,\n",
       "    'y1': 141,\n",
       "    'y2': 178}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003591.jpg',\n",
       "  'height': 181,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 10,\n",
       "    'x2': 484,\n",
       "    'y1': 46,\n",
       "    'y2': 238}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003574.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 278,\n",
       "    'x2': 369,\n",
       "    'y1': 171,\n",
       "    'y2': 283},\n",
       "   {'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 159,\n",
       "    'x2': 219,\n",
       "    'y1': 174,\n",
       "    'y2': 262},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 140,\n",
       "    'x2': 189,\n",
       "    'y1': 89,\n",
       "    'y2': 175},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 170,\n",
       "    'x2': 190,\n",
       "    'y1': 111,\n",
       "    'y2': 167},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 191,\n",
       "    'x2': 217,\n",
       "    'y1': 105,\n",
       "    'y2': 181}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006378.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 6,\n",
       "    'x2': 326,\n",
       "    'y1': 73,\n",
       "    'y2': 471},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 54,\n",
       "    'x2': 82,\n",
       "    'y1': 210,\n",
       "    'y2': 277},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 29,\n",
       "    'x2': 39,\n",
       "    'y1': 215,\n",
       "    'y2': 249},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 16,\n",
       "    'x2': 31,\n",
       "    'y1': 211,\n",
       "    'y2': 250}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002246.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 61,\n",
       "    'x2': 136,\n",
       "    'y1': 160,\n",
       "    'y2': 307},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 17,\n",
       "    'x2': 104,\n",
       "    'y1': 96,\n",
       "    'y2': 307}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009263.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 140,\n",
       "    'x2': 439,\n",
       "    'y1': 95,\n",
       "    'y2': 245}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008305.jpg',\n",
       "  'height': 406,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': True,\n",
       "    'x1': 16,\n",
       "    'x2': 50,\n",
       "    'y1': 109,\n",
       "    'y2': 173},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': True,\n",
       "    'x1': 261,\n",
       "    'x2': 284,\n",
       "    'y1': 118,\n",
       "    'y2': 155},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': True,\n",
       "    'x1': 223,\n",
       "    'x2': 263,\n",
       "    'y1': 197,\n",
       "    'y2': 260},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 267,\n",
       "    'x2': 367,\n",
       "    'y1': 136,\n",
       "    'y2': 270},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': True,\n",
       "    'x1': 336,\n",
       "    'x2': 423,\n",
       "    'y1': 216,\n",
       "    'y2': 301},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 375,\n",
       "    'x2': 408,\n",
       "    'y1': 85,\n",
       "    'y2': 143},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 353,\n",
       "    'x2': 373,\n",
       "    'y1': 82,\n",
       "    'y2': 136},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 338,\n",
       "    'x2': 358,\n",
       "    'y1': 90,\n",
       "    'y2': 114},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 200,\n",
       "    'x2': 237,\n",
       "    'y1': 56,\n",
       "    'y2': 128},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 19,\n",
       "    'x2': 270,\n",
       "    'y1': 8,\n",
       "    'y2': 334},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 372,\n",
       "    'x2': 476,\n",
       "    'y1': 63,\n",
       "    'y2': 334},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 287,\n",
       "    'x2': 356,\n",
       "    'y1': 63,\n",
       "    'y2': 192},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 458,\n",
       "    'x2': 496,\n",
       "    'y1': 79,\n",
       "    'y2': 128},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 168,\n",
       "    'x2': 196,\n",
       "    'y1': 67,\n",
       "    'y2': 95}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001307.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 342,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 158},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 276,\n",
       "    'x2': 500,\n",
       "    'y1': 151,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 384,\n",
       "    'x2': 492,\n",
       "    'y1': 37,\n",
       "    'y2': 92}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007583.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 451,\n",
       "    'x2': 475,\n",
       "    'y1': 195,\n",
       "    'y2': 276},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 96,\n",
       "    'x2': 224,\n",
       "    'y1': 124,\n",
       "    'y2': 253},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 224,\n",
       "    'x2': 356,\n",
       "    'y1': 120,\n",
       "    'y2': 256},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 351,\n",
       "    'x2': 378,\n",
       "    'y1': 43,\n",
       "    'y2': 93},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 132,\n",
       "    'x2': 196,\n",
       "    'y1': 143,\n",
       "    'y2': 209},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 122,\n",
       "    'x2': 186,\n",
       "    'y1': 153,\n",
       "    'y2': 213}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002951.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 59,\n",
       "    'x2': 388,\n",
       "    'y1': 105,\n",
       "    'y2': 318},\n",
       "   {'class': 'horse',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 113,\n",
       "    'y1': 179,\n",
       "    'y2': 318},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 178,\n",
       "    'x2': 287,\n",
       "    'y1': 4,\n",
       "    'y2': 318},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 459,\n",
       "    'x2': 480,\n",
       "    'y1': 181,\n",
       "    'y2': 292}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003583.jpg',\n",
       "  'height': 318,\n",
       "  'imageset': 'test',\n",
       "  'width': 480},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 220,\n",
       "    'x2': 442,\n",
       "    'y1': 114,\n",
       "    'y2': 269},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 304,\n",
       "    'x2': 416,\n",
       "    'y1': 93,\n",
       "    'y2': 254}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005133.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 169,\n",
       "    'x2': 375,\n",
       "    'y1': 377,\n",
       "    'y2': 500},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 73,\n",
       "    'y1': 301,\n",
       "    'y2': 423},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 93,\n",
       "    'x2': 189,\n",
       "    'y1': 289,\n",
       "    'y2': 419},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 84,\n",
       "    'x2': 135,\n",
       "    'y1': 250,\n",
       "    'y2': 319},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 22,\n",
       "    'x2': 94,\n",
       "    'y1': 246,\n",
       "    'y2': 327},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 23,\n",
       "    'y1': 224,\n",
       "    'y2': 285}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005180.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 152,\n",
       "    'x2': 499,\n",
       "    'y1': 229,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 371,\n",
       "    'x2': 500,\n",
       "    'y1': 98,\n",
       "    'y2': 301},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 297,\n",
       "    'x2': 426,\n",
       "    'y1': 113,\n",
       "    'y2': 266},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 172,\n",
       "    'x2': 291,\n",
       "    'y1': 110,\n",
       "    'y2': 231},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 149,\n",
       "    'y1': 117,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 33,\n",
       "    'y1': 126,\n",
       "    'y2': 212}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004740.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 43,\n",
       "    'x2': 192,\n",
       "    'y1': 126,\n",
       "    'y2': 334},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 150,\n",
       "    'x2': 321,\n",
       "    'y1': 94,\n",
       "    'y2': 334},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 246,\n",
       "    'x2': 418,\n",
       "    'y1': 60,\n",
       "    'y2': 334},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 321,\n",
       "    'x2': 500,\n",
       "    'y1': 21,\n",
       "    'y2': 322}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003172.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 302,\n",
       "    'x2': 396,\n",
       "    'y1': 241,\n",
       "    'y2': 309},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 322,\n",
       "    'x2': 359,\n",
       "    'y1': 210,\n",
       "    'y2': 286},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 128,\n",
       "    'x2': 160,\n",
       "    'y1': 223,\n",
       "    'y2': 322},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 193,\n",
       "    'x2': 231,\n",
       "    'y1': 269,\n",
       "    'y2': 362},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 242,\n",
       "    'x2': 274,\n",
       "    'y1': 260,\n",
       "    'y2': 360},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 401,\n",
       "    'x2': 439,\n",
       "    'y1': 304,\n",
       "    'y2': 374},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 455,\n",
       "    'x2': 489,\n",
       "    'y1': 300,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005931.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 292,\n",
       "    'x2': 499,\n",
       "    'y1': 181,\n",
       "    'y2': 288},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 379,\n",
       "    'x2': 500,\n",
       "    'y1': 175,\n",
       "    'y2': 229},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 164,\n",
       "    'x2': 263,\n",
       "    'y1': 178,\n",
       "    'y2': 242},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 177,\n",
       "    'y1': 172,\n",
       "    'y2': 252},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 321,\n",
       "    'x2': 367,\n",
       "    'y1': 138,\n",
       "    'y2': 194},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 272,\n",
       "    'x2': 324,\n",
       "    'y1': 138,\n",
       "    'y2': 269},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 264,\n",
       "    'x2': 291,\n",
       "    'y1': 147,\n",
       "    'y2': 266},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 219,\n",
       "    'x2': 266,\n",
       "    'y1': 153,\n",
       "    'y2': 281},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 104,\n",
       "    'x2': 146,\n",
       "    'y1': 158,\n",
       "    'y2': 295},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 61,\n",
       "    'x2': 111,\n",
       "    'y1': 149,\n",
       "    'y2': 292},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 13,\n",
       "    'x2': 47,\n",
       "    'y1': 144,\n",
       "    'y2': 288}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000693.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 212,\n",
       "    'x2': 318,\n",
       "    'y1': 28,\n",
       "    'y2': 136},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 25,\n",
       "    'x2': 374,\n",
       "    'y1': 117,\n",
       "    'y2': 471},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 318,\n",
       "    'x2': 368,\n",
       "    'y1': 1,\n",
       "    'y2': 43}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002240.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 82,\n",
       "    'x2': 383,\n",
       "    'y1': 68,\n",
       "    'y2': 270}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000199.jpg',\n",
       "  'height': 329,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 114,\n",
       "    'x2': 249,\n",
       "    'y1': 88,\n",
       "    'y2': 256}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000803.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 331,\n",
       "    'y1': 1,\n",
       "    'y2': 390},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 101,\n",
       "    'x2': 250,\n",
       "    'y1': 234,\n",
       "    'y2': 355}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006048.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 332},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 500,\n",
       "    'y1': 2,\n",
       "    'y2': 356}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008420.jpg',\n",
       "  'height': 357,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 175,\n",
       "    'x2': 260,\n",
       "    'y1': 158,\n",
       "    'y2': 321},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 250,\n",
       "    'x2': 373,\n",
       "    'y1': 152,\n",
       "    'y2': 325}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006557.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 91,\n",
       "    'x2': 253,\n",
       "    'y1': 172,\n",
       "    'y2': 480},\n",
       "   {'class': 'horse',\n",
       "    'difficult': True,\n",
       "    'x1': 255,\n",
       "    'x2': 318,\n",
       "    'y1': 307,\n",
       "    'y2': 390},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 302,\n",
       "    'x2': 318,\n",
       "    'y1': 264,\n",
       "    'y2': 318},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 118,\n",
       "    'x2': 242,\n",
       "    'y1': 99,\n",
       "    'y2': 304}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007620.jpg',\n",
       "  'height': 480,\n",
       "  'imageset': 'test',\n",
       "  'width': 318},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 412,\n",
       "    'y1': 22,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008149.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 85,\n",
       "    'x2': 478,\n",
       "    'y1': 82,\n",
       "    'y2': 482}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008972.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 481},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 124,\n",
       "    'x2': 186,\n",
       "    'y1': 91,\n",
       "    'y2': 213},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 164,\n",
       "    'x2': 322,\n",
       "    'y1': 20,\n",
       "    'y2': 326}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007874.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 141,\n",
       "    'x2': 337,\n",
       "    'y1': 2,\n",
       "    'y2': 224}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002131.jpg',\n",
       "  'height': 456,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 64,\n",
       "    'x2': 322,\n",
       "    'y1': 120,\n",
       "    'y2': 417}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001567.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 197,\n",
       "    'x2': 372,\n",
       "    'y1': 122,\n",
       "    'y2': 319}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007716.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 101,\n",
       "    'x2': 121,\n",
       "    'y1': 141,\n",
       "    'y2': 171},\n",
       "   {'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 105,\n",
       "    'x2': 176,\n",
       "    'y1': 162,\n",
       "    'y2': 190},\n",
       "   {'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 167,\n",
       "    'x2': 247,\n",
       "    'y1': 145,\n",
       "    'y2': 189}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000350.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 69,\n",
       "    'x2': 107,\n",
       "    'y1': 1,\n",
       "    'y2': 98},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 98,\n",
       "    'x2': 168,\n",
       "    'y1': 1,\n",
       "    'y2': 202},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 43,\n",
       "    'y1': 2,\n",
       "    'y2': 199},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 160,\n",
       "    'x2': 203,\n",
       "    'y1': 4,\n",
       "    'y2': 82},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 192,\n",
       "    'x2': 257,\n",
       "    'y1': 1,\n",
       "    'y2': 69},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 386,\n",
       "    'x2': 438,\n",
       "    'y1': 2,\n",
       "    'y2': 78},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 398,\n",
       "    'x2': 500,\n",
       "    'y1': 2,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 424,\n",
       "    'x2': 482,\n",
       "    'y1': 27,\n",
       "    'y2': 83},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 111,\n",
       "    'x2': 437,\n",
       "    'y1': 42,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009139.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 43,\n",
       "    'x2': 150,\n",
       "    'y1': 177,\n",
       "    'y2': 294},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 135,\n",
       "    'x2': 204,\n",
       "    'y1': 118,\n",
       "    'y2': 257},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 115,\n",
       "    'x2': 148,\n",
       "    'y1': 146,\n",
       "    'y2': 187}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003676.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 288,\n",
       "    'x2': 497,\n",
       "    'y1': 4,\n",
       "    'y2': 213},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 302,\n",
       "    'x2': 335,\n",
       "    'y1': 19,\n",
       "    'y2': 67},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 59,\n",
       "    'x2': 246,\n",
       "    'y1': 96,\n",
       "    'y2': 251}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003113.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 394,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 331},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 278,\n",
       "    'x2': 422,\n",
       "    'y1': 2,\n",
       "    'y2': 332},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 131,\n",
       "    'x2': 330,\n",
       "    'y1': 62,\n",
       "    'y2': 332},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 90,\n",
       "    'x2': 308,\n",
       "    'y1': 2,\n",
       "    'y2': 332}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003903.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 53,\n",
       "    'x2': 204,\n",
       "    'y1': 4,\n",
       "    'y2': 236},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 31,\n",
       "    'x2': 138,\n",
       "    'y1': 42,\n",
       "    'y2': 241}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006566.jpg',\n",
       "  'height': 298,\n",
       "  'imageset': 'test',\n",
       "  'width': 207},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 285,\n",
       "    'y1': 99,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007418.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 332},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 23,\n",
       "    'x2': 243,\n",
       "    'y1': 22,\n",
       "    'y2': 331},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 308,\n",
       "    'x2': 376,\n",
       "    'y1': 224,\n",
       "    'y2': 314}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000901.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 62,\n",
       "    'x2': 500,\n",
       "    'y1': 71,\n",
       "    'y2': 328}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000724.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 245,\n",
       "    'x2': 375,\n",
       "    'y1': 171,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 191,\n",
       "    'x2': 333,\n",
       "    'y1': 191,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 63,\n",
       "    'x2': 234,\n",
       "    'y1': 157,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004739.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 203,\n",
       "    'x2': 436,\n",
       "    'y1': 87,\n",
       "    'y2': 230}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001873.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 188,\n",
       "    'x2': 259,\n",
       "    'y1': 112,\n",
       "    'y2': 406},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 72,\n",
       "    'x2': 225,\n",
       "    'y1': 37,\n",
       "    'y2': 478}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007769.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 51,\n",
       "    'x2': 496,\n",
       "    'y1': 87,\n",
       "    'y2': 229}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007096.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 4,\n",
       "    'x2': 129,\n",
       "    'y1': 230,\n",
       "    'y2': 353}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009725.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 64,\n",
       "    'x2': 493,\n",
       "    'y1': 8,\n",
       "    'y2': 368}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001655.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 80,\n",
       "    'x2': 109,\n",
       "    'y1': 309,\n",
       "    'y2': 332},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 143,\n",
       "    'x2': 169,\n",
       "    'y1': 165,\n",
       "    'y2': 248},\n",
       "   {'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 210,\n",
       "    'x2': 269,\n",
       "    'y1': 9,\n",
       "    'y2': 67},\n",
       "   {'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 172,\n",
       "    'x2': 226,\n",
       "    'y1': 27,\n",
       "    'y2': 65},\n",
       "   {'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 128,\n",
       "    'x2': 185,\n",
       "    'y1': 25,\n",
       "    'y2': 67}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006490.jpg',\n",
       "  'height': 358,\n",
       "  'imageset': 'test',\n",
       "  'width': 269},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 43,\n",
       "    'x2': 323,\n",
       "    'y1': 161,\n",
       "    'y2': 391}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006655.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 125,\n",
       "    'y1': 131,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 206,\n",
       "    'x2': 435,\n",
       "    'y1': 115,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002469.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 8,\n",
       "    'x2': 499,\n",
       "    'y1': 289,\n",
       "    'y2': 373},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 71,\n",
       "    'x2': 259,\n",
       "    'y1': 100,\n",
       "    'y2': 326},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 236,\n",
       "    'x2': 436,\n",
       "    'y1': 102,\n",
       "    'y2': 316}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003485.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 363,\n",
       "    'y1': 143,\n",
       "    'y2': 245}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009864.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 228,\n",
       "    'x2': 456,\n",
       "    'y1': 63,\n",
       "    'y2': 245}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001719.jpg',\n",
       "  'height': 345,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 299,\n",
       "    'y1': 32,\n",
       "    'y2': 434},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 280,\n",
       "    'x2': 318,\n",
       "    'y1': 1,\n",
       "    'y2': 22},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 226,\n",
       "    'x2': 270,\n",
       "    'y1': 1,\n",
       "    'y2': 22},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 137,\n",
       "    'x2': 183,\n",
       "    'y1': 3,\n",
       "    'y2': 23},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 182,\n",
       "    'x2': 228,\n",
       "    'y1': 1,\n",
       "    'y2': 23},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 92,\n",
       "    'x2': 137,\n",
       "    'y1': 3,\n",
       "    'y2': 25},\n",
       "   {'class': 'car', 'difficult': False, 'x1': 55, 'x2': 97, 'y1': 6, 'y2': 26},\n",
       "   {'class': 'car', 'difficult': False, 'x1': 20, 'x2': 56, 'y1': 8, 'y2': 29},\n",
       "   {'class': 'car', 'difficult': True, 'x1': 1, 'x2': 23, 'y1': 11, 'y2': 30}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005520.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 334},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 204,\n",
       "    'x2': 435,\n",
       "    'y1': 114,\n",
       "    'y2': 196},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 89,\n",
       "    'y1': 165,\n",
       "    'y2': 196}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008554.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 88,\n",
       "    'x2': 416,\n",
       "    'y1': 128,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005247.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 20,\n",
       "    'x2': 273,\n",
       "    'y1': 111,\n",
       "    'y2': 445}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007047.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 165,\n",
       "    'x2': 222,\n",
       "    'y1': 210,\n",
       "    'y2': 372},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 4,\n",
       "    'x2': 161,\n",
       "    'y1': 169,\n",
       "    'y2': 395},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 16,\n",
       "    'x2': 52,\n",
       "    'y1': 101,\n",
       "    'y2': 174},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 63,\n",
       "    'x2': 107,\n",
       "    'y1': 100,\n",
       "    'y2': 132},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 85,\n",
       "    'x2': 373,\n",
       "    'y1': 69,\n",
       "    'y2': 395}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007739.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 495,\n",
       "    'y1': 90,\n",
       "    'y2': 195}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005123.jpg',\n",
       "  'height': 312,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 446,\n",
       "    'y1': 200,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 5,\n",
       "    'x2': 178,\n",
       "    'y1': 91,\n",
       "    'y2': 261},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 271,\n",
       "    'x2': 446,\n",
       "    'y1': 145,\n",
       "    'y2': 370},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 154,\n",
       "    'x2': 340,\n",
       "    'y1': 73,\n",
       "    'y2': 303}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008941.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 257,\n",
       "    'x2': 412,\n",
       "    'y1': 63,\n",
       "    'y2': 373},\n",
       "   {'class': 'bus',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 133,\n",
       "    'y1': 59,\n",
       "    'y2': 118}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002700.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 94,\n",
       "    'x2': 442,\n",
       "    'y1': 1,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000292.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 107,\n",
       "    'x2': 384,\n",
       "    'y1': 125,\n",
       "    'y2': 325},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 201,\n",
       "    'x2': 388,\n",
       "    'y1': 39,\n",
       "    'y2': 337},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 80,\n",
       "    'y1': 1,\n",
       "    'y2': 348},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 34,\n",
       "    'x2': 120,\n",
       "    'y1': 1,\n",
       "    'y2': 234},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 177,\n",
       "    'x2': 307,\n",
       "    'y1': 1,\n",
       "    'y2': 36}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000458.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 111,\n",
       "    'y1': 153,\n",
       "    'y2': 359},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 52,\n",
       "    'x2': 157,\n",
       "    'y1': 128,\n",
       "    'y2': 318}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001139.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 500,\n",
       "    'y1': 130,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 199,\n",
       "    'x2': 302,\n",
       "    'y1': 11,\n",
       "    'y2': 146},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 318,\n",
       "    'x2': 500,\n",
       "    'y1': 54,\n",
       "    'y2': 303},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 173,\n",
       "    'y1': 55,\n",
       "    'y2': 361},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 288,\n",
       "    'x2': 324,\n",
       "    'y1': 222,\n",
       "    'y2': 328},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 253,\n",
       "    'x2': 278,\n",
       "    'y1': 114,\n",
       "    'y2': 182},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 299,\n",
       "    'x2': 313,\n",
       "    'y1': 1,\n",
       "    'y2': 27},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 149,\n",
       "    'x2': 208,\n",
       "    'y1': 100,\n",
       "    'y2': 209}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008520.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 74,\n",
       "    'x2': 266,\n",
       "    'y1': 41,\n",
       "    'y2': 335},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 317,\n",
       "    'x2': 479,\n",
       "    'y1': 76,\n",
       "    'y2': 335},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 420,\n",
       "    'x2': 500,\n",
       "    'y1': 99,\n",
       "    'y2': 182}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002630.jpg',\n",
       "  'height': 335,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 136,\n",
       "    'x2': 317,\n",
       "    'y1': 210,\n",
       "    'y2': 372},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 206,\n",
       "    'x2': 380,\n",
       "    'y1': 84,\n",
       "    'y2': 248},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 140,\n",
       "    'x2': 202,\n",
       "    'y1': 74,\n",
       "    'y2': 225},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 47,\n",
       "    'x2': 112,\n",
       "    'y1': 64,\n",
       "    'y2': 252}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008746.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 2,\n",
       "    'x2': 158,\n",
       "    'y1': 216,\n",
       "    'y2': 373},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 196,\n",
       "    'x2': 268,\n",
       "    'y1': 228,\n",
       "    'y2': 294}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001540.jpg',\n",
       "  'height': 373,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 70,\n",
       "    'x2': 401,\n",
       "    'y1': 213,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 379,\n",
       "    'x2': 422,\n",
       "    'y1': 201,\n",
       "    'y2': 298},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 357,\n",
       "    'x2': 418,\n",
       "    'y1': 322,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 95,\n",
       "    'x2': 162,\n",
       "    'y1': 181,\n",
       "    'y2': 232},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 208,\n",
       "    'x2': 263,\n",
       "    'y1': 11,\n",
       "    'y2': 76},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 370,\n",
       "    'x2': 432,\n",
       "    'y1': 128,\n",
       "    'y2': 336},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 295,\n",
       "    'x2': 388,\n",
       "    'y1': 153,\n",
       "    'y2': 262},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 111,\n",
       "    'x2': 187,\n",
       "    'y1': 149,\n",
       "    'y2': 229}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006624.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 20,\n",
       "    'x2': 82,\n",
       "    'y1': 278,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 15,\n",
       "    'x2': 287,\n",
       "    'y1': 26,\n",
       "    'y2': 284},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 257,\n",
       "    'x2': 500,\n",
       "    'y1': 7,\n",
       "    'y2': 337},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 3,\n",
       "    'x2': 500,\n",
       "    'y1': 263,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003278.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 108,\n",
       "    'x2': 208,\n",
       "    'y1': 366,\n",
       "    'y2': 500},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 136,\n",
       "    'x2': 184,\n",
       "    'y1': 307,\n",
       "    'y2': 341}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008184.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 417,\n",
       "    'x2': 500,\n",
       "    'y1': 213,\n",
       "    'y2': 374},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 458,\n",
       "    'x2': 500,\n",
       "    'y1': 148,\n",
       "    'y2': 218},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 352,\n",
       "    'x2': 448,\n",
       "    'y1': 162,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 257,\n",
       "    'x2': 338,\n",
       "    'y1': 163,\n",
       "    'y2': 311},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 146,\n",
       "    'x2': 245,\n",
       "    'y1': 50,\n",
       "    'y2': 359}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000621.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 128,\n",
       "    'x2': 351,\n",
       "    'y1': 1,\n",
       "    'y2': 209}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009226.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 161,\n",
       "    'x2': 215,\n",
       "    'y1': 201,\n",
       "    'y2': 374},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 52,\n",
       "    'x2': 152,\n",
       "    'y1': 153,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004546.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 377,\n",
       "    'x2': 476,\n",
       "    'y1': 130,\n",
       "    'y2': 197},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 469,\n",
       "    'x2': 500,\n",
       "    'y1': 169,\n",
       "    'y2': 230},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 429,\n",
       "    'x2': 456,\n",
       "    'y1': 166,\n",
       "    'y2': 203}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004001.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 5,\n",
       "    'x2': 332,\n",
       "    'y1': 57,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007161.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 270,\n",
       "    'x2': 493,\n",
       "    'y1': 95,\n",
       "    'y2': 215},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 101,\n",
       "    'x2': 351,\n",
       "    'y1': 87,\n",
       "    'y2': 192},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 12,\n",
       "    'x2': 178,\n",
       "    'y1': 82,\n",
       "    'y2': 168},\n",
       "   {'class': 'car', 'difficult': True, 'x1': 1, 'x2': 68, 'y1': 86, 'y2': 146},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 281,\n",
       "    'x2': 358,\n",
       "    'y1': 74,\n",
       "    'y2': 114},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 443,\n",
       "    'x2': 500,\n",
       "    'y1': 72,\n",
       "    'y2': 121},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 166,\n",
       "    'x2': 256,\n",
       "    'y1': 178,\n",
       "    'y2': 270}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005627.jpg',\n",
       "  'height': 280,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 55,\n",
       "    'x2': 263,\n",
       "    'y1': 143,\n",
       "    'y2': 322},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 130,\n",
       "    'x2': 252,\n",
       "    'y1': 103,\n",
       "    'y2': 319}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009277.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 64,\n",
       "    'x2': 465,\n",
       "    'y1': 1,\n",
       "    'y2': 252},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 343,\n",
       "    'x2': 357,\n",
       "    'y1': 180,\n",
       "    'y2': 209},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 293,\n",
       "    'x2': 308,\n",
       "    'y1': 177,\n",
       "    'y2': 209},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 72,\n",
       "    'x2': 89,\n",
       "    'y1': 185,\n",
       "    'y2': 220},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 100,\n",
       "    'x2': 112,\n",
       "    'y1': 188,\n",
       "    'y2': 214},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 179,\n",
       "    'x2': 190,\n",
       "    'y1': 181,\n",
       "    'y2': 213},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 215,\n",
       "    'x2': 230,\n",
       "    'y1': 186,\n",
       "    'y2': 222},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 307,\n",
       "    'x2': 317,\n",
       "    'y1': 192,\n",
       "    'y2': 220}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007660.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 276,\n",
       "    'y1': 1,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 327,\n",
       "    'y1': 1,\n",
       "    'y2': 484}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004569.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 202,\n",
       "    'y1': 217,\n",
       "    'y2': 345},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': True,\n",
       "    'x1': 115,\n",
       "    'x2': 160,\n",
       "    'y1': 199,\n",
       "    'y2': 233},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 195,\n",
       "    'x2': 375,\n",
       "    'y1': 252,\n",
       "    'y2': 456},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 241,\n",
       "    'x2': 344,\n",
       "    'y1': 272,\n",
       "    'y2': 499},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 310,\n",
       "    'x2': 358,\n",
       "    'y1': 213,\n",
       "    'y2': 263},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 202,\n",
       "    'x2': 266,\n",
       "    'y1': 231,\n",
       "    'y2': 401},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 220,\n",
       "    'x2': 247,\n",
       "    'y1': 217,\n",
       "    'y2': 275}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009486.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 317,\n",
       "    'y1': 3,\n",
       "    'y2': 373}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002084.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 79,\n",
       "    'x2': 471,\n",
       "    'y1': 56,\n",
       "    'y2': 254},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 270,\n",
       "    'x2': 316,\n",
       "    'y1': 161,\n",
       "    'y2': 285},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 222,\n",
       "    'x2': 261,\n",
       "    'y1': 165,\n",
       "    'y2': 229},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 53,\n",
       "    'y1': 232,\n",
       "    'y2': 332}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003475.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 217,\n",
       "    'x2': 397,\n",
       "    'y1': 67,\n",
       "    'y2': 290},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 229,\n",
       "    'x2': 287,\n",
       "    'y1': 141,\n",
       "    'y2': 277},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 127,\n",
       "    'x2': 235,\n",
       "    'y1': 252,\n",
       "    'y2': 291},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 62,\n",
       "    'x2': 164,\n",
       "    'y1': 124,\n",
       "    'y2': 349}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002981.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 160,\n",
       "    'y1': 142,\n",
       "    'y2': 276},\n",
       "   {'class': 'train',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 46,\n",
       "    'y1': 142,\n",
       "    'y2': 201}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008679.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 6,\n",
       "    'x2': 157,\n",
       "    'y1': 55,\n",
       "    'y2': 204},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 255,\n",
       "    'x2': 335,\n",
       "    'y1': 35,\n",
       "    'y2': 179},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 94,\n",
       "    'x2': 240,\n",
       "    'y1': 33,\n",
       "    'y2': 222}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003520.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 335},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 235,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 207}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008949.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 217,\n",
       "    'y1': 1,\n",
       "    'y2': 362}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005428.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 65,\n",
       "    'x2': 303,\n",
       "    'y1': 38,\n",
       "    'y2': 294},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 281,\n",
       "    'x2': 490,\n",
       "    'y1': 142,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004420.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 405,\n",
       "    'x2': 444,\n",
       "    'y1': 205,\n",
       "    'y2': 245},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 415,\n",
       "    'x2': 450,\n",
       "    'y1': 270,\n",
       "    'y2': 325},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 72,\n",
       "    'x2': 172,\n",
       "    'y1': 122,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 171,\n",
       "    'x2': 281,\n",
       "    'y1': 117,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 256,\n",
       "    'x2': 337,\n",
       "    'y1': 142,\n",
       "    'y2': 352},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 330,\n",
       "    'x2': 405,\n",
       "    'y1': 130,\n",
       "    'y2': 342}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003020.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 75,\n",
       "    'x2': 315,\n",
       "    'y1': 4,\n",
       "    'y2': 498}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001295.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 369,\n",
       "    'x2': 500,\n",
       "    'y1': 174,\n",
       "    'y2': 281},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 252,\n",
       "    'x2': 431,\n",
       "    'y1': 100,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 27,\n",
       "    'x2': 316,\n",
       "    'y1': 117,\n",
       "    'y2': 375},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 315,\n",
       "    'y1': 163,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005808.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 100,\n",
       "    'x2': 400,\n",
       "    'y1': 45,\n",
       "    'y2': 181},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 133,\n",
       "    'y1': 1,\n",
       "    'y2': 300}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009599.jpg',\n",
       "  'height': 300,\n",
       "  'imageset': 'test',\n",
       "  'width': 400},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 104,\n",
       "    'x2': 440,\n",
       "    'y1': 65,\n",
       "    'y2': 372},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 4,\n",
       "    'x2': 433,\n",
       "    'y1': 2,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005286.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 58,\n",
       "    'x2': 271,\n",
       "    'y1': 188,\n",
       "    'y2': 310}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000062.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 60,\n",
       "    'x2': 309,\n",
       "    'y1': 88,\n",
       "    'y2': 310}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006063.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 153,\n",
       "    'x2': 416,\n",
       "    'y1': 80,\n",
       "    'y2': 286},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 241,\n",
       "    'x2': 299,\n",
       "    'y1': 51,\n",
       "    'y2': 181}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003022.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 66,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 313}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006064.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 55,\n",
       "    'x2': 496,\n",
       "    'y1': 96,\n",
       "    'y2': 265},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 47,\n",
       "    'x2': 94,\n",
       "    'y1': 50,\n",
       "    'y2': 200},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 80,\n",
       "    'x2': 141,\n",
       "    'y1': 42,\n",
       "    'y2': 117}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008682.jpg',\n",
       "  'height': 294,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 217,\n",
       "    'x2': 275,\n",
       "    'y1': 126,\n",
       "    'y2': 241},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 152,\n",
       "    'x2': 227,\n",
       "    'y1': 168,\n",
       "    'y2': 247},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 92,\n",
       "    'x2': 138,\n",
       "    'y1': 93,\n",
       "    'y2': 152},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 146,\n",
       "    'x2': 221,\n",
       "    'y1': 117,\n",
       "    'y2': 173},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 31,\n",
       "    'x2': 159,\n",
       "    'y1': 62,\n",
       "    'y2': 222}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004486.jpg',\n",
       "  'height': 358,\n",
       "  'imageset': 'test',\n",
       "  'width': 300},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 243,\n",
       "    'x2': 274,\n",
       "    'y1': 192,\n",
       "    'y2': 216},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 217,\n",
       "    'x2': 238,\n",
       "    'y1': 184,\n",
       "    'y2': 205},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 198,\n",
       "    'x2': 215,\n",
       "    'y1': 184,\n",
       "    'y2': 201},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 147,\n",
       "    'x2': 180,\n",
       "    'y1': 188,\n",
       "    'y2': 208},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 122,\n",
       "    'x2': 143,\n",
       "    'y1': 186,\n",
       "    'y2': 193},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 82,\n",
       "    'x2': 112,\n",
       "    'y1': 185,\n",
       "    'y2': 194},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 19,\n",
       "    'x2': 64,\n",
       "    'y1': 182,\n",
       "    'y2': 195},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 2,\n",
       "    'x2': 26,\n",
       "    'y1': 183,\n",
       "    'y2': 195}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007082.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 84,\n",
       "    'x2': 323,\n",
       "    'y1': 72,\n",
       "    'y2': 285},\n",
       "   {'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 498,\n",
       "    'y1': 15,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007581.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 160,\n",
       "    'x2': 205,\n",
       "    'y1': 209,\n",
       "    'y2': 309},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 218,\n",
       "    'x2': 256,\n",
       "    'y1': 209,\n",
       "    'y2': 308},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 257,\n",
       "    'x2': 293,\n",
       "    'y1': 203,\n",
       "    'y2': 309}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004056.jpg',\n",
       "  'height': 364,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 70,\n",
       "    'x2': 493,\n",
       "    'y1': 48,\n",
       "    'y2': 332},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 4,\n",
       "    'x2': 307,\n",
       "    'y1': 1,\n",
       "    'y2': 124}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002408.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 190,\n",
       "    'y1': 178,\n",
       "    'y2': 241}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007450.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 5,\n",
       "    'x2': 339,\n",
       "    'y1': 8,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007782.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 319,\n",
       "    'x2': 375,\n",
       "    'y1': 146,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 287,\n",
       "    'x2': 327,\n",
       "    'y1': 224,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 248,\n",
       "    'x2': 284,\n",
       "    'y1': 201,\n",
       "    'y2': 340},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 196,\n",
       "    'x2': 247,\n",
       "    'y1': 163,\n",
       "    'y2': 344},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 79,\n",
       "    'x2': 130,\n",
       "    'y1': 133,\n",
       "    'y2': 198},\n",
       "   {'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 5,\n",
       "    'x2': 500,\n",
       "    'y1': 41,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004167.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 209,\n",
       "    'x2': 275,\n",
       "    'y1': 132,\n",
       "    'y2': 222},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 219,\n",
       "    'x2': 273,\n",
       "    'y1': 107,\n",
       "    'y2': 187},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 465,\n",
       "    'x2': 483,\n",
       "    'y1': 273,\n",
       "    'y2': 324},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 436,\n",
       "    'x2': 456,\n",
       "    'y1': 279,\n",
       "    'y2': 327}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000055.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 76,\n",
       "    'x2': 401,\n",
       "    'y1': 56,\n",
       "    'y2': 373}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000988.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 126,\n",
       "    'x2': 181,\n",
       "    'y1': 194,\n",
       "    'y2': 230},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 270,\n",
       "    'x2': 334,\n",
       "    'y1': 187,\n",
       "    'y2': 227},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 52,\n",
       "    'x2': 105,\n",
       "    'y1': 190,\n",
       "    'y2': 227},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 442,\n",
       "    'x2': 500,\n",
       "    'y1': 190,\n",
       "    'y2': 226},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 39,\n",
       "    'x2': 125,\n",
       "    'y1': 205,\n",
       "    'y2': 228},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 174,\n",
       "    'x2': 256,\n",
       "    'y1': 205,\n",
       "    'y2': 230},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 330,\n",
       "    'x2': 366,\n",
       "    'y1': 206,\n",
       "    'y2': 228},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 409,\n",
       "    'x2': 443,\n",
       "    'y1': 209,\n",
       "    'y2': 228}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003692.jpg',\n",
       "  'height': 250,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 104,\n",
       "    'x2': 351,\n",
       "    'y1': 90,\n",
       "    'y2': 331},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 217,\n",
       "    'x2': 499,\n",
       "    'y1': 72,\n",
       "    'y2': 331}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006489.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 138,\n",
       "    'x2': 288,\n",
       "    'y1': 87,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 114,\n",
       "    'x2': 309,\n",
       "    'y1': 12,\n",
       "    'y2': 265},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 222,\n",
       "    'x2': 479,\n",
       "    'y1': 54,\n",
       "    'y2': 333},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 53,\n",
       "    'y1': 56,\n",
       "    'y2': 103},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 70,\n",
       "    'x2': 120,\n",
       "    'y1': 52,\n",
       "    'y2': 101},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 167,\n",
       "    'x2': 194,\n",
       "    'y1': 59,\n",
       "    'y2': 96},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 224,\n",
       "    'x2': 292,\n",
       "    'y1': 57,\n",
       "    'y2': 99},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 292,\n",
       "    'x2': 370,\n",
       "    'y1': 54,\n",
       "    'y2': 97}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002331.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 56,\n",
       "    'x2': 320,\n",
       "    'y1': 87,\n",
       "    'y2': 438},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 131,\n",
       "    'x2': 241,\n",
       "    'y1': 46,\n",
       "    'y2': 282}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004301.jpg',\n",
       "  'height': 480,\n",
       "  'imageset': 'test',\n",
       "  'width': 400},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 312,\n",
       "    'x2': 412,\n",
       "    'y1': 45,\n",
       "    'y2': 282},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 70,\n",
       "    'x2': 232,\n",
       "    'y1': 16,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001583.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 272,\n",
       "    'x2': 352,\n",
       "    'y1': 103,\n",
       "    'y2': 131},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 500,\n",
       "    'y1': 103,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002843.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 215,\n",
       "    'x2': 306,\n",
       "    'y1': 67,\n",
       "    'y2': 290},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 62,\n",
       "    'x2': 436,\n",
       "    'y1': 160,\n",
       "    'y2': 332}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006586.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 140,\n",
       "    'x2': 433,\n",
       "    'y1': 121,\n",
       "    'y2': 301},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 261,\n",
       "    'x2': 320,\n",
       "    'y1': 75,\n",
       "    'y2': 237}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004294.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 6,\n",
       "    'x2': 494,\n",
       "    'y1': 68,\n",
       "    'y2': 366}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008408.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 31,\n",
       "    'x2': 385,\n",
       "    'y1': 30,\n",
       "    'y2': 302}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002236.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 383,\n",
       "    'y1': 87,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004156.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 95,\n",
       "    'x2': 458,\n",
       "    'y1': 129,\n",
       "    'y2': 262},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 494,\n",
       "    'x2': 500,\n",
       "    'y1': 202,\n",
       "    'y2': 259},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 400,\n",
       "    'x2': 464,\n",
       "    'y1': 206,\n",
       "    'y2': 351},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 318,\n",
       "    'x2': 365,\n",
       "    'y1': 198,\n",
       "    'y2': 326},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 75,\n",
       "    'x2': 92,\n",
       "    'y1': 188,\n",
       "    'y2': 243},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 29,\n",
       "    'y1': 195,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000723.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 64,\n",
       "    'x2': 268,\n",
       "    'y1': 21,\n",
       "    'y2': 371},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 500,\n",
       "    'y1': 68,\n",
       "    'y2': 378}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007034.jpg',\n",
       "  'height': 401,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 10,\n",
       "    'x2': 500,\n",
       "    'y1': 51,\n",
       "    'y2': 413},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 122,\n",
       "    'x2': 373,\n",
       "    'y1': 19,\n",
       "    'y2': 412}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005595.jpg',\n",
       "  'height': 413,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 48,\n",
       "    'x2': 112,\n",
       "    'y1': 153,\n",
       "    'y2': 259},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 87,\n",
       "    'x2': 134,\n",
       "    'y1': 148,\n",
       "    'y2': 249},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 128,\n",
       "    'x2': 285,\n",
       "    'y1': 13,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002846.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 12,\n",
       "    'x2': 500,\n",
       "    'y1': 85,\n",
       "    'y2': 364},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 375,\n",
       "    'x2': 500,\n",
       "    'y1': 75,\n",
       "    'y2': 186},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 196,\n",
       "    'x2': 373,\n",
       "    'y1': 78,\n",
       "    'y2': 234},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 273,\n",
       "    'x2': 500,\n",
       "    'y1': 107,\n",
       "    'y2': 220},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 214,\n",
       "    'x2': 273,\n",
       "    'y1': 37,\n",
       "    'y2': 108}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005025.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 74,\n",
       "    'x2': 324,\n",
       "    'y1': 125,\n",
       "    'y2': 450},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 74,\n",
       "    'y1': 138,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 98,\n",
       "    'x2': 156,\n",
       "    'y1': 121,\n",
       "    'y2': 291},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 226,\n",
       "    'x2': 313,\n",
       "    'y1': 128,\n",
       "    'y2': 401}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009674.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 332},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 314,\n",
       "    'x2': 482,\n",
       "    'y1': 163,\n",
       "    'y2': 354}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007560.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 109,\n",
       "    'x2': 299,\n",
       "    'y1': 211,\n",
       "    'y2': 392},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 101,\n",
       "    'x2': 264,\n",
       "    'y1': 185,\n",
       "    'y2': 332}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001446.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 335},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 92,\n",
       "    'x2': 308,\n",
       "    'y1': 40,\n",
       "    'y2': 455}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005972.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 255,\n",
       "    'y1': 274,\n",
       "    'y2': 451},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 194,\n",
       "    'x2': 286,\n",
       "    'y1': 155,\n",
       "    'y2': 433}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006059.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 93,\n",
       "    'x2': 373,\n",
       "    'y1': 55,\n",
       "    'y2': 292}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002928.jpg',\n",
       "  'height': 329,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 41,\n",
       "    'x2': 106,\n",
       "    'y1': 312,\n",
       "    'y2': 415},\n",
       "   {'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 285,\n",
       "    'x2': 375,\n",
       "    'y1': 414,\n",
       "    'y2': 455},\n",
       "   {'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 319,\n",
       "    'y1': 1,\n",
       "    'y2': 465}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005604.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 272,\n",
       "    'x2': 500,\n",
       "    'y1': 124,\n",
       "    'y2': 358},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 54,\n",
       "    'x2': 252,\n",
       "    'y1': 161,\n",
       "    'y2': 351}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004202.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 500,\n",
       "    'y1': 67,\n",
       "    'y2': 374},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 419,\n",
       "    'x2': 500,\n",
       "    'y1': 52,\n",
       "    'y2': 219},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 358,\n",
       "    'x2': 404,\n",
       "    'y1': 38,\n",
       "    'y2': 100},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 228,\n",
       "    'x2': 296,\n",
       "    'y1': 2,\n",
       "    'y2': 44},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 134,\n",
       "    'x2': 181,\n",
       "    'y1': 36,\n",
       "    'y2': 82},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 43,\n",
       "    'x2': 124,\n",
       "    'y1': 41,\n",
       "    'y2': 184},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 76,\n",
       "    'y1': 94,\n",
       "    'y2': 310},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 82,\n",
       "    'x2': 141,\n",
       "    'y1': 2,\n",
       "    'y2': 117},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 148,\n",
       "    'x2': 196,\n",
       "    'y1': 3,\n",
       "    'y2': 74}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007442.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 97,\n",
       "    'x2': 401,\n",
       "    'y1': 238,\n",
       "    'y2': 375},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 197,\n",
       "    'x2': 500,\n",
       "    'y1': 264,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 171,\n",
       "    'x2': 418,\n",
       "    'y1': 111,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 250,\n",
       "    'x2': 500,\n",
       "    'y1': 101,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007324.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 489,\n",
       "    'y1': 58,\n",
       "    'y2': 331}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003046.jpg',\n",
       "  'height': 351,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 244,\n",
       "    'x2': 332,\n",
       "    'y1': 113,\n",
       "    'y2': 208}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005587.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 52,\n",
       "    'x2': 278,\n",
       "    'y1': 118,\n",
       "    'y2': 432}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006856.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 65,\n",
       "    'x2': 301,\n",
       "    'y1': 133,\n",
       "    'y2': 382}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004921.jpg',\n",
       "  'height': 480,\n",
       "  'imageset': 'test',\n",
       "  'width': 369},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 7,\n",
       "    'x2': 500,\n",
       "    'y1': 102,\n",
       "    'y2': 374},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 314,\n",
       "    'x2': 425,\n",
       "    'y1': 24,\n",
       "    'y2': 120}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004210.jpg',\n",
       "  'height': 374,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 39,\n",
       "    'x2': 460,\n",
       "    'y1': 131,\n",
       "    'y2': 314},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 91,\n",
       "    'y1': 122,\n",
       "    'y2': 187}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009302.jpg',\n",
       "  'height': 373,\n",
       "  'imageset': 'test',\n",
       "  'width': 497},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 58,\n",
       "    'x2': 397,\n",
       "    'y1': 135,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 408,\n",
       "    'x2': 500,\n",
       "    'y1': 239,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 3,\n",
       "    'x2': 108,\n",
       "    'y1': 221,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 11,\n",
       "    'x2': 160,\n",
       "    'y1': 269,\n",
       "    'y2': 374},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 190,\n",
       "    'x2': 211,\n",
       "    'y1': 113,\n",
       "    'y2': 172},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 146,\n",
       "    'x2': 162,\n",
       "    'y1': 101,\n",
       "    'y2': 165},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 213,\n",
       "    'x2': 234,\n",
       "    'y1': 128,\n",
       "    'y2': 211},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 237,\n",
       "    'x2': 264,\n",
       "    'y1': 134,\n",
       "    'y2': 213},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 249,\n",
       "    'x2': 500,\n",
       "    'y1': 61,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 29,\n",
       "    'y1': 57,\n",
       "    'y2': 142},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 4,\n",
       "    'x2': 153,\n",
       "    'y1': 76,\n",
       "    'y2': 345},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 71,\n",
       "    'x2': 163,\n",
       "    'y1': 57,\n",
       "    'y2': 134},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 220,\n",
       "    'x2': 284,\n",
       "    'y1': 60,\n",
       "    'y2': 150},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 264,\n",
       "    'x2': 348,\n",
       "    'y1': 57,\n",
       "    'y2': 172},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 277,\n",
       "    'x2': 431,\n",
       "    'y1': 68,\n",
       "    'y2': 206}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004640.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 30,\n",
       "    'x2': 500,\n",
       "    'y1': 99,\n",
       "    'y2': 315}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005046.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 139,\n",
       "    'y1': 17,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 134,\n",
       "    'x2': 333,\n",
       "    'y1': 163,\n",
       "    'y2': 476},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 209,\n",
       "    'x2': 332,\n",
       "    'y1': 167,\n",
       "    'y2': 390},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 175,\n",
       "    'x2': 264,\n",
       "    'y1': 112,\n",
       "    'y2': 210},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 254,\n",
       "    'x2': 333,\n",
       "    'y1': 125,\n",
       "    'y2': 349}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001581.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 75,\n",
       "    'x2': 358,\n",
       "    'y1': 101,\n",
       "    'y2': 302}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000556.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 492,\n",
       "    'y1': 156,\n",
       "    'y2': 343}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000841.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 40,\n",
       "    'x2': 253,\n",
       "    'y1': 120,\n",
       "    'y2': 412}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007083.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 332},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 288,\n",
       "    'x2': 404,\n",
       "    'y1': 146,\n",
       "    'y2': 250},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 71,\n",
       "    'x2': 104,\n",
       "    'y1': 192,\n",
       "    'y2': 293},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 145,\n",
       "    'x2': 169,\n",
       "    'y1': 195,\n",
       "    'y2': 284},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 119,\n",
       "    'x2': 134,\n",
       "    'y1': 205,\n",
       "    'y2': 248},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 105,\n",
       "    'x2': 119,\n",
       "    'y1': 206,\n",
       "    'y2': 247}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000858.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 444,\n",
       "    'y1': 106,\n",
       "    'y2': 372},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 150,\n",
       "    'x2': 405,\n",
       "    'y1': 101,\n",
       "    'y2': 300},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 366,\n",
       "    'x2': 479,\n",
       "    'y1': 4,\n",
       "    'y2': 160}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003029.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 185,\n",
       "    'x2': 500,\n",
       "    'y1': 57,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006871.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 175,\n",
       "    'x2': 422,\n",
       "    'y1': 158,\n",
       "    'y2': 251},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 210,\n",
       "    'x2': 229,\n",
       "    'y1': 104,\n",
       "    'y2': 156}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004249.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 331,\n",
       "    'x2': 500,\n",
       "    'y1': 81,\n",
       "    'y2': 351},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 177,\n",
       "    'x2': 342,\n",
       "    'y1': 75,\n",
       "    'y2': 344},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 24,\n",
       "    'x2': 194,\n",
       "    'y1': 96,\n",
       "    'y2': 337}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009495.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 11,\n",
       "    'x2': 393,\n",
       "    'y1': 8,\n",
       "    'y2': 479}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008538.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 400},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 317,\n",
       "    'x2': 500,\n",
       "    'y1': 85,\n",
       "    'y2': 328},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 150,\n",
       "    'x2': 270,\n",
       "    'y1': 89,\n",
       "    'y2': 277},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 140,\n",
       "    'y1': 96,\n",
       "    'y2': 247},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 500,\n",
       "    'y1': 231,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005151.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 320,\n",
       "    'y1': 33,\n",
       "    'y2': 440}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005462.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 343},\n",
       " {'bboxes': [{'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 210,\n",
       "    'x2': 387,\n",
       "    'y1': 2,\n",
       "    'y2': 332},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 127,\n",
       "    'x2': 278,\n",
       "    'y1': 56,\n",
       "    'y2': 164},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 48,\n",
       "    'x2': 297,\n",
       "    'y1': 137,\n",
       "    'y2': 332}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004610.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 29,\n",
       "    'x2': 265,\n",
       "    'y1': 25,\n",
       "    'y2': 190},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 225,\n",
       "    'y1': 47,\n",
       "    'y2': 374},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 194,\n",
       "    'x2': 426,\n",
       "    'y1': 75,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 371,\n",
       "    'x2': 471,\n",
       "    'y1': 66,\n",
       "    'y2': 365},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 219,\n",
       "    'x2': 305,\n",
       "    'y1': 254,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002792.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 63,\n",
       "    'x2': 265,\n",
       "    'y1': 7,\n",
       "    'y2': 242}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002771.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'pottedplant',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 82,\n",
       "    'y1': 11,\n",
       "    'y2': 333},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 107,\n",
       "    'y1': 276,\n",
       "    'y2': 333},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 221,\n",
       "    'x2': 500,\n",
       "    'y1': 227,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 240,\n",
       "    'x2': 379,\n",
       "    'y1': 69,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 114,\n",
       "    'x2': 257,\n",
       "    'y1': 42,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005556.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 17,\n",
       "    'x2': 136,\n",
       "    'y1': 12,\n",
       "    'y2': 331},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 114,\n",
       "    'x2': 233,\n",
       "    'y1': 9,\n",
       "    'y2': 331},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 212,\n",
       "    'x2': 347,\n",
       "    'y1': 2,\n",
       "    'y2': 331}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003383.jpg',\n",
       "  'height': 331,\n",
       "  'imageset': 'test',\n",
       "  'width': 360},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 47,\n",
       "    'x2': 149,\n",
       "    'y1': 141,\n",
       "    'y2': 245},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 216,\n",
       "    'x2': 347,\n",
       "    'y1': 149,\n",
       "    'y2': 254},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 344,\n",
       "    'x2': 482,\n",
       "    'y1': 131,\n",
       "    'y2': 277}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005902.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 25,\n",
       "    'x2': 311,\n",
       "    'y1': 89,\n",
       "    'y2': 419},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 50,\n",
       "    'y1': 142,\n",
       "    'y2': 465}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007591.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 426,\n",
       "    'y1': 22,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 239,\n",
       "    'x2': 500,\n",
       "    'y1': 50,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004726.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 135,\n",
       "    'x2': 259,\n",
       "    'y1': 88,\n",
       "    'y2': 198},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 377,\n",
       "    'x2': 475,\n",
       "    'y1': 140,\n",
       "    'y2': 255},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 347,\n",
       "    'x2': 500,\n",
       "    'y1': 238,\n",
       "    'y2': 332},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 174,\n",
       "    'x2': 200,\n",
       "    'y1': 119,\n",
       "    'y2': 173},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 421,\n",
       "    'x2': 444,\n",
       "    'y1': 25,\n",
       "    'y2': 34},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 409,\n",
       "    'x2': 436,\n",
       "    'y1': 30,\n",
       "    'y2': 43},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 382,\n",
       "    'x2': 407,\n",
       "    'y1': 27,\n",
       "    'y2': 39}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007835.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 76,\n",
       "    'x2': 412,\n",
       "    'y1': 82,\n",
       "    'y2': 192},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 402,\n",
       "    'x2': 500,\n",
       "    'y1': 119,\n",
       "    'y2': 178}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003940.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 333,\n",
       "    'y1': 116,\n",
       "    'y2': 393}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008552.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 31,\n",
       "    'x2': 312,\n",
       "    'y1': 80,\n",
       "    'y2': 291},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 316,\n",
       "    'x2': 374,\n",
       "    'y1': 183,\n",
       "    'y2': 250},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 155,\n",
       "    'x2': 229,\n",
       "    'y1': 49,\n",
       "    'y2': 220}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000319.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 80,\n",
       "    'x2': 344,\n",
       "    'y1': 141,\n",
       "    'y2': 247},\n",
       "   {'class': 'train',\n",
       "    'difficult': True,\n",
       "    'x1': 318,\n",
       "    'x2': 500,\n",
       "    'y1': 120,\n",
       "    'y2': 244}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003777.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 72,\n",
       "    'x2': 257,\n",
       "    'y1': 132,\n",
       "    'y2': 309},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 257,\n",
       "    'x2': 449,\n",
       "    'y1': 133,\n",
       "    'y2': 268}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008109.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 90,\n",
       "    'x2': 335,\n",
       "    'y1': 40,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000873.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 335},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 285,\n",
       "    'x2': 375,\n",
       "    'y1': 68,\n",
       "    'y2': 235}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003291.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 115,\n",
       "    'x2': 278,\n",
       "    'y1': 174,\n",
       "    'y2': 274},\n",
       "   {'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 45,\n",
       "    'x2': 163,\n",
       "    'y1': 280,\n",
       "    'y2': 416}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005538.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 335},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 318,\n",
       "    'x2': 407,\n",
       "    'y1': 146,\n",
       "    'y2': 247},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 368,\n",
       "    'x2': 498,\n",
       "    'y1': 122,\n",
       "    'y2': 332},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 126,\n",
       "    'y1': 160,\n",
       "    'y2': 362},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 11,\n",
       "    'x2': 167,\n",
       "    'y1': 133,\n",
       "    'y2': 242},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 176,\n",
       "    'x2': 220,\n",
       "    'y1': 106,\n",
       "    'y2': 164},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 254,\n",
       "    'x2': 457,\n",
       "    'y1': 315,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 377,\n",
       "    'x2': 498,\n",
       "    'y1': 223,\n",
       "    'y2': 373},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 154,\n",
       "    'x2': 227,\n",
       "    'y1': 149,\n",
       "    'y2': 198},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 114,\n",
       "    'x2': 165,\n",
       "    'y1': 124,\n",
       "    'y2': 216},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 284,\n",
       "    'x2': 306,\n",
       "    'y1': 205,\n",
       "    'y2': 286},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 207,\n",
       "    'x2': 223,\n",
       "    'y1': 158,\n",
       "    'y2': 207},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 233,\n",
       "    'x2': 249,\n",
       "    'y1': 165,\n",
       "    'y2': 211},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 98,\n",
       "    'x2': 373,\n",
       "    'y1': 196,\n",
       "    'y2': 371},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 86,\n",
       "    'x2': 192,\n",
       "    'y1': 126,\n",
       "    'y2': 161},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 98,\n",
       "    'x2': 124,\n",
       "    'y1': 111,\n",
       "    'y2': 132}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005233.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 169,\n",
       "    'x2': 407,\n",
       "    'y1': 96,\n",
       "    'y2': 276},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 237,\n",
       "    'x2': 358,\n",
       "    'y1': 99,\n",
       "    'y2': 240}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002105.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 124,\n",
       "    'x2': 284,\n",
       "    'y1': 2,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 284,\n",
       "    'x2': 500,\n",
       "    'y1': 48,\n",
       "    'y2': 333},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 5,\n",
       "    'x2': 499,\n",
       "    'y1': 44,\n",
       "    'y2': 332}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000683.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 154,\n",
       "    'x2': 281,\n",
       "    'y1': 194,\n",
       "    'y2': 372},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 373,\n",
       "    'x2': 500,\n",
       "    'y1': 173,\n",
       "    'y2': 322}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000385.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 65,\n",
       "    'x2': 277,\n",
       "    'y1': 172,\n",
       "    'y2': 330},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 150,\n",
       "    'x2': 322,\n",
       "    'y1': 11,\n",
       "    'y2': 301}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007317.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 450,\n",
       "    'y1': 2,\n",
       "    'y2': 332}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003930.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': True,\n",
       "    'x1': 182,\n",
       "    'x2': 369,\n",
       "    'y1': 78,\n",
       "    'y2': 246},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 219,\n",
       "    'x2': 328,\n",
       "    'y1': 114,\n",
       "    'y2': 213}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000644.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 51,\n",
       "    'x2': 420,\n",
       "    'y1': 54,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 25,\n",
       "    'x2': 204,\n",
       "    'y1': 2,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 277,\n",
       "    'x2': 477,\n",
       "    'y1': 1,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 380,\n",
       "    'x2': 496,\n",
       "    'y1': 1,\n",
       "    'y2': 345}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005366.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 47,\n",
       "    'x2': 454,\n",
       "    'y1': 49,\n",
       "    'y2': 219}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002754.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 118,\n",
       "    'y1': 2,\n",
       "    'y2': 189},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 155,\n",
       "    'y1': 89,\n",
       "    'y2': 301},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 331,\n",
       "    'x2': 500,\n",
       "    'y1': 110,\n",
       "    'y2': 325},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 153,\n",
       "    'x2': 344,\n",
       "    'y1': 85,\n",
       "    'y2': 290},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 89,\n",
       "    'x2': 208,\n",
       "    'y1': 16,\n",
       "    'y2': 212},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 418,\n",
       "    'x2': 485,\n",
       "    'y1': 1,\n",
       "    'y2': 102},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 315,\n",
       "    'x2': 356,\n",
       "    'y1': 1,\n",
       "    'y2': 48},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 367,\n",
       "    'x2': 395,\n",
       "    'y1': 1,\n",
       "    'y2': 53},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 392,\n",
       "    'x2': 429,\n",
       "    'y1': 1,\n",
       "    'y2': 45}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005698.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 180,\n",
       "    'x2': 248,\n",
       "    'y1': 75,\n",
       "    'y2': 163},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 90,\n",
       "    'x2': 126,\n",
       "    'y1': 82,\n",
       "    'y2': 199},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 4,\n",
       "    'x2': 107,\n",
       "    'y1': 73,\n",
       "    'y2': 456},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 102,\n",
       "    'x2': 279,\n",
       "    'y1': 174,\n",
       "    'y2': 397},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 174,\n",
       "    'x2': 213,\n",
       "    'y1': 157,\n",
       "    'y2': 209},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 203,\n",
       "    'x2': 268,\n",
       "    'y1': 146,\n",
       "    'y2': 249},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 94,\n",
       "    'x2': 221,\n",
       "    'y1': 293,\n",
       "    'y2': 488}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005596.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 17,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 360}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003019.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 18,\n",
       "    'x2': 429,\n",
       "    'y1': 210,\n",
       "    'y2': 356},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 351,\n",
       "    'x2': 475,\n",
       "    'y1': 257,\n",
       "    'y2': 356},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 295,\n",
       "    'x2': 381,\n",
       "    'y1': 192,\n",
       "    'y2': 246},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 215,\n",
       "    'x2': 261,\n",
       "    'y1': 189,\n",
       "    'y2': 223},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 31,\n",
       "    'x2': 101,\n",
       "    'y1': 184,\n",
       "    'y2': 231},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 31,\n",
       "    'x2': 158,\n",
       "    'y1': 217,\n",
       "    'y2': 356},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 137,\n",
       "    'x2': 248,\n",
       "    'y1': 239,\n",
       "    'y2': 356}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009815.jpg',\n",
       "  'height': 356,\n",
       "  'imageset': 'test',\n",
       "  'width': 475},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 250,\n",
       "    'x2': 500,\n",
       "    'y1': 139,\n",
       "    'y2': 269},\n",
       "   {'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 140,\n",
       "    'x2': 254,\n",
       "    'y1': 148,\n",
       "    'y2': 266},\n",
       "   {'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 58,\n",
       "    'x2': 146,\n",
       "    'y1': 160,\n",
       "    'y2': 262},\n",
       "   {'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 17,\n",
       "    'x2': 65,\n",
       "    'y1': 163,\n",
       "    'y2': 266}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006992.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 500,\n",
       "    'y1': 11,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001943.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 152,\n",
       "    'x2': 265,\n",
       "    'y1': 212,\n",
       "    'y2': 363},\n",
       "   {'class': 'bird',\n",
       "    'difficult': True,\n",
       "    'x1': 94,\n",
       "    'x2': 121,\n",
       "    'y1': 288,\n",
       "    'y2': 352}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007051.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 51,\n",
       "    'x2': 113,\n",
       "    'y1': 151,\n",
       "    'y2': 170},\n",
       "   {'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 376,\n",
       "    'x2': 409,\n",
       "    'y1': 122,\n",
       "    'y2': 146},\n",
       "   {'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 269,\n",
       "    'x2': 317,\n",
       "    'y1': 130,\n",
       "    'y2': 144},\n",
       "   {'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 251,\n",
       "    'x2': 287,\n",
       "    'y1': 135,\n",
       "    'y2': 155},\n",
       "   {'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 213,\n",
       "    'x2': 266,\n",
       "    'y1': 147,\n",
       "    'y2': 169},\n",
       "   {'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 107,\n",
       "    'x2': 157,\n",
       "    'y1': 146,\n",
       "    'y2': 165},\n",
       "   {'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 95,\n",
       "    'x2': 131,\n",
       "    'y1': 139,\n",
       "    'y2': 152}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009137.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 384,\n",
       "    'y1': 52,\n",
       "    'y2': 290}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000040.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 496,\n",
       "    'y1': 68,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006019.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 22,\n",
       "    'y1': 298,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 25,\n",
       "    'x2': 82,\n",
       "    'y1': 292,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 195,\n",
       "    'x2': 243,\n",
       "    'y1': 290,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 138,\n",
       "    'x2': 159,\n",
       "    'y1': 289,\n",
       "    'y2': 366},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 148,\n",
       "    'x2': 199,\n",
       "    'y1': 292,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 390,\n",
       "    'x2': 432,\n",
       "    'y1': 282,\n",
       "    'y2': 351},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 455,\n",
       "    'x2': 496,\n",
       "    'y1': 285,\n",
       "    'y2': 352},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 430,\n",
       "    'x2': 461,\n",
       "    'y1': 282,\n",
       "    'y2': 347},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 118,\n",
       "    'x2': 143,\n",
       "    'y1': 303,\n",
       "    'y2': 354},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 93,\n",
       "    'x2': 123,\n",
       "    'y1': 305,\n",
       "    'y2': 358},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': True,\n",
       "    'x1': 75,\n",
       "    'x2': 91,\n",
       "    'y1': 322,\n",
       "    'y2': 350},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 50,\n",
       "    'x2': 93,\n",
       "    'y1': 345,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007406.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 68,\n",
       "    'x2': 447,\n",
       "    'y1': 15,\n",
       "    'y2': 314},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 440,\n",
       "    'x2': 483,\n",
       "    'y1': 3,\n",
       "    'y2': 112},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 86,\n",
       "    'y1': 2,\n",
       "    'y2': 204},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 101,\n",
       "    'x2': 128,\n",
       "    'y1': 1,\n",
       "    'y2': 71},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 122,\n",
       "    'x2': 180,\n",
       "    'y1': 1,\n",
       "    'y2': 76},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 397,\n",
       "    'x2': 418,\n",
       "    'y1': 4,\n",
       "    'y2': 50},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 414,\n",
       "    'x2': 426,\n",
       "    'y1': 1,\n",
       "    'y2': 48},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 421,\n",
       "    'x2': 444,\n",
       "    'y1': 1,\n",
       "    'y2': 58}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001085.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 415,\n",
       "    'x2': 500,\n",
       "    'y1': 169,\n",
       "    'y2': 303},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 189,\n",
       "    'y1': 245,\n",
       "    'y2': 375},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 87,\n",
       "    'x2': 368,\n",
       "    'y1': 176,\n",
       "    'y2': 310}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005498.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 158,\n",
       "    'x2': 331,\n",
       "    'y1': 247,\n",
       "    'y2': 375},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 390,\n",
       "    'x2': 500,\n",
       "    'y1': 274,\n",
       "    'y2': 353},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 10,\n",
       "    'x2': 83,\n",
       "    'y1': 268,\n",
       "    'y2': 330}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003265.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 148,\n",
       "    'x2': 267,\n",
       "    'y1': 197,\n",
       "    'y2': 346}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002644.jpg',\n",
       "  'height': 360,\n",
       "  'imageset': 'test',\n",
       "  'width': 268},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 210,\n",
       "    'x2': 308,\n",
       "    'y1': 226,\n",
       "    'y2': 286},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 137,\n",
       "    'x2': 224,\n",
       "    'y1': 225,\n",
       "    'y2': 287},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': True,\n",
       "    'x1': 76,\n",
       "    'x2': 167,\n",
       "    'y1': 237,\n",
       "    'y2': 293},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 36,\n",
       "    'x2': 150,\n",
       "    'y1': 245,\n",
       "    'y2': 324},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 229,\n",
       "    'x2': 286,\n",
       "    'y1': 183,\n",
       "    'y2': 270},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 153,\n",
       "    'x2': 213,\n",
       "    'y1': 180,\n",
       "    'y2': 279},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 100,\n",
       "    'x2': 154,\n",
       "    'y1': 186,\n",
       "    'y2': 245},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 61,\n",
       "    'x2': 138,\n",
       "    'y1': 195,\n",
       "    'y2': 296},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 425,\n",
       "    'x2': 461,\n",
       "    'y1': 179,\n",
       "    'y2': 228}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003542.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 75,\n",
       "    'x2': 466,\n",
       "    'y1': 88,\n",
       "    'y2': 375},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': True,\n",
       "    'x1': 195,\n",
       "    'x2': 483,\n",
       "    'y1': 302,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004412.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 178,\n",
       "    'x2': 295,\n",
       "    'y1': 289,\n",
       "    'y2': 361},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 100,\n",
       "    'x2': 182,\n",
       "    'y1': 264,\n",
       "    'y2': 320},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 305,\n",
       "    'x2': 408,\n",
       "    'y1': 264,\n",
       "    'y2': 353},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 199,\n",
       "    'x2': 348,\n",
       "    'y1': 261,\n",
       "    'y2': 322}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009225.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 322,\n",
       "    'x2': 372,\n",
       "    'y1': 155,\n",
       "    'y2': 203},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 294,\n",
       "    'x2': 357,\n",
       "    'y1': 211,\n",
       "    'y2': 310}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007564.jpg',\n",
       "  'height': 318,\n",
       "  'imageset': 'test',\n",
       "  'width': 422},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 305,\n",
       "    'x2': 450,\n",
       "    'y1': 115,\n",
       "    'y2': 281},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 49,\n",
       "    'x2': 112,\n",
       "    'y1': 112,\n",
       "    'y2': 178}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007348.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 190,\n",
       "    'x2': 287,\n",
       "    'y1': 1,\n",
       "    'y2': 70},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 387,\n",
       "    'x2': 488,\n",
       "    'y1': 1,\n",
       "    'y2': 96},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 60,\n",
       "    'y1': 10,\n",
       "    'y2': 88},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 11,\n",
       "    'x2': 317,\n",
       "    'y1': 109,\n",
       "    'y2': 297},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 107,\n",
       "    'x2': 316,\n",
       "    'y1': 49,\n",
       "    'y2': 283}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002830.jpg',\n",
       "  'height': 331,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 175,\n",
       "    'x2': 199,\n",
       "    'y1': 197,\n",
       "    'y2': 262},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 70,\n",
       "    'x2': 115,\n",
       "    'y1': 192,\n",
       "    'y2': 326},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 29,\n",
       "    'x2': 84,\n",
       "    'y1': 202,\n",
       "    'y2': 352},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 258,\n",
       "    'x2': 278,\n",
       "    'y1': 205,\n",
       "    'y2': 284},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 240,\n",
       "    'x2': 266,\n",
       "    'y1': 191,\n",
       "    'y2': 275},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 17,\n",
       "    'x2': 37,\n",
       "    'y1': 202,\n",
       "    'y2': 262}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005900.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 329,\n",
       "    'x2': 375,\n",
       "    'y1': 339,\n",
       "    'y2': 493},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 297,\n",
       "    'x2': 347,\n",
       "    'y1': 341,\n",
       "    'y2': 500},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 227,\n",
       "    'x2': 315,\n",
       "    'y1': 373,\n",
       "    'y2': 429},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 68,\n",
       "    'y1': 334,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007347.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 57,\n",
       "    'x2': 333,\n",
       "    'y1': 47,\n",
       "    'y2': 454}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007582.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 42,\n",
       "    'y1': 117,\n",
       "    'y2': 267},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 116,\n",
       "    'x2': 308,\n",
       "    'y1': 68,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 107,\n",
       "    'x2': 244,\n",
       "    'y1': 101,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 220,\n",
       "    'x2': 360,\n",
       "    'y1': 78,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 304,\n",
       "    'x2': 401,\n",
       "    'y1': 50,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 185,\n",
       "    'x2': 240,\n",
       "    'y1': 65,\n",
       "    'y2': 137}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008957.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 269,\n",
       "    'x2': 500,\n",
       "    'y1': 45,\n",
       "    'y2': 286},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 238,\n",
       "    'y1': 64,\n",
       "    'y2': 375},\n",
       "   {'class': 'dog',\n",
       "    'difficult': True,\n",
       "    'x1': 139,\n",
       "    'x2': 500,\n",
       "    'y1': 238,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 116,\n",
       "    'y1': 1,\n",
       "    'y2': 84}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008201.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 175,\n",
       "    'x2': 493,\n",
       "    'y1': 45,\n",
       "    'y2': 337}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008787.jpg',\n",
       "  'height': 349,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 47,\n",
       "    'x2': 153,\n",
       "    'y1': 124,\n",
       "    'y2': 213},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 310,\n",
       "    'x2': 419,\n",
       "    'y1': 147,\n",
       "    'y2': 236},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 210,\n",
       "    'x2': 472,\n",
       "    'y1': 188,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000994.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 57,\n",
       "    'x2': 500,\n",
       "    'y1': 14,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003227.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 374,\n",
       "    'x2': 500,\n",
       "    'y1': 247,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 348,\n",
       "    'x2': 465,\n",
       "    'y1': 208,\n",
       "    'y2': 375},\n",
       "   {'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 22,\n",
       "    'x2': 336,\n",
       "    'y1': 134,\n",
       "    'y2': 308}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001155.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 238,\n",
       "    'x2': 330,\n",
       "    'y1': 156,\n",
       "    'y2': 361},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 99,\n",
       "    'x2': 153,\n",
       "    'y1': 185,\n",
       "    'y2': 295},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 208,\n",
       "    'x2': 245,\n",
       "    'y1': 203,\n",
       "    'y2': 238},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 23,\n",
       "    'y1': 217,\n",
       "    'y2': 281},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 170,\n",
       "    'x2': 329,\n",
       "    'y1': 235,\n",
       "    'y2': 353},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': True,\n",
       "    'x1': 252,\n",
       "    'x2': 306,\n",
       "    'y1': 238,\n",
       "    'y2': 299},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 198,\n",
       "    'x2': 265,\n",
       "    'y1': 226,\n",
       "    'y2': 260},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 76,\n",
       "    'x2': 161,\n",
       "    'y1': 227,\n",
       "    'y2': 301},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': True,\n",
       "    'x1': 3,\n",
       "    'x2': 20,\n",
       "    'y1': 257,\n",
       "    'y2': 310}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008046.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 330},\n",
       " {'bboxes': [{'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 379,\n",
       "    'x2': 441,\n",
       "    'y1': 134,\n",
       "    'y2': 229},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 247,\n",
       "    'x2': 354,\n",
       "    'y1': 196,\n",
       "    'y2': 351},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 152,\n",
       "    'x2': 260,\n",
       "    'y1': 224,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 86,\n",
       "    'y1': 263,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 115,\n",
       "    'x2': 178,\n",
       "    'y1': 203,\n",
       "    'y2': 238},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 30,\n",
       "    'x2': 323,\n",
       "    'y1': 227,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005941.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 315,\n",
       "    'x2': 352,\n",
       "    'y1': 247,\n",
       "    'y2': 274},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 258,\n",
       "    'x2': 284,\n",
       "    'y1': 245,\n",
       "    'y2': 269},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 66,\n",
       "    'x2': 183,\n",
       "    'y1': 240,\n",
       "    'y2': 320},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 9,\n",
       "    'x2': 41,\n",
       "    'y1': 248,\n",
       "    'y2': 286}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004764.jpg',\n",
       "  'height': 342,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 337,\n",
       "    'x2': 497,\n",
       "    'y1': 159,\n",
       "    'y2': 234},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 337,\n",
       "    'x2': 439,\n",
       "    'y1': 205,\n",
       "    'y2': 270},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 100,\n",
       "    'x2': 322,\n",
       "    'y1': 174,\n",
       "    'y2': 239},\n",
       "   {'class': 'bird',\n",
       "    'difficult': True,\n",
       "    'x1': 231,\n",
       "    'x2': 286,\n",
       "    'y1': 156,\n",
       "    'y2': 196},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 119,\n",
       "    'x2': 231,\n",
       "    'y1': 218,\n",
       "    'y2': 301},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 7,\n",
       "    'x2': 118,\n",
       "    'y1': 253,\n",
       "    'y2': 340}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004373.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 35,\n",
       "    'x2': 500,\n",
       "    'y1': 2,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000442.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 139,\n",
       "    'x2': 460,\n",
       "    'y1': 1,\n",
       "    'y2': 309}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008007.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 5,\n",
       "    'x2': 500,\n",
       "    'y1': 172,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 158,\n",
       "    'x2': 320,\n",
       "    'y1': 28,\n",
       "    'y2': 224}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008945.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 158,\n",
       "    'x2': 417,\n",
       "    'y1': 116,\n",
       "    'y2': 331}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009061.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 315,\n",
       "    'y1': 26,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002877.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 231,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 373},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 171,\n",
       "    'x2': 360,\n",
       "    'y1': 44,\n",
       "    'y2': 353}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005323.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 44,\n",
       "    'x2': 389,\n",
       "    'y1': 46,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005580.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 115,\n",
       "    'x2': 220,\n",
       "    'y1': 204,\n",
       "    'y2': 436},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 80,\n",
       "    'x2': 253,\n",
       "    'y1': 67,\n",
       "    'y2': 404}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003304.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 326},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 251,\n",
       "    'x2': 298,\n",
       "    'y1': 115,\n",
       "    'y2': 217}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001667.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 4,\n",
       "    'x2': 158,\n",
       "    'y1': 54,\n",
       "    'y2': 223}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002356.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 118,\n",
       "    'x2': 155,\n",
       "    'y1': 145,\n",
       "    'y2': 259},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 79,\n",
       "    'x2': 119,\n",
       "    'y1': 170,\n",
       "    'y2': 255},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 340,\n",
       "    'x2': 453,\n",
       "    'y1': 116,\n",
       "    'y2': 175},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 236,\n",
       "    'x2': 320,\n",
       "    'y1': 148,\n",
       "    'y2': 184},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 193,\n",
       "    'x2': 245,\n",
       "    'y1': 152,\n",
       "    'y2': 185}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009665.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 19,\n",
       "    'x2': 400,\n",
       "    'y1': 53,\n",
       "    'y2': 299},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 105,\n",
       "    'x2': 178,\n",
       "    'y1': 1,\n",
       "    'y2': 59},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 267,\n",
       "    'x2': 337,\n",
       "    'y1': 3,\n",
       "    'y2': 100},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 287,\n",
       "    'x2': 367,\n",
       "    'y1': 1,\n",
       "    'y2': 117}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008257.jpg',\n",
       "  'height': 299,\n",
       "  'imageset': 'test',\n",
       "  'width': 400},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 149,\n",
       "    'x2': 397,\n",
       "    'y1': 149,\n",
       "    'y2': 360},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 132,\n",
       "    'y1': 158,\n",
       "    'y2': 345}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008994.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 11,\n",
       "    'x2': 339,\n",
       "    'y1': 35,\n",
       "    'y2': 188}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009096.jpg',\n",
       "  'height': 208,\n",
       "  'imageset': 'test',\n",
       "  'width': 344},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 37,\n",
       "    'y1': 291,\n",
       "    'y2': 338},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 43,\n",
       "    'x2': 91,\n",
       "    'y1': 239,\n",
       "    'y2': 334}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002016.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 388,\n",
       "    'x2': 458,\n",
       "    'y1': 72,\n",
       "    'y2': 201},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 327,\n",
       "    'x2': 419,\n",
       "    'y1': 102,\n",
       "    'y2': 252},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 76,\n",
       "    'x2': 303,\n",
       "    'y1': 100,\n",
       "    'y2': 281},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 324,\n",
       "    'x2': 372,\n",
       "    'y1': 50,\n",
       "    'y2': 109}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005589.jpg',\n",
       "  'height': 281,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 224,\n",
       "    'x2': 265,\n",
       "    'y1': 199,\n",
       "    'y2': 277},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 284,\n",
       "    'x2': 316,\n",
       "    'y1': 198,\n",
       "    'y2': 298},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': True,\n",
       "    'x1': 226,\n",
       "    'x2': 264,\n",
       "    'y1': 231,\n",
       "    'y2': 294}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001396.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 38,\n",
       "    'x2': 334,\n",
       "    'y1': 50,\n",
       "    'y2': 441}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008394.jpg',\n",
       "  'height': 473,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 278,\n",
       "    'x2': 389,\n",
       "    'y1': 74,\n",
       "    'y2': 225}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005198.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 82,\n",
       "    'x2': 402,\n",
       "    'y1': 121,\n",
       "    'y2': 365}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007955.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 139,\n",
       "    'x2': 500,\n",
       "    'y1': 3,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006728.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 14,\n",
       "    'x2': 479,\n",
       "    'y1': 104,\n",
       "    'y2': 321},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 394,\n",
       "    'x2': 434,\n",
       "    'y1': 337,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000277.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 209,\n",
       "    'x2': 274,\n",
       "    'y1': 104,\n",
       "    'y2': 140}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005022.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 196,\n",
       "    'x2': 440,\n",
       "    'y1': 27,\n",
       "    'y2': 299}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001123.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 47,\n",
       "    'x2': 461,\n",
       "    'y1': 22,\n",
       "    'y2': 327}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006942.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 275,\n",
       "    'x2': 341,\n",
       "    'y1': 89,\n",
       "    'y2': 256},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 382,\n",
       "    'x2': 460,\n",
       "    'y1': 178,\n",
       "    'y2': 283}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000734.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 181,\n",
       "    'x2': 341,\n",
       "    'y1': 132,\n",
       "    'y2': 277}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002968.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 210,\n",
       "    'x2': 327,\n",
       "    'y1': 37,\n",
       "    'y2': 374},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 313,\n",
       "    'x2': 433,\n",
       "    'y1': 79,\n",
       "    'y2': 372}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002079.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 20,\n",
       "    'x2': 240,\n",
       "    'y1': 68,\n",
       "    'y2': 307}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001087.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 250},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 373,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 141},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': True,\n",
       "    'x1': 294,\n",
       "    'x2': 403,\n",
       "    'y1': 252,\n",
       "    'y2': 334},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 35,\n",
       "    'x2': 347,\n",
       "    'y1': 35,\n",
       "    'y2': 334},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 38,\n",
       "    'y1': 209,\n",
       "    'y2': 275}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008362.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 277,\n",
       "    'x2': 325,\n",
       "    'y1': 167,\n",
       "    'y2': 291},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 153,\n",
       "    'x2': 168,\n",
       "    'y1': 210,\n",
       "    'y2': 261},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 167,\n",
       "    'x2': 181,\n",
       "    'y1': 213,\n",
       "    'y2': 258},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 181,\n",
       "    'x2': 199,\n",
       "    'y1': 209,\n",
       "    'y2': 259},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 109,\n",
       "    'x2': 130,\n",
       "    'y1': 219,\n",
       "    'y2': 270},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 73,\n",
       "    'x2': 95,\n",
       "    'y1': 194,\n",
       "    'y2': 268},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 66,\n",
       "    'y1': 218,\n",
       "    'y2': 296},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 206,\n",
       "    'x2': 265,\n",
       "    'y1': 135,\n",
       "    'y2': 320},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 136,\n",
       "    'x2': 153,\n",
       "    'y1': 209,\n",
       "    'y2': 259},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 198,\n",
       "    'x2': 213,\n",
       "    'y1': 196,\n",
       "    'y2': 267}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008271.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 310,\n",
       "    'y1': 125,\n",
       "    'y2': 421}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006127.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 205,\n",
       "    'x2': 294,\n",
       "    'y1': 92,\n",
       "    'y2': 373},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 291,\n",
       "    'x2': 422,\n",
       "    'y1': 110,\n",
       "    'y2': 307},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 398,\n",
       "    'x2': 500,\n",
       "    'y1': 8,\n",
       "    'y2': 164},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 54,\n",
       "    'x2': 263,\n",
       "    'y1': 39,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 68,\n",
       "    'y1': 78,\n",
       "    'y2': 374},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 82,\n",
       "    'y1': 66,\n",
       "    'y2': 373},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 382,\n",
       "    'x2': 500,\n",
       "    'y1': 107,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003959.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 164,\n",
       "    'x2': 227,\n",
       "    'y1': 54,\n",
       "    'y2': 195},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 69,\n",
       "    'x2': 298,\n",
       "    'y1': 103,\n",
       "    'y2': 284},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 276,\n",
       "    'x2': 361,\n",
       "    'y1': 77,\n",
       "    'y2': 144},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 306,\n",
       "    'x2': 327,\n",
       "    'y1': 59,\n",
       "    'y2': 116},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 372,\n",
       "    'x2': 387,\n",
       "    'y1': 88,\n",
       "    'y2': 133},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 470,\n",
       "    'x2': 483,\n",
       "    'y1': 98,\n",
       "    'y2': 131},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 408,\n",
       "    'x2': 431,\n",
       "    'y1': 96,\n",
       "    'y2': 133},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 386,\n",
       "    'x2': 407,\n",
       "    'y1': 100,\n",
       "    'y2': 132},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 151,\n",
       "    'x2': 167,\n",
       "    'y1': 106,\n",
       "    'y2': 140},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 105,\n",
       "    'x2': 125,\n",
       "    'y1': 106,\n",
       "    'y2': 142},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 88,\n",
       "    'x2': 108,\n",
       "    'y1': 112,\n",
       "    'y2': 142},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 70,\n",
       "    'x2': 84,\n",
       "    'y1': 98,\n",
       "    'y2': 114},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 62,\n",
       "    'x2': 85,\n",
       "    'y1': 105,\n",
       "    'y2': 144},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 44,\n",
       "    'x2': 65,\n",
       "    'y1': 109,\n",
       "    'y2': 142},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 26,\n",
       "    'x2': 46,\n",
       "    'y1': 112,\n",
       "    'y2': 146},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 19,\n",
       "    'y1': 101,\n",
       "    'y2': 145},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 36,\n",
       "    'x2': 48,\n",
       "    'y1': 109,\n",
       "    'y2': 125},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 92,\n",
       "    'x2': 112,\n",
       "    'y1': 73,\n",
       "    'y2': 89},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 91,\n",
       "    'x2': 108,\n",
       "    'y1': 91,\n",
       "    'y2': 108},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 253,\n",
       "    'x2': 270,\n",
       "    'y1': 89,\n",
       "    'y2': 110}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004006.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': True,\n",
       "    'x1': 2,\n",
       "    'x2': 498,\n",
       "    'y1': 4,\n",
       "    'y2': 375},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 68,\n",
       "    'x2': 352,\n",
       "    'y1': 76,\n",
       "    'y2': 300}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007312.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 308,\n",
       "    'x2': 356,\n",
       "    'y1': 131,\n",
       "    'y2': 173},\n",
       "   {'class': 'dog',\n",
       "    'difficult': True,\n",
       "    'x1': 224,\n",
       "    'x2': 274,\n",
       "    'y1': 143,\n",
       "    'y2': 182},\n",
       "   {'class': 'dog',\n",
       "    'difficult': True,\n",
       "    'x1': 270,\n",
       "    'x2': 298,\n",
       "    'y1': 125,\n",
       "    'y2': 153}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000086.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 62,\n",
       "    'x2': 396,\n",
       "    'y1': 28,\n",
       "    'y2': 351}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002876.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 333,\n",
       "    'x2': 440,\n",
       "    'y1': 269,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 8,\n",
       "    'x2': 227,\n",
       "    'y1': 277,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 70,\n",
       "    'x2': 193,\n",
       "    'y1': 242,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007756.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 45,\n",
       "    'x2': 120,\n",
       "    'y1': 134,\n",
       "    'y2': 340},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 33,\n",
       "    'y1': 153,\n",
       "    'y2': 351},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 106,\n",
       "    'x2': 167,\n",
       "    'y1': 131,\n",
       "    'y2': 273},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 119,\n",
       "    'x2': 224,\n",
       "    'y1': 127,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 196,\n",
       "    'x2': 331,\n",
       "    'y1': 101,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 440,\n",
       "    'x2': 500,\n",
       "    'y1': 255,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 398,\n",
       "    'x2': 470,\n",
       "    'y1': 308,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002087.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 206,\n",
       "    'x2': 401,\n",
       "    'y1': 110,\n",
       "    'y2': 302}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001114.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 74,\n",
       "    'x2': 239,\n",
       "    'y1': 104,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006788.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 178,\n",
       "    'x2': 500,\n",
       "    'y1': 11,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 499,\n",
       "    'y1': 2,\n",
       "    'y2': 332}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004934.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 172,\n",
       "    'y1': 119,\n",
       "    'y2': 410},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 26,\n",
       "    'x2': 168,\n",
       "    'y1': 248,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008027.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 12,\n",
       "    'x2': 457,\n",
       "    'y1': 86,\n",
       "    'y2': 328}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001089.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 19,\n",
       "    'x2': 359,\n",
       "    'y1': 167,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 207,\n",
       "    'x2': 254,\n",
       "    'y1': 105,\n",
       "    'y2': 194},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 272,\n",
       "    'x2': 342,\n",
       "    'y1': 105,\n",
       "    'y2': 177},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 341,\n",
       "    'x2': 380,\n",
       "    'y1': 120,\n",
       "    'y2': 184},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 355,\n",
       "    'x2': 407,\n",
       "    'y1': 127,\n",
       "    'y2': 212},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 348,\n",
       "    'x2': 437,\n",
       "    'y1': 163,\n",
       "    'y2': 314},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 346,\n",
       "    'x2': 480,\n",
       "    'y1': 170,\n",
       "    'y2': 373},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 167,\n",
       "    'x2': 248,\n",
       "    'y1': 116,\n",
       "    'y2': 217},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 126,\n",
       "    'x2': 205,\n",
       "    'y1': 121,\n",
       "    'y2': 236},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 67,\n",
       "    'x2': 195,\n",
       "    'y1': 128,\n",
       "    'y2': 278},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 15,\n",
       "    'x2': 125,\n",
       "    'y1': 170,\n",
       "    'y2': 344},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 92,\n",
       "    'y1': 181,\n",
       "    'y2': 373}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000744.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 140,\n",
       "    'x2': 401,\n",
       "    'y1': 70,\n",
       "    'y2': 262},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 114,\n",
       "    'x2': 253,\n",
       "    'y1': 96,\n",
       "    'y2': 357}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005218.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 51,\n",
       "    'x2': 83,\n",
       "    'y1': 51,\n",
       "    'y2': 150},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 84,\n",
       "    'x2': 117,\n",
       "    'y1': 51,\n",
       "    'y2': 150},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 117,\n",
       "    'x2': 149,\n",
       "    'y1': 45,\n",
       "    'y2': 152},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 151,\n",
       "    'x2': 182,\n",
       "    'y1': 47,\n",
       "    'y2': 151},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 182,\n",
       "    'x2': 213,\n",
       "    'y1': 47,\n",
       "    'y2': 150},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 214,\n",
       "    'x2': 246,\n",
       "    'y1': 46,\n",
       "    'y2': 150},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 246,\n",
       "    'x2': 279,\n",
       "    'y1': 46,\n",
       "    'y2': 151},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 279,\n",
       "    'x2': 311,\n",
       "    'y1': 47,\n",
       "    'y2': 151},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 311,\n",
       "    'x2': 343,\n",
       "    'y1': 47,\n",
       "    'y2': 151},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 61,\n",
       "    'x2': 85,\n",
       "    'y1': 217,\n",
       "    'y2': 282},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 118,\n",
       "    'x2': 150,\n",
       "    'y1': 212,\n",
       "    'y2': 281},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 150,\n",
       "    'x2': 181,\n",
       "    'y1': 214,\n",
       "    'y2': 281},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 181,\n",
       "    'x2': 213,\n",
       "    'y1': 214,\n",
       "    'y2': 281},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 213,\n",
       "    'x2': 245,\n",
       "    'y1': 217,\n",
       "    'y2': 281},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 245,\n",
       "    'x2': 276,\n",
       "    'y1': 215,\n",
       "    'y2': 281},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 276,\n",
       "    'x2': 305,\n",
       "    'y1': 217,\n",
       "    'y2': 281},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 213,\n",
       "    'x2': 243,\n",
       "    'y1': 307,\n",
       "    'y2': 369},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 243,\n",
       "    'x2': 274,\n",
       "    'y1': 308,\n",
       "    'y2': 369},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 274,\n",
       "    'x2': 304,\n",
       "    'y1': 308,\n",
       "    'y2': 367}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003076.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 305,\n",
       "    'x2': 493,\n",
       "    'y1': 69,\n",
       "    'y2': 276},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 221,\n",
       "    'y1': 115,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008646.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 61,\n",
       "    'x2': 373,\n",
       "    'y1': 64,\n",
       "    'y2': 322}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008685.jpg',\n",
       "  'height': 372,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 10,\n",
       "    'x2': 305,\n",
       "    'y1': 52,\n",
       "    'y2': 264}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003535.jpg',\n",
       "  'height': 276,\n",
       "  'imageset': 'test',\n",
       "  'width': 347},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 94,\n",
       "    'x2': 312,\n",
       "    'y1': 32,\n",
       "    'y2': 320}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001257.jpg',\n",
       "  'height': 320,\n",
       "  'imageset': 'test',\n",
       "  'width': 427},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 470,\n",
       "    'y1': 30,\n",
       "    'y2': 375},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 132,\n",
       "    'y1': 70,\n",
       "    'y2': 238}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001552.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 295,\n",
       "    'x2': 435,\n",
       "    'y1': 215,\n",
       "    'y2': 315},\n",
       "   {'class': 'cow',\n",
       "    'difficult': True,\n",
       "    'x1': 411,\n",
       "    'x2': 459,\n",
       "    'y1': 212,\n",
       "    'y2': 291},\n",
       "   {'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 207,\n",
       "    'x2': 267,\n",
       "    'y1': 209,\n",
       "    'y2': 280},\n",
       "   {'class': 'cow',\n",
       "    'difficult': True,\n",
       "    'x1': 49,\n",
       "    'x2': 78,\n",
       "    'y1': 205,\n",
       "    'y2': 256}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005335.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 315,\n",
       "    'y1': 151,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008570.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 291,\n",
       "    'x2': 408,\n",
       "    'y1': 258,\n",
       "    'y2': 361},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 323,\n",
       "    'x2': 433,\n",
       "    'y1': 72,\n",
       "    'y2': 280},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 138,\n",
       "    'x2': 317,\n",
       "    'y1': 172,\n",
       "    'y2': 354},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 339,\n",
       "    'y1': 43,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001657.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 100,\n",
       "    'x2': 329,\n",
       "    'y1': 4,\n",
       "    'y2': 145},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 38,\n",
       "    'x2': 394,\n",
       "    'y1': 105,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009688.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 109,\n",
       "    'y1': 180,\n",
       "    'y2': 366},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 227,\n",
       "    'x2': 448,\n",
       "    'y1': 128,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 67,\n",
       "    'x2': 230,\n",
       "    'y1': 120,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 43,\n",
       "    'y1': 92,\n",
       "    'y2': 182},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 410,\n",
       "    'x2': 484,\n",
       "    'y1': 225,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 130,\n",
       "    'x2': 383,\n",
       "    'y1': 92,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006830.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 154,\n",
       "    'x2': 289,\n",
       "    'y1': 82,\n",
       "    'y2': 188}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008334.jpg',\n",
       "  'height': 199,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 500,\n",
       "    'y1': 84,\n",
       "    'y2': 361}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003920.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 2,\n",
       "    'x2': 500,\n",
       "    'y1': 247,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 113,\n",
       "    'x2': 437,\n",
       "    'y1': 1,\n",
       "    'y2': 257},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 462,\n",
       "    'x2': 500,\n",
       "    'y1': 69,\n",
       "    'y2': 239}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008719.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 277,\n",
       "    'x2': 454,\n",
       "    'y1': 143,\n",
       "    'y2': 423},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 269,\n",
       "    'y1': 67,\n",
       "    'y2': 433}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002046.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 454},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 183,\n",
       "    'x2': 500,\n",
       "    'y1': 51,\n",
       "    'y2': 340},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 209,\n",
       "    'y1': 1,\n",
       "    'y2': 242}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006894.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 93,\n",
       "    'x2': 435,\n",
       "    'y1': 71,\n",
       "    'y2': 316}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001820.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 167,\n",
       "    'x2': 204,\n",
       "    'y1': 139,\n",
       "    'y2': 253},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 318,\n",
       "    'x2': 329,\n",
       "    'y1': 160,\n",
       "    'y2': 182},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 367,\n",
       "    'x2': 399,\n",
       "    'y1': 158,\n",
       "    'y2': 177},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 96,\n",
       "    'x2': 475,\n",
       "    'y1': 86,\n",
       "    'y2': 187}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007267.jpg',\n",
       "  'height': 292,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 176,\n",
       "    'x2': 335,\n",
       "    'y1': 160,\n",
       "    'y2': 291},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 183,\n",
       "    'y1': 132,\n",
       "    'y2': 308},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 291,\n",
       "    'x2': 326,\n",
       "    'y1': 102,\n",
       "    'y2': 136},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 267,\n",
       "    'x2': 303,\n",
       "    'y1': 114,\n",
       "    'y2': 135}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000291.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 278,\n",
       "    'x2': 351,\n",
       "    'y1': 184,\n",
       "    'y2': 291},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 150,\n",
       "    'x2': 228,\n",
       "    'y1': 195,\n",
       "    'y2': 305},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 144,\n",
       "    'x2': 217,\n",
       "    'y1': 254,\n",
       "    'y2': 368},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 257,\n",
       "    'x2': 292,\n",
       "    'y1': 150,\n",
       "    'y2': 192},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 143,\n",
       "    'x2': 190,\n",
       "    'y1': 156,\n",
       "    'y2': 206},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 26,\n",
       "    'y1': 163,\n",
       "    'y2': 217}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001138.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 500,\n",
       "    'y1': 2,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 185,\n",
       "    'x2': 335,\n",
       "    'y1': 157,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 175,\n",
       "    'x2': 209,\n",
       "    'y1': 198,\n",
       "    'y2': 229},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 44,\n",
       "    'x2': 90,\n",
       "    'y1': 192,\n",
       "    'y2': 229},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 120,\n",
       "    'x2': 134,\n",
       "    'y1': 167,\n",
       "    'y2': 186}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009885.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 118,\n",
       "    'x2': 382,\n",
       "    'y1': 24,\n",
       "    'y2': 301},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 140,\n",
       "    'x2': 264,\n",
       "    'y1': 134,\n",
       "    'y2': 340}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004807.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 218,\n",
       "    'x2': 347,\n",
       "    'y1': 126,\n",
       "    'y2': 214},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 17,\n",
       "    'x2': 34,\n",
       "    'y1': 28,\n",
       "    'y2': 67},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 40,\n",
       "    'x2': 57,\n",
       "    'y1': 27,\n",
       "    'y2': 68}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007992.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 58,\n",
       "    'x2': 392,\n",
       "    'y1': 121,\n",
       "    'y2': 334},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 191,\n",
       "    'x2': 340,\n",
       "    'y1': 19,\n",
       "    'y2': 344}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003538.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 52,\n",
       "    'x2': 324,\n",
       "    'y1': 303,\n",
       "    'y2': 500},\n",
       "   {'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 355,\n",
       "    'y1': 24,\n",
       "    'y2': 323}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000638.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 330,\n",
       "    'x2': 354,\n",
       "    'y1': 116,\n",
       "    'y2': 159},\n",
       "   {'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 336,\n",
       "    'x2': 381,\n",
       "    'y1': 220,\n",
       "    'y2': 256}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006110.jpg',\n",
       "  'height': 323,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 89,\n",
       "    'x2': 445,\n",
       "    'y1': 74,\n",
       "    'y2': 366},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 201,\n",
       "    'x2': 313,\n",
       "    'y1': 35,\n",
       "    'y2': 220}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002409.jpg',\n",
       "  'height': 385,\n",
       "  'imageset': 'test',\n",
       "  'width': 480},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 274,\n",
       "    'x2': 348,\n",
       "    'y1': 132,\n",
       "    'y2': 151}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009120.jpg',\n",
       "  'height': 242,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 500,\n",
       "    'y1': 45,\n",
       "    'y2': 227},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 137,\n",
       "    'x2': 191,\n",
       "    'y1': 213,\n",
       "    'y2': 255}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001080.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 358,\n",
       "    'y1': 132,\n",
       "    'y2': 209},\n",
       "   {'class': 'train',\n",
       "    'difficult': True,\n",
       "    'x1': 325,\n",
       "    'x2': 500,\n",
       "    'y1': 88,\n",
       "    'y2': 205}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008412.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 12,\n",
       "    'x2': 485,\n",
       "    'y1': 125,\n",
       "    'y2': 231}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005238.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 66,\n",
       "    'x2': 372,\n",
       "    'y1': 149,\n",
       "    'y2': 319}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006741.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 188,\n",
       "    'x2': 248,\n",
       "    'y1': 223,\n",
       "    'y2': 305},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 149,\n",
       "    'x2': 214,\n",
       "    'y1': 233,\n",
       "    'y2': 310},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 53,\n",
       "    'y1': 179,\n",
       "    'y2': 344}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002161.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 334,\n",
       "    'x2': 436,\n",
       "    'y1': 1,\n",
       "    'y2': 373},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 196,\n",
       "    'x2': 309,\n",
       "    'y1': 80,\n",
       "    'y2': 326},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 279,\n",
       "    'x2': 334,\n",
       "    'y1': 53,\n",
       "    'y2': 267},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 29,\n",
       "    'x2': 359,\n",
       "    'y1': 109,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000058.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 36,\n",
       "    'x2': 375,\n",
       "    'y1': 92,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007158.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 264,\n",
       "    'x2': 500,\n",
       "    'y1': 79,\n",
       "    'y2': 181}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002998.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 50,\n",
       "    'x2': 186,\n",
       "    'y1': 1,\n",
       "    'y2': 278},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 177,\n",
       "    'x2': 331,\n",
       "    'y1': 1,\n",
       "    'y2': 294},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 315,\n",
       "    'x2': 375,\n",
       "    'y1': 34,\n",
       "    'y2': 362}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006092.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 8,\n",
       "    'x2': 186,\n",
       "    'y1': 238,\n",
       "    'y2': 340},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 180,\n",
       "    'x2': 254,\n",
       "    'y1': 226,\n",
       "    'y2': 290},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 242,\n",
       "    'x2': 286,\n",
       "    'y1': 217,\n",
       "    'y2': 262},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 263,\n",
       "    'x2': 312,\n",
       "    'y1': 202,\n",
       "    'y2': 245},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 358,\n",
       "    'x2': 385,\n",
       "    'y1': 212,\n",
       "    'y2': 283},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 413,\n",
       "    'x2': 448,\n",
       "    'y1': 219,\n",
       "    'y2': 305},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 389,\n",
       "    'x2': 420,\n",
       "    'y1': 209,\n",
       "    'y2': 287}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004810.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 116,\n",
       "    'x2': 381,\n",
       "    'y1': 17,\n",
       "    'y2': 245},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 312,\n",
       "    'x2': 345,\n",
       "    'y1': 59,\n",
       "    'y2': 111},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 304,\n",
       "    'x2': 323,\n",
       "    'y1': 52,\n",
       "    'y2': 86},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 188,\n",
       "    'x2': 207,\n",
       "    'y1': 45,\n",
       "    'y2': 80},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 370,\n",
       "    'x2': 417,\n",
       "    'y1': 69,\n",
       "    'y2': 125},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 330,\n",
       "    'x2': 373,\n",
       "    'y1': 68,\n",
       "    'y2': 155},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 167,\n",
       "    'x2': 197,\n",
       "    'y1': 60,\n",
       "    'y2': 106}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006274.jpg',\n",
       "  'height': 245,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 229,\n",
       "    'x2': 440,\n",
       "    'y1': 114,\n",
       "    'y2': 218},\n",
       "   {'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 92,\n",
       "    'x2': 288,\n",
       "    'y1': 89,\n",
       "    'y2': 213}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005950.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 407,\n",
       "    'x2': 461,\n",
       "    'y1': 114,\n",
       "    'y2': 195},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 100,\n",
       "    'x2': 341,\n",
       "    'y1': 152,\n",
       "    'y2': 338}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005767.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 61,\n",
       "    'x2': 500,\n",
       "    'y1': 22,\n",
       "    'y2': 335}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006168.jpg',\n",
       "  'height': 335,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 75,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 261},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 135,\n",
       "    'x2': 370,\n",
       "    'y1': 133,\n",
       "    'y2': 293}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009103.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 11,\n",
       "    'x2': 496,\n",
       "    'y1': 59,\n",
       "    'y2': 255}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002521.jpg',\n",
       "  'height': 284,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 269}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006194.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 84,\n",
       "    'x2': 198,\n",
       "    'y1': 82,\n",
       "    'y2': 186},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 61,\n",
       "    'y1': 2,\n",
       "    'y2': 73},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 121,\n",
       "    'x2': 368,\n",
       "    'y1': 78,\n",
       "    'y2': 360}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009561.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 24,\n",
       "    'x2': 204,\n",
       "    'y1': 81,\n",
       "    'y2': 222},\n",
       "   {'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 256,\n",
       "    'x2': 452,\n",
       "    'y1': 116,\n",
       "    'y2': 269}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000928.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 22,\n",
       "    'x2': 324,\n",
       "    'y1': 18,\n",
       "    'y2': 454},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 7,\n",
       "    'x2': 22,\n",
       "    'y1': 273,\n",
       "    'y2': 305},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 333,\n",
       "    'x2': 345,\n",
       "    'y1': 292,\n",
       "    'y2': 374},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 301,\n",
       "    'x2': 332,\n",
       "    'y1': 354,\n",
       "    'y2': 391}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007726.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 345},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 351,\n",
       "    'x2': 450,\n",
       "    'y1': 65,\n",
       "    'y2': 161},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 18,\n",
       "    'x2': 231,\n",
       "    'y1': 107,\n",
       "    'y2': 344}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005827.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 157,\n",
       "    'x2': 290,\n",
       "    'y1': 225,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 243,\n",
       "    'x2': 358,\n",
       "    'y1': 70,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 165,\n",
       "    'x2': 254,\n",
       "    'y1': 80,\n",
       "    'y2': 375},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 250,\n",
       "    'x2': 268,\n",
       "    'y1': 176,\n",
       "    'y2': 233}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003867.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 298,\n",
       "    'x2': 343,\n",
       "    'y1': 131,\n",
       "    'y2': 268},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 407,\n",
       "    'y1': 206,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005357.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 180,\n",
       "    'x2': 231,\n",
       "    'y1': 99,\n",
       "    'y2': 305},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 404,\n",
       "    'x2': 500,\n",
       "    'y1': 143,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 248,\n",
       "    'x2': 397,\n",
       "    'y1': 213,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 219,\n",
       "    'x2': 300,\n",
       "    'y1': 192,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006659.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 174,\n",
       "    'x2': 324,\n",
       "    'y1': 229,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 5,\n",
       "    'x2': 250,\n",
       "    'y1': 145,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 19,\n",
       "    'x2': 323,\n",
       "    'y1': 6,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000043.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 94,\n",
       "    'x2': 378,\n",
       "    'y1': 54,\n",
       "    'y2': 306}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005802.jpg',\n",
       "  'height': 430,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 61,\n",
       "    'x2': 298,\n",
       "    'y1': 101,\n",
       "    'y2': 488}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006494.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 2,\n",
       "    'x2': 500,\n",
       "    'y1': 97,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 309,\n",
       "    'y1': 14,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 244,\n",
       "    'x2': 465,\n",
       "    'y1': 1,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 154,\n",
       "    'x2': 302,\n",
       "    'y1': 152,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008918.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 3,\n",
       "    'x2': 500,\n",
       "    'y1': 163,\n",
       "    'y2': 373},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 22,\n",
       "    'x2': 87,\n",
       "    'y1': 128,\n",
       "    'y2': 277},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 17,\n",
       "    'x2': 433,\n",
       "    'y1': 17,\n",
       "    'y2': 172},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 300,\n",
       "    'x2': 417,\n",
       "    'y1': 3,\n",
       "    'y2': 163}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001431.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 47,\n",
       "    'x2': 385,\n",
       "    'y1': 92,\n",
       "    'y2': 343},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 55,\n",
       "    'y1': 214,\n",
       "    'y2': 349},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 259,\n",
       "    'x2': 298,\n",
       "    'y1': 139,\n",
       "    'y2': 222}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006407.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 450,\n",
       "    'x2': 496,\n",
       "    'y1': 88,\n",
       "    'y2': 216},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 358,\n",
       "    'x2': 409,\n",
       "    'y1': 114,\n",
       "    'y2': 223},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 160,\n",
       "    'x2': 444,\n",
       "    'y1': 8,\n",
       "    'y2': 229},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 122,\n",
       "    'x2': 261,\n",
       "    'y1': 94,\n",
       "    'y2': 223},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 96,\n",
       "    'x2': 162,\n",
       "    'y1': 216,\n",
       "    'y2': 344},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 26,\n",
       "    'x2': 189,\n",
       "    'y1': 93,\n",
       "    'y2': 229}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002743.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 28,\n",
       "    'x2': 287,\n",
       "    'y1': 84,\n",
       "    'y2': 314},\n",
       "   {'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 76,\n",
       "    'x2': 418,\n",
       "    'y1': 41,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000741.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 99,\n",
       "    'x2': 468,\n",
       "    'y1': 36,\n",
       "    'y2': 301}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001788.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 447,\n",
       "    'y1': 21,\n",
       "    'y2': 325}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002936.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 87,\n",
       "    'x2': 308,\n",
       "    'y1': 84,\n",
       "    'y2': 314},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 455,\n",
       "    'x2': 500,\n",
       "    'y1': 54,\n",
       "    'y2': 110},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 233,\n",
       "    'x2': 275,\n",
       "    'y1': 180,\n",
       "    'y2': 252}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002062.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 12,\n",
       "    'x2': 166,\n",
       "    'y1': 169,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 44,\n",
       "    'x2': 407,\n",
       "    'y1': 79,\n",
       "    'y2': 357}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002687.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 286,\n",
       "    'x2': 351,\n",
       "    'y1': 271,\n",
       "    'y2': 330},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 102,\n",
       "    'x2': 139,\n",
       "    'y1': 261,\n",
       "    'y2': 329},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 209,\n",
       "    'x2': 262,\n",
       "    'y1': 149,\n",
       "    'y2': 275},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 257,\n",
       "    'x2': 296,\n",
       "    'y1': 149,\n",
       "    'y2': 280},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 282,\n",
       "    'x2': 375,\n",
       "    'y1': 165,\n",
       "    'y2': 331},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 57,\n",
       "    'x2': 122,\n",
       "    'y1': 179,\n",
       "    'y2': 330}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001366.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 44,\n",
       "    'x2': 450,\n",
       "    'y1': 72,\n",
       "    'y2': 210}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000067.jpg',\n",
       "  'height': 272,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 103,\n",
       "    'x2': 122,\n",
       "    'y1': 158,\n",
       "    'y2': 181},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 9,\n",
       "    'x2': 46,\n",
       "    'y1': 189,\n",
       "    'y2': 252},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 36,\n",
       "    'x2': 74,\n",
       "    'y1': 192,\n",
       "    'y2': 260},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 43,\n",
       "    'y1': 299,\n",
       "    'y2': 375},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 112,\n",
       "    'x2': 471,\n",
       "    'y1': 183,\n",
       "    'y2': 328},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 107,\n",
       "    'x2': 243,\n",
       "    'y1': 146,\n",
       "    'y2': 196}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001222.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 205,\n",
       "    'y1': 107,\n",
       "    'y2': 375},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 100,\n",
       "    'y1': 36,\n",
       "    'y2': 138},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 180,\n",
       "    'x2': 311,\n",
       "    'y1': 17,\n",
       "    'y2': 131},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 302,\n",
       "    'x2': 429,\n",
       "    'y1': 34,\n",
       "    'y2': 173},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 419,\n",
       "    'x2': 500,\n",
       "    'y1': 64,\n",
       "    'y2': 261},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 83,\n",
       "    'x2': 196,\n",
       "    'y1': 31,\n",
       "    'y2': 131}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008954.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 24,\n",
       "    'x2': 256,\n",
       "    'y1': 47,\n",
       "    'y2': 182},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 141,\n",
       "    'x2': 199,\n",
       "    'y1': 22,\n",
       "    'y2': 132}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003232.jpg',\n",
       "  'height': 223,\n",
       "  'imageset': 'test',\n",
       "  'width': 320},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 75,\n",
       "    'x2': 104,\n",
       "    'y1': 61,\n",
       "    'y2': 144},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 153,\n",
       "    'x2': 190,\n",
       "    'y1': 64,\n",
       "    'y2': 243},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 243,\n",
       "    'x2': 261,\n",
       "    'y1': 67,\n",
       "    'y2': 241},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 351,\n",
       "    'x2': 386,\n",
       "    'y1': 68,\n",
       "    'y2': 241},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 483,\n",
       "    'x2': 500,\n",
       "    'y1': 115,\n",
       "    'y2': 311},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 452,\n",
       "    'x2': 488,\n",
       "    'y1': 57,\n",
       "    'y2': 268},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 366,\n",
       "    'x2': 412,\n",
       "    'y1': 57,\n",
       "    'y2': 270},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 392,\n",
       "    'x2': 461,\n",
       "    'y1': 40,\n",
       "    'y2': 317},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 291,\n",
       "    'x2': 354,\n",
       "    'y1': 40,\n",
       "    'y2': 313},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 193,\n",
       "    'x2': 259,\n",
       "    'y1': 39,\n",
       "    'y2': 313},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 29,\n",
       "    'x2': 86,\n",
       "    'y1': 50,\n",
       "    'y2': 272},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 82,\n",
       "    'x2': 150,\n",
       "    'y1': 35,\n",
       "    'y2': 312},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 39,\n",
       "    'y1': 36,\n",
       "    'y2': 304}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008925.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 72,\n",
       "    'x2': 232,\n",
       "    'y1': 105,\n",
       "    'y2': 305},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 184,\n",
       "    'x2': 500,\n",
       "    'y1': 58,\n",
       "    'y2': 352}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001852.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 138,\n",
       "    'x2': 381,\n",
       "    'y1': 176,\n",
       "    'y2': 261}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000665.jpg',\n",
       "  'height': 437,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 288,\n",
       "    'x2': 497,\n",
       "    'y1': 143,\n",
       "    'y2': 330},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 312,\n",
       "    'y1': 184,\n",
       "    'y2': 378},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 74,\n",
       "    'x2': 294,\n",
       "    'y1': 12,\n",
       "    'y2': 209}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000551.jpg',\n",
       "  'height': 378,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 191,\n",
       "    'x2': 481,\n",
       "    'y1': 120,\n",
       "    'y2': 187}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001660.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 32,\n",
       "    'x2': 436,\n",
       "    'y1': 33,\n",
       "    'y2': 372}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007221.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 92,\n",
       "    'x2': 326,\n",
       "    'y1': 390,\n",
       "    'y2': 443}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006164.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 21,\n",
       "    'x2': 333,\n",
       "    'y1': 224,\n",
       "    'y2': 477},\n",
       "   {'class': 'dog',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 188,\n",
       "    'y1': 404,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 41,\n",
       "    'x2': 206,\n",
       "    'y1': 75,\n",
       "    'y2': 298},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 101,\n",
       "    'x2': 235,\n",
       "    'y1': 5,\n",
       "    'y2': 245}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005120.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 288,\n",
       "    'x2': 340,\n",
       "    'y1': 157,\n",
       "    'y2': 220}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001503.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 119,\n",
       "    'x2': 262,\n",
       "    'y1': 180,\n",
       "    'y2': 235},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 477,\n",
       "    'x2': 492,\n",
       "    'y1': 172,\n",
       "    'y2': 208},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 465,\n",
       "    'x2': 479,\n",
       "    'y1': 177,\n",
       "    'y2': 209},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 151,\n",
       "    'x2': 390,\n",
       "    'y1': 178,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 56,\n",
       "    'x2': 256,\n",
       "    'y1': 166,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 39,\n",
       "    'x2': 52,\n",
       "    'y1': 167,\n",
       "    'y2': 193}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009125.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 113,\n",
       "    'x2': 171,\n",
       "    'y1': 129,\n",
       "    'y2': 207}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002979.jpg',\n",
       "  'height': 307,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 46,\n",
       "    'x2': 375,\n",
       "    'y1': 68,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006090.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 195,\n",
       "    'x2': 231,\n",
       "    'y1': 182,\n",
       "    'y2': 248},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 116,\n",
       "    'x2': 227,\n",
       "    'y1': 125,\n",
       "    'y2': 266}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005578.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 56,\n",
       "    'x2': 188,\n",
       "    'y1': 146,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 160,\n",
       "    'x2': 263,\n",
       "    'y1': 133,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 237,\n",
       "    'x2': 293,\n",
       "    'y1': 146,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 284,\n",
       "    'x2': 377,\n",
       "    'y1': 171,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 307,\n",
       "    'x2': 352,\n",
       "    'y1': 156,\n",
       "    'y2': 235},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 331,\n",
       "    'x2': 388,\n",
       "    'y1': 168,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 362,\n",
       "    'x2': 427,\n",
       "    'y1': 166,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 398,\n",
       "    'x2': 500,\n",
       "    'y1': 153,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008402.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 86,\n",
       "    'x2': 397,\n",
       "    'y1': 147,\n",
       "    'y2': 249},\n",
       "   {'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 74,\n",
       "    'x2': 321,\n",
       "    'y1': 129,\n",
       "    'y2': 218}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005427.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 79,\n",
       "    'x2': 441,\n",
       "    'y1': 29,\n",
       "    'y2': 356},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': True,\n",
       "    'x1': 44,\n",
       "    'x2': 96,\n",
       "    'y1': 45,\n",
       "    'y2': 78},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': True,\n",
       "    'x1': 117,\n",
       "    'x2': 149,\n",
       "    'y1': 55,\n",
       "    'y2': 84}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000353.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 306,\n",
       "    'x2': 348,\n",
       "    'y1': 184,\n",
       "    'y2': 328},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 270,\n",
       "    'x2': 305,\n",
       "    'y1': 172,\n",
       "    'y2': 241},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 260,\n",
       "    'x2': 430,\n",
       "    'y1': 18,\n",
       "    'y2': 259},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 197,\n",
       "    'x2': 500,\n",
       "    'y1': 120,\n",
       "    'y2': 354},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 86,\n",
       "    'x2': 195,\n",
       "    'y1': 22,\n",
       "    'y2': 151},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 112,\n",
       "    'y1': 38,\n",
       "    'y2': 138}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004068.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 324,\n",
       "    'y1': 92,\n",
       "    'y2': 266},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 345,\n",
       "    'x2': 500,\n",
       "    'y1': 107,\n",
       "    'y2': 230}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007440.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 450,\n",
       "    'x2': 482,\n",
       "    'y1': 87,\n",
       "    'y2': 149},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 383,\n",
       "    'x2': 401,\n",
       "    'y1': 128,\n",
       "    'y2': 152},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 304,\n",
       "    'x2': 341,\n",
       "    'y1': 87,\n",
       "    'y2': 147},\n",
       "   {'class': 'bird',\n",
       "    'difficult': True,\n",
       "    'x1': 284,\n",
       "    'x2': 311,\n",
       "    'y1': 104,\n",
       "    'y2': 137},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 237,\n",
       "    'x2': 284,\n",
       "    'y1': 74,\n",
       "    'y2': 123},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 190,\n",
       "    'x2': 219,\n",
       "    'y1': 117,\n",
       "    'y2': 155},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 105,\n",
       "    'x2': 134,\n",
       "    'y1': 137,\n",
       "    'y2': 184},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 56,\n",
       "    'x2': 86,\n",
       "    'y1': 143,\n",
       "    'y2': 188}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001745.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 272,\n",
       "    'y1': 61,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 243,\n",
       "    'x2': 489,\n",
       "    'y1': 76,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 443,\n",
       "    'x2': 499,\n",
       "    'y1': 140,\n",
       "    'y2': 193},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 410,\n",
       "    'x2': 441,\n",
       "    'y1': 143,\n",
       "    'y2': 185}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004285.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 281,\n",
       "    'x2': 398,\n",
       "    'y1': 18,\n",
       "    'y2': 96},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 324,\n",
       "    'y1': 1,\n",
       "    'y2': 331},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 259,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 245}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009583.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 429,\n",
       "    'x2': 478,\n",
       "    'y1': 177,\n",
       "    'y2': 265},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 359,\n",
       "    'x2': 444,\n",
       "    'y1': 202,\n",
       "    'y2': 269},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 355,\n",
       "    'x2': 465,\n",
       "    'y1': 213,\n",
       "    'y2': 359},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 200,\n",
       "    'x2': 341,\n",
       "    'y1': 218,\n",
       "    'y2': 335},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 232,\n",
       "    'x2': 309,\n",
       "    'y1': 174,\n",
       "    'y2': 252}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003225.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 134,\n",
       "    'x2': 500,\n",
       "    'y1': 95,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009264.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 59,\n",
       "    'x2': 402,\n",
       "    'y1': 84,\n",
       "    'y2': 329},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 211,\n",
       "    'x2': 315,\n",
       "    'y1': 45,\n",
       "    'y2': 232}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008303.jpg',\n",
       "  'height': 393,\n",
       "  'imageset': 'test',\n",
       "  'width': 480},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 193,\n",
       "    'x2': 217,\n",
       "    'y1': 43,\n",
       "    'y2': 129},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 221,\n",
       "    'x2': 244,\n",
       "    'y1': 45,\n",
       "    'y2': 127},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 82,\n",
       "    'x2': 186,\n",
       "    'y1': 142,\n",
       "    'y2': 230},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 167,\n",
       "    'x2': 500,\n",
       "    'y1': 40,\n",
       "    'y2': 272},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 229,\n",
       "    'x2': 500,\n",
       "    'y1': 138,\n",
       "    'y2': 272}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006359.jpg',\n",
       "  'height': 272,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 65,\n",
       "    'x2': 427,\n",
       "    'y1': 61,\n",
       "    'y2': 304},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 40,\n",
       "    'y1': 137,\n",
       "    'y2': 227}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005924.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 66,\n",
       "    'x2': 218,\n",
       "    'y1': 55,\n",
       "    'y2': 188},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 109,\n",
       "    'x2': 178,\n",
       "    'y1': 13,\n",
       "    'y2': 126}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003584.jpg',\n",
       "  'height': 236,\n",
       "  'imageset': 'test',\n",
       "  'width': 320},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 42,\n",
       "    'x2': 500,\n",
       "    'y1': 114,\n",
       "    'y2': 217},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 370,\n",
       "    'x2': 443,\n",
       "    'y1': 181,\n",
       "    'y2': 214},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 351,\n",
       "    'x2': 366,\n",
       "    'y1': 175,\n",
       "    'y2': 211}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001935.jpg',\n",
       "  'height': 374,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': True,\n",
       "    'x1': 56,\n",
       "    'x2': 407,\n",
       "    'y1': 57,\n",
       "    'y2': 142},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 146,\n",
       "    'x2': 500,\n",
       "    'y1': 56,\n",
       "    'y2': 189}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001885.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 201,\n",
       "    'x2': 326,\n",
       "    'y1': 146,\n",
       "    'y2': 217}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006985.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 497,\n",
       "    'y1': 43,\n",
       "    'y2': 330},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 363,\n",
       "    'x2': 406,\n",
       "    'y1': 155,\n",
       "    'y2': 213},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 346,\n",
       "    'x2': 383,\n",
       "    'y1': 169,\n",
       "    'y2': 212},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 474,\n",
       "    'x2': 500,\n",
       "    'y1': 177,\n",
       "    'y2': 215},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 202,\n",
       "    'x2': 221,\n",
       "    'y1': 138,\n",
       "    'y2': 234}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001953.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 48,\n",
       "    'x2': 183,\n",
       "    'y1': 94,\n",
       "    'y2': 207},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 193,\n",
       "    'x2': 245,\n",
       "    'y1': 90,\n",
       "    'y2': 150},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 261,\n",
       "    'x2': 299,\n",
       "    'y1': 90,\n",
       "    'y2': 124}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007401.jpg',\n",
       "  'height': 240,\n",
       "  'imageset': 'test',\n",
       "  'width': 320},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 266,\n",
       "    'x2': 335,\n",
       "    'y1': 161,\n",
       "    'y2': 246},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 196,\n",
       "    'x2': 392,\n",
       "    'y1': 213,\n",
       "    'y2': 373},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 184,\n",
       "    'x2': 290,\n",
       "    'y1': 135,\n",
       "    'y2': 273}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002813.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 217,\n",
       "    'x2': 271,\n",
       "    'y1': 84,\n",
       "    'y2': 166},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 17,\n",
       "    'x2': 256,\n",
       "    'y1': 96,\n",
       "    'y2': 250},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 278,\n",
       "    'x2': 439,\n",
       "    'y1': 110,\n",
       "    'y2': 269}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009916.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 15,\n",
       "    'x2': 489,\n",
       "    'y1': 70,\n",
       "    'y2': 258}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004314.jpg',\n",
       "  'height': 372,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 500,\n",
       "    'y1': 47,\n",
       "    'y2': 321}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007386.jpg',\n",
       "  'height': 330,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 369,\n",
       "    'y1': 119,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 149,\n",
       "    'x2': 358,\n",
       "    'y1': 8,\n",
       "    'y2': 256},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 54,\n",
       "    'y1': 1,\n",
       "    'y2': 91}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001438.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 110,\n",
       "    'x2': 318,\n",
       "    'y1': 75,\n",
       "    'y2': 400},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 268,\n",
       "    'x2': 368,\n",
       "    'y1': 154,\n",
       "    'y2': 330},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 221,\n",
       "    'x2': 374,\n",
       "    'y1': 329,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 24,\n",
       "    'x2': 236,\n",
       "    'y1': 353,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 84,\n",
       "    'y1': 128,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004771.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 52,\n",
       "    'x2': 419,\n",
       "    'y1': 72,\n",
       "    'y2': 394}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002672.jpg',\n",
       "  'height': 429,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': True,\n",
       "    'x1': 2,\n",
       "    'x2': 500,\n",
       "    'y1': 2,\n",
       "    'y2': 317},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 128,\n",
       "    'y1': 23,\n",
       "    'y2': 277}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004568.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 500,\n",
       "    'y1': 119,\n",
       "    'y2': 438},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 245,\n",
       "    'x2': 500,\n",
       "    'y1': 79,\n",
       "    'y2': 280},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 92,\n",
       "    'x2': 496,\n",
       "    'y1': 71,\n",
       "    'y2': 435}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009766.jpg',\n",
       "  'height': 439,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 359,\n",
       "    'y1': 1,\n",
       "    'y2': 373}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004875.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 367,\n",
       "    'x2': 426,\n",
       "    'y1': 132,\n",
       "    'y2': 287},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 202,\n",
       "    'y1': 1,\n",
       "    'y2': 333},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 412,\n",
       "    'y1': 45,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001709.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'pottedplant',\n",
       "    'difficult': True,\n",
       "    'x1': 80,\n",
       "    'x2': 221,\n",
       "    'y1': 182,\n",
       "    'y2': 375},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 270,\n",
       "    'x2': 296,\n",
       "    'y1': 311,\n",
       "    'y2': 330},\n",
       "   {'class': 'bus',\n",
       "    'difficult': True,\n",
       "    'x1': 366,\n",
       "    'x2': 412,\n",
       "    'y1': 281,\n",
       "    'y2': 329},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 462,\n",
       "    'x2': 479,\n",
       "    'y1': 282,\n",
       "    'y2': 298}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009261.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 22,\n",
       "    'x2': 150,\n",
       "    'y1': 127,\n",
       "    'y2': 289}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007403.jpg',\n",
       "  'height': 387,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 65,\n",
       "    'x2': 146,\n",
       "    'y1': 189,\n",
       "    'y2': 305},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 224,\n",
       "    'x2': 327,\n",
       "    'y1': 185,\n",
       "    'y2': 296},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 295,\n",
       "    'x2': 500,\n",
       "    'y1': 178,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004813.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 85,\n",
       "    'x2': 223,\n",
       "    'y1': 278,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 94,\n",
       "    'x2': 252,\n",
       "    'y1': 142,\n",
       "    'y2': 350}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001452.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 43,\n",
       "    'x2': 344,\n",
       "    'y1': 138,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007248.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 354,\n",
       "    'y1': 30,\n",
       "    'y2': 254}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006149.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 397,\n",
       "    'y1': 13,\n",
       "    'y2': 380},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 49,\n",
       "    'x2': 357,\n",
       "    'y1': 138,\n",
       "    'y2': 312}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005010.jpg',\n",
       "  'height': 380,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 231,\n",
       "    'x2': 422,\n",
       "    'y1': 95,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 5,\n",
       "    'x2': 243,\n",
       "    'y1': 114,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 122,\n",
       "    'x2': 169,\n",
       "    'y1': 117,\n",
       "    'y2': 188},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 129,\n",
       "    'y1': 89,\n",
       "    'y2': 320},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 348,\n",
       "    'x2': 412,\n",
       "    'y1': 162,\n",
       "    'y2': 278},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 403,\n",
       "    'x2': 471,\n",
       "    'y1': 141,\n",
       "    'y2': 231},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 439,\n",
       "    'x2': 469,\n",
       "    'y1': 145,\n",
       "    'y2': 183}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005148.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 199,\n",
       "    'x2': 445,\n",
       "    'y1': 27,\n",
       "    'y2': 304},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 238,\n",
       "    'y1': 1,\n",
       "    'y2': 286}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003880.jpg',\n",
       "  'height': 372,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 4,\n",
       "    'x2': 375,\n",
       "    'y1': 15,\n",
       "    'y2': 496}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007251.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 261,\n",
       "    'x2': 407,\n",
       "    'y1': 135,\n",
       "    'y2': 319}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006315.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 213,\n",
       "    'x2': 298,\n",
       "    'y1': 140,\n",
       "    'y2': 193}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004261.jpg',\n",
       "  'height': 326,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 82,\n",
       "    'x2': 423,\n",
       "    'y1': 84,\n",
       "    'y2': 303},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 164,\n",
       "    'x2': 286,\n",
       "    'y1': 50,\n",
       "    'y2': 212}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002655.jpg',\n",
       "  'height': 407,\n",
       "  'imageset': 'test',\n",
       "  'width': 480},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 15,\n",
       "    'x2': 99,\n",
       "    'y1': 77,\n",
       "    'y2': 271}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007313.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 39,\n",
       "    'x2': 316,\n",
       "    'y1': 189,\n",
       "    'y2': 330},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 16,\n",
       "    'x2': 192,\n",
       "    'y1': 123,\n",
       "    'y2': 291}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009493.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 500,\n",
       "    'y1': 160,\n",
       "    'y2': 315}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005504.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 353,\n",
       "    'x2': 500,\n",
       "    'y1': 66,\n",
       "    'y2': 338},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 151,\n",
       "    'y1': 110,\n",
       "    'y2': 375},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 226,\n",
       "    'x2': 263,\n",
       "    'y1': 243,\n",
       "    'y2': 368}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006360.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 132,\n",
       "    'x2': 287,\n",
       "    'y1': 79,\n",
       "    'y2': 372}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008013.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 306},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 137,\n",
       "    'y1': 277,\n",
       "    'y2': 362},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 177,\n",
       "    'y1': 428,\n",
       "    'y2': 500},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 45,\n",
       "    'y1': 354,\n",
       "    'y2': 427}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009313.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 111,\n",
       "    'x2': 382,\n",
       "    'y1': 46,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005115.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 304,\n",
       "    'x2': 500,\n",
       "    'y1': 64,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 170,\n",
       "    'y1': 88,\n",
       "    'y2': 311},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 31,\n",
       "    'x2': 61,\n",
       "    'y1': 258,\n",
       "    'y2': 333},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 13,\n",
       "    'x2': 41,\n",
       "    'y1': 273,\n",
       "    'y2': 331},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 409,\n",
       "    'x2': 437,\n",
       "    'y1': 249,\n",
       "    'y2': 300}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005942.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 452,\n",
       "    'x2': 500,\n",
       "    'y1': 236,\n",
       "    'y2': 333},\n",
       "   {'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 371,\n",
       "    'x2': 500,\n",
       "    'y1': 113,\n",
       "    'y2': 254},\n",
       "   {'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 157,\n",
       "    'x2': 377,\n",
       "    'y1': 124,\n",
       "    'y2': 228},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 51,\n",
       "    'x2': 65,\n",
       "    'y1': 166,\n",
       "    'y2': 198},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 144,\n",
       "    'x2': 158,\n",
       "    'y1': 175,\n",
       "    'y2': 196},\n",
       "   {'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 80,\n",
       "    'x2': 144,\n",
       "    'y1': 149,\n",
       "    'y2': 198}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007405.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 9,\n",
       "    'x2': 112,\n",
       "    'y1': 61,\n",
       "    'y2': 478},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 88,\n",
       "    'x2': 373,\n",
       "    'y1': 1,\n",
       "    'y2': 423}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004941.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 71,\n",
       "    'x2': 247,\n",
       "    'y1': 154,\n",
       "    'y2': 234},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 293,\n",
       "    'x2': 390,\n",
       "    'y1': 127,\n",
       "    'y2': 305}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007512.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 20,\n",
       "    'x2': 144,\n",
       "    'y1': 355,\n",
       "    'y2': 444}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003741.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 335},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 96,\n",
       "    'x2': 288,\n",
       "    'y1': 227,\n",
       "    'y2': 324},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 298,\n",
       "    'x2': 421,\n",
       "    'y1': 257,\n",
       "    'y2': 327},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 421,\n",
       "    'x2': 500,\n",
       "    'y1': 254,\n",
       "    'y2': 333},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 305,\n",
       "    'x2': 470,\n",
       "    'y1': 227,\n",
       "    'y2': 273},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 284,\n",
       "    'x2': 329,\n",
       "    'y1': 246,\n",
       "    'y2': 284},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 16,\n",
       "    'x2': 105,\n",
       "    'y1': 231,\n",
       "    'y2': 287},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 46,\n",
       "    'x2': 70,\n",
       "    'y1': 241,\n",
       "    'y2': 314},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 25,\n",
       "    'y1': 239,\n",
       "    'y2': 315},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 76,\n",
       "    'x2': 104,\n",
       "    'y1': 233,\n",
       "    'y2': 295}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001382.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 192,\n",
       "    'x2': 379,\n",
       "    'y1': 1,\n",
       "    'y2': 229}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005891.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 217,\n",
       "    'x2': 372,\n",
       "    'y1': 21,\n",
       "    'y2': 372},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 354,\n",
       "    'x2': 434,\n",
       "    'y1': 167,\n",
       "    'y2': 275},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 68,\n",
       "    'y1': 51,\n",
       "    'y2': 372}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004766.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 43,\n",
       "    'x2': 109,\n",
       "    'y1': 97,\n",
       "    'y2': 135},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 132,\n",
       "    'x2': 500,\n",
       "    'y1': 34,\n",
       "    'y2': 290}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001394.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 44,\n",
       "    'y1': 78,\n",
       "    'y2': 264},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 43,\n",
       "    'x2': 160,\n",
       "    'y1': 57,\n",
       "    'y2': 241},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 19,\n",
       "    'x2': 97,\n",
       "    'y1': 100,\n",
       "    'y2': 277},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 143,\n",
       "    'x2': 394,\n",
       "    'y1': 44,\n",
       "    'y2': 129}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001437.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 486,\n",
       "    'y1': 54,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000640.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 43,\n",
       "    'x2': 228,\n",
       "    'y1': 134,\n",
       "    'y2': 345},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 71,\n",
       "    'x2': 500,\n",
       "    'y1': 22,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004112.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 4,\n",
       "    'x2': 369,\n",
       "    'y1': 97,\n",
       "    'y2': 299},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 315,\n",
       "    'x2': 500,\n",
       "    'y1': 76,\n",
       "    'y2': 202}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001991.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 107,\n",
       "    'x2': 309,\n",
       "    'y1': 96,\n",
       "    'y2': 348}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000119.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 137,\n",
       "    'x2': 451,\n",
       "    'y1': 109,\n",
       "    'y2': 290},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 205,\n",
       "    'x2': 359,\n",
       "    'y1': 81,\n",
       "    'y2': 276}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006951.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 242,\n",
       "    'x2': 354,\n",
       "    'y1': 184,\n",
       "    'y2': 270},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 87,\n",
       "    'x2': 117,\n",
       "    'y1': 192,\n",
       "    'y2': 211},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 74,\n",
       "    'x2': 103,\n",
       "    'y1': 205,\n",
       "    'y2': 283},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 112,\n",
       "    'x2': 166,\n",
       "    'y1': 207,\n",
       "    'y2': 294},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 146,\n",
       "    'x2': 176,\n",
       "    'y1': 194,\n",
       "    'y2': 214},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 90,\n",
       "    'y1': 264,\n",
       "    'y2': 332}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004053.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 3,\n",
       "    'x2': 233,\n",
       "    'y1': 163,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 252,\n",
       "    'x2': 405,\n",
       "    'y1': 128,\n",
       "    'y2': 335},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 97,\n",
       "    'x2': 405,\n",
       "    'y1': 21,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009651.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 24,\n",
       "    'x2': 295,\n",
       "    'y1': 14,\n",
       "    'y2': 429}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009142.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 358},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 151,\n",
       "    'x2': 474,\n",
       "    'y1': 301,\n",
       "    'y2': 437}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003661.jpg',\n",
       "  'height': 468,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 37,\n",
       "    'x2': 355,\n",
       "    'y1': 42,\n",
       "    'y2': 339},\n",
       "   {'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 307,\n",
       "    'x2': 375,\n",
       "    'y1': 170,\n",
       "    'y2': 239}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009909.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 51,\n",
       "    'x2': 325,\n",
       "    'y1': 2,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000664.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 2,\n",
       "    'x2': 120,\n",
       "    'y1': 80,\n",
       "    'y2': 150},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 203,\n",
       "    'x2': 298,\n",
       "    'y1': 47,\n",
       "    'y2': 107},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 410,\n",
       "    'x2': 499,\n",
       "    'y1': 81,\n",
       "    'y2': 163},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 419,\n",
       "    'x2': 495,\n",
       "    'y1': 217,\n",
       "    'y2': 270},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 329,\n",
       "    'x2': 346,\n",
       "    'y1': 63,\n",
       "    'y2': 107},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 181,\n",
       "    'x2': 205,\n",
       "    'y1': 161,\n",
       "    'y2': 241},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 156,\n",
       "    'x2': 176,\n",
       "    'y1': 181,\n",
       "    'y2': 247},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 128,\n",
       "    'x2': 161,\n",
       "    'y1': 181,\n",
       "    'y2': 261},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 491,\n",
       "    'y1': 88,\n",
       "    'y2': 333},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 5,\n",
       "    'x2': 82,\n",
       "    'y1': 1,\n",
       "    'y2': 84}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001489.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 456,\n",
       "    'x2': 500,\n",
       "    'y1': 191,\n",
       "    'y2': 237},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 106,\n",
       "    'y1': 187,\n",
       "    'y2': 244},\n",
       "   {'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 102,\n",
       "    'x2': 378,\n",
       "    'y1': 76,\n",
       "    'y2': 272},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 35,\n",
       "    'y1': 200,\n",
       "    'y2': 321},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 16,\n",
       "    'x2': 58,\n",
       "    'y1': 183,\n",
       "    'y2': 281}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003503.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 234,\n",
       "    'x2': 280,\n",
       "    'y1': 285,\n",
       "    'y2': 465},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 349,\n",
       "    'y1': 413,\n",
       "    'y2': 500},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 327,\n",
       "    'x2': 372,\n",
       "    'y1': 291,\n",
       "    'y2': 471},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 4,\n",
       "    'x2': 134,\n",
       "    'y1': 293,\n",
       "    'y2': 419},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 128,\n",
       "    'x2': 326,\n",
       "    'y1': 71,\n",
       "    'y2': 421}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003643.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 180,\n",
       "    'x2': 277,\n",
       "    'y1': 174,\n",
       "    'y2': 226}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004374.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 489,\n",
       "    'y1': 1,\n",
       "    'y2': 340}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000375.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 253,\n",
       "    'x2': 471,\n",
       "    'y1': 106,\n",
       "    'y2': 312}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000576.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 30,\n",
       "    'x2': 369,\n",
       "    'y1': 203,\n",
       "    'y2': 328}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003559.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 194,\n",
       "    'x2': 297,\n",
       "    'y1': 168,\n",
       "    'y2': 241},\n",
       "   {'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 147,\n",
       "    'x2': 283,\n",
       "    'y1': 54,\n",
       "    'y2': 224},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 239,\n",
       "    'x2': 266,\n",
       "    'y1': 112,\n",
       "    'y2': 135}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000252.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 180,\n",
       "    'x2': 488,\n",
       "    'y1': 111,\n",
       "    'y2': 284}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001956.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 19,\n",
       "    'x2': 456,\n",
       "    'y1': 62,\n",
       "    'y2': 321}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005142.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 249,\n",
       "    'x2': 310,\n",
       "    'y1': 283,\n",
       "    'y2': 325},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 447,\n",
       "    'x2': 500,\n",
       "    'y1': 270,\n",
       "    'y2': 330},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 217,\n",
       "    'x2': 249,\n",
       "    'y1': 285,\n",
       "    'y2': 337},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 389,\n",
       "    'x2': 405,\n",
       "    'y1': 280,\n",
       "    'y2': 297},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 404,\n",
       "    'x2': 419,\n",
       "    'y1': 280,\n",
       "    'y2': 296},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 218,\n",
       "    'y1': 240,\n",
       "    'y2': 375},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 316,\n",
       "    'x2': 390,\n",
       "    'y1': 264,\n",
       "    'y2': 321}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009829.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 499,\n",
       "    'y1': 24,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008650.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 215,\n",
       "    'y1': 67,\n",
       "    'y2': 317}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004504.jpg',\n",
       "  'height': 335,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 157,\n",
       "    'x2': 269,\n",
       "    'y1': 62,\n",
       "    'y2': 298}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008662.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 53,\n",
       "    'x2': 468,\n",
       "    'y1': 100,\n",
       "    'y2': 238},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 158,\n",
       "    'x2': 188,\n",
       "    'y1': 130,\n",
       "    'y2': 168},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 183,\n",
       "    'x2': 206,\n",
       "    'y1': 108,\n",
       "    'y2': 136},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 144,\n",
       "    'x2': 167,\n",
       "    'y1': 107,\n",
       "    'y2': 132},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 87,\n",
       "    'x2': 122,\n",
       "    'y1': 126,\n",
       "    'y2': 150}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002719.jpg',\n",
       "  'height': 374,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 459,\n",
       "    'x2': 500,\n",
       "    'y1': 135,\n",
       "    'y2': 167},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 261,\n",
       "    'x2': 294,\n",
       "    'y1': 143,\n",
       "    'y2': 168},\n",
       "   {'class': 'horse',\n",
       "    'difficult': True,\n",
       "    'x1': 303,\n",
       "    'x2': 325,\n",
       "    'y1': 139,\n",
       "    'y2': 165},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 134,\n",
       "    'x2': 155,\n",
       "    'y1': 142,\n",
       "    'y2': 172},\n",
       "   {'class': 'horse',\n",
       "    'difficult': True,\n",
       "    'x1': 111,\n",
       "    'x2': 127,\n",
       "    'y1': 142,\n",
       "    'y2': 175},\n",
       "   {'class': 'horse',\n",
       "    'difficult': True,\n",
       "    'x1': 100,\n",
       "    'x2': 114,\n",
       "    'y1': 142,\n",
       "    'y2': 176},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 476,\n",
       "    'x2': 486,\n",
       "    'y1': 129,\n",
       "    'y2': 153},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 309,\n",
       "    'x2': 316,\n",
       "    'y1': 132,\n",
       "    'y2': 153},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 276,\n",
       "    'x2': 287,\n",
       "    'y1': 136,\n",
       "    'y2': 154},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 143,\n",
       "    'x2': 153,\n",
       "    'y1': 135,\n",
       "    'y2': 154},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 118,\n",
       "    'x2': 127,\n",
       "    'y1': 137,\n",
       "    'y2': 158},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 100,\n",
       "    'x2': 114,\n",
       "    'y1': 138,\n",
       "    'y2': 164}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001635.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 189,\n",
       "    'x2': 196,\n",
       "    'y1': 131,\n",
       "    'y2': 160},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 81,\n",
       "    'y1': 359,\n",
       "    'y2': 400},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 408,\n",
       "    'x2': 500,\n",
       "    'y1': 270,\n",
       "    'y2': 400},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 278,\n",
       "    'x2': 375,\n",
       "    'y1': 274,\n",
       "    'y2': 340},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 197,\n",
       "    'x2': 277,\n",
       "    'y1': 261,\n",
       "    'y2': 312},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 107,\n",
       "    'x2': 178,\n",
       "    'y1': 261,\n",
       "    'y2': 301},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 16,\n",
       "    'x2': 78,\n",
       "    'y1': 248,\n",
       "    'y2': 286},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': True,\n",
       "    'x1': 47,\n",
       "    'x2': 114,\n",
       "    'y1': 269,\n",
       "    'y2': 339},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 415,\n",
       "    'y1': 294,\n",
       "    'y2': 400},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 345,\n",
       "    'x2': 355,\n",
       "    'y1': 161,\n",
       "    'y2': 185},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 334,\n",
       "    'x2': 344,\n",
       "    'y1': 163,\n",
       "    'y2': 187},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 180,\n",
       "    'x2': 187,\n",
       "    'y1': 128,\n",
       "    'y2': 163}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001023.jpg',\n",
       "  'height': 400,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 58,\n",
       "    'x2': 451,\n",
       "    'y1': 35,\n",
       "    'y2': 296},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 325,\n",
       "    'x2': 422,\n",
       "    'y1': 66,\n",
       "    'y2': 119},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 436,\n",
       "    'x2': 500,\n",
       "    'y1': 102,\n",
       "    'y2': 152},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 45,\n",
       "    'x2': 58,\n",
       "    'y1': 67,\n",
       "    'y2': 98},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 29,\n",
       "    'x2': 43,\n",
       "    'y1': 65,\n",
       "    'y2': 99}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006333.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 23,\n",
       "    'x2': 446,\n",
       "    'y1': 59,\n",
       "    'y2': 294},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 291,\n",
       "    'x2': 325,\n",
       "    'y1': 36,\n",
       "    'y2': 57}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009008.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 190,\n",
       "    'x2': 409,\n",
       "    'y1': 161,\n",
       "    'y2': 375},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 138,\n",
       "    'x2': 344,\n",
       "    'y1': 103,\n",
       "    'y2': 325},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 123,\n",
       "    'x2': 189,\n",
       "    'y1': 48,\n",
       "    'y2': 97},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 408,\n",
       "    'x2': 468,\n",
       "    'y1': 69,\n",
       "    'y2': 94},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 3,\n",
       "    'x2': 41,\n",
       "    'y1': 65,\n",
       "    'y2': 135},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 26,\n",
       "    'y1': 84,\n",
       "    'y2': 170},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 468,\n",
       "    'x2': 496,\n",
       "    'y1': 52,\n",
       "    'y2': 69},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 429,\n",
       "    'x2': 444,\n",
       "    'y1': 53,\n",
       "    'y2': 70},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 470,\n",
       "    'x2': 499,\n",
       "    'y1': 89,\n",
       "    'y2': 107},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 361,\n",
       "    'x2': 380,\n",
       "    'y1': 52,\n",
       "    'y2': 67},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 307,\n",
       "    'x2': 337,\n",
       "    'y1': 47,\n",
       "    'y2': 69},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 275,\n",
       "    'x2': 299,\n",
       "    'y1': 52,\n",
       "    'y2': 67},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 3,\n",
       "    'x2': 36,\n",
       "    'y1': 46,\n",
       "    'y2': 68},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 107,\n",
       "    'x2': 121,\n",
       "    'y1': 51,\n",
       "    'y2': 67},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 118,\n",
       "    'x2': 136,\n",
       "    'y1': 59,\n",
       "    'y2': 83}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009451.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 339,\n",
       "    'x2': 500,\n",
       "    'y1': 99,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 181,\n",
       "    'x2': 344,\n",
       "    'y1': 91,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 30,\n",
       "    'x2': 228,\n",
       "    'y1': 96,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009473.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 98,\n",
       "    'x2': 479,\n",
       "    'y1': 56,\n",
       "    'y2': 354}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003560.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 312,\n",
       "    'x2': 489,\n",
       "    'y1': 168,\n",
       "    'y2': 326},\n",
       "   {'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 194,\n",
       "    'x2': 270,\n",
       "    'y1': 36,\n",
       "    'y2': 157},\n",
       "   {'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 180,\n",
       "    'x2': 213,\n",
       "    'y1': 76,\n",
       "    'y2': 96},\n",
       "   {'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 169,\n",
       "    'x2': 194,\n",
       "    'y1': 88,\n",
       "    'y2': 107},\n",
       "   {'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 353,\n",
       "    'x2': 378,\n",
       "    'y1': 75,\n",
       "    'y2': 88},\n",
       "   {'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 111,\n",
       "    'x2': 129,\n",
       "    'y1': 68,\n",
       "    'y2': 79},\n",
       "   {'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 160,\n",
       "    'x2': 174,\n",
       "    'y1': 55,\n",
       "    'y2': 75},\n",
       "   {'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 74,\n",
       "    'x2': 94,\n",
       "    'y1': 68,\n",
       "    'y2': 82}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001342.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 297,\n",
       "    'y1': 64,\n",
       "    'y2': 278}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005632.jpg',\n",
       "  'height': 278,\n",
       "  'imageset': 'test',\n",
       "  'width': 370},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 105,\n",
       "    'x2': 473,\n",
       "    'y1': 25,\n",
       "    'y2': 255}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007850.jpg',\n",
       "  'height': 328,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 36,\n",
       "    'x2': 288,\n",
       "    'y1': 70,\n",
       "    'y2': 486}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000983.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 166,\n",
       "    'x2': 228,\n",
       "    'y1': 188,\n",
       "    'y2': 275}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004646.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 335},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 33,\n",
       "    'x2': 482,\n",
       "    'y1': 72,\n",
       "    'y2': 254}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003143.jpg',\n",
       "  'height': 292,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 213,\n",
       "    'x2': 380,\n",
       "    'y1': 29,\n",
       "    'y2': 224},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 53,\n",
       "    'x2': 378,\n",
       "    'y1': 65,\n",
       "    'y2': 261}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003222.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 185,\n",
       "    'x2': 500,\n",
       "    'y1': 290,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 254,\n",
       "    'x2': 419,\n",
       "    'y1': 146,\n",
       "    'y2': 315},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 309,\n",
       "    'y1': 72,\n",
       "    'y2': 374},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 28,\n",
       "    'x2': 221,\n",
       "    'y1': 170,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000870.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 54,\n",
       "    'x2': 369,\n",
       "    'y1': 99,\n",
       "    'y2': 278},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 155,\n",
       "    'x2': 299,\n",
       "    'y1': 68,\n",
       "    'y2': 264}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003670.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 185,\n",
       "    'x2': 458,\n",
       "    'y1': 121,\n",
       "    'y2': 327}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009360.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 333,\n",
       "    'y1': 1,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006961.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 85,\n",
       "    'x2': 349,\n",
       "    'y1': 87,\n",
       "    'y2': 294},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 98,\n",
       "    'x2': 220,\n",
       "    'y1': 43,\n",
       "    'y2': 249}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008128.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 272,\n",
       "    'x2': 374,\n",
       "    'y1': 1,\n",
       "    'y2': 234}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009648.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 152,\n",
       "    'x2': 281,\n",
       "    'y1': 84,\n",
       "    'y2': 315},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 32,\n",
       "    'x2': 223,\n",
       "    'y1': 84,\n",
       "    'y2': 351},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 259,\n",
       "    'x2': 500,\n",
       "    'y1': 105,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007081.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 308,\n",
       "    'x2': 394,\n",
       "    'y1': 220,\n",
       "    'y2': 273}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004670.jpg',\n",
       "  'height': 325,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 375,\n",
       "    'y1': 51,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007316.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 389},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 117,\n",
       "    'y1': 33,\n",
       "    'y2': 184},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 36,\n",
       "    'x2': 107,\n",
       "    'y1': 3,\n",
       "    'y2': 55},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 371,\n",
       "    'y1': 146,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001025.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 42,\n",
       "    'x2': 133,\n",
       "    'y1': 269,\n",
       "    'y2': 314}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006109.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 24,\n",
       "    'x2': 260,\n",
       "    'y1': 42,\n",
       "    'y2': 242}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003925.jpg',\n",
       "  'height': 242,\n",
       "  'imageset': 'test',\n",
       "  'width': 320},\n",
       " {'bboxes': [{'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 86,\n",
       "    'x2': 246,\n",
       "    'y1': 110,\n",
       "    'y2': 222},\n",
       "   {'class': 'cow',\n",
       "    'difficult': True,\n",
       "    'x1': 252,\n",
       "    'x2': 313,\n",
       "    'y1': 124,\n",
       "    'y2': 170},\n",
       "   {'class': 'cow',\n",
       "    'difficult': True,\n",
       "    'x1': 314,\n",
       "    'x2': 475,\n",
       "    'y1': 103,\n",
       "    'y2': 154},\n",
       "   {'class': 'cow',\n",
       "    'difficult': True,\n",
       "    'x1': 330,\n",
       "    'x2': 499,\n",
       "    'y1': 122,\n",
       "    'y2': 285},\n",
       "   {'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 142,\n",
       "    'x2': 340,\n",
       "    'y1': 146,\n",
       "    'y2': 375},\n",
       "   {'class': 'cow',\n",
       "    'difficult': True,\n",
       "    'x1': 2,\n",
       "    'x2': 51,\n",
       "    'y1': 142,\n",
       "    'y2': 295}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008527.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 340,\n",
       "    'x2': 500,\n",
       "    'y1': 112,\n",
       "    'y2': 271},\n",
       "   {'class': 'horse',\n",
       "    'difficult': True,\n",
       "    'x1': 299,\n",
       "    'x2': 470,\n",
       "    'y1': 129,\n",
       "    'y2': 218},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 84,\n",
       "    'x2': 356,\n",
       "    'y1': 84,\n",
       "    'y2': 264},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 230,\n",
       "    'y1': 81,\n",
       "    'y2': 230}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008298.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 70,\n",
       "    'x2': 129,\n",
       "    'y1': 151,\n",
       "    'y2': 275},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 121,\n",
       "    'x2': 142,\n",
       "    'y1': 135,\n",
       "    'y2': 168},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': True,\n",
       "    'x1': 183,\n",
       "    'x2': 199,\n",
       "    'y1': 137,\n",
       "    'y2': 165}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007792.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 139,\n",
       "    'x2': 499,\n",
       "    'y1': 133,\n",
       "    'y2': 272}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003805.jpg',\n",
       "  'height': 335,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 270,\n",
       "    'x2': 335,\n",
       "    'y1': 244,\n",
       "    'y2': 326},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 228,\n",
       "    'x2': 320,\n",
       "    'y1': 322,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 170,\n",
       "    'x2': 220,\n",
       "    'y1': 227,\n",
       "    'y2': 261},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 35,\n",
       "    'y1': 236,\n",
       "    'y2': 270},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 293,\n",
       "    'y1': 248,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008210.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 220,\n",
       "    'x2': 467,\n",
       "    'y1': 72,\n",
       "    'y2': 367},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 124,\n",
       "    'y1': 105,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002195.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 135,\n",
       "    'x2': 336,\n",
       "    'y1': 244,\n",
       "    'y2': 333},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 388,\n",
       "    'x2': 500,\n",
       "    'y1': 297,\n",
       "    'y2': 375},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 340,\n",
       "    'x2': 377,\n",
       "    'y1': 255,\n",
       "    'y2': 274}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002887.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 174,\n",
       "    'x2': 397,\n",
       "    'y1': 89,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 387,\n",
       "    'y1': 1,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 203,\n",
       "    'y1': 1,\n",
       "    'y2': 199},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 2,\n",
       "    'x2': 500,\n",
       "    'y1': 33,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001150.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 42,\n",
       "    'x2': 350,\n",
       "    'y1': 46,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008508.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 350},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 103,\n",
       "    'x2': 370,\n",
       "    'y1': 34,\n",
       "    'y2': 244},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 402,\n",
       "    'x2': 500,\n",
       "    'y1': 46,\n",
       "    'y2': 103},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 131,\n",
       "    'x2': 381,\n",
       "    'y1': 22,\n",
       "    'y2': 113}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008290.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 128,\n",
       "    'x2': 211,\n",
       "    'y1': 1,\n",
       "    'y2': 206}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009257.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 85,\n",
       "    'x2': 404,\n",
       "    'y1': 1,\n",
       "    'y2': 136},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 85,\n",
       "    'x2': 500,\n",
       "    'y1': 2,\n",
       "    'y2': 281}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004260.jpg',\n",
       "  'height': 281,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 105,\n",
       "    'x2': 385,\n",
       "    'y1': 50,\n",
       "    'y2': 178}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000821.jpg',\n",
       "  'height': 299,\n",
       "  'imageset': 'test',\n",
       "  'width': 448},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 247,\n",
       "    'x2': 500,\n",
       "    'y1': 37,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007988.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 72,\n",
       "    'x2': 272,\n",
       "    'y1': 69,\n",
       "    'y2': 246}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008025.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 498,\n",
       "    'y1': 14,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006080.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': True,\n",
       "    'x1': 233,\n",
       "    'x2': 274,\n",
       "    'y1': 159,\n",
       "    'y2': 213},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 322,\n",
       "    'x2': 380,\n",
       "    'y1': 155,\n",
       "    'y2': 199}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005833.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 64,\n",
       "    'x2': 209,\n",
       "    'y1': 106,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 183,\n",
       "    'x2': 331,\n",
       "    'y1': 88,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001473.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 171,\n",
       "    'y1': 26,\n",
       "    'y2': 276},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 329,\n",
       "    'x2': 408,\n",
       "    'y1': 1,\n",
       "    'y2': 66},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 282,\n",
       "    'x2': 500,\n",
       "    'y1': 49,\n",
       "    'y2': 375},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 443,\n",
       "    'y1': 225,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005377.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 375,\n",
       "    'y1': 195,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007094.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 13,\n",
       "    'x2': 493,\n",
       "    'y1': 84,\n",
       "    'y2': 287}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005083.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 132,\n",
       "    'x2': 500,\n",
       "    'y1': 19,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007291.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 107,\n",
       "    'x2': 387,\n",
       "    'y1': 107,\n",
       "    'y2': 234}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008637.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 227,\n",
       "    'y1': 1,\n",
       "    'y2': 235}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003073.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 82,\n",
       "    'x2': 150,\n",
       "    'y1': 209,\n",
       "    'y2': 252},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 171,\n",
       "    'x2': 256,\n",
       "    'y1': 34,\n",
       "    'y2': 259},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 231,\n",
       "    'x2': 306,\n",
       "    'y1': 200,\n",
       "    'y2': 266},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 39,\n",
       "    'x2': 500,\n",
       "    'y1': 250,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008821.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 256,\n",
       "    'x2': 349,\n",
       "    'y1': 1,\n",
       "    'y2': 192},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 309,\n",
       "    'x2': 466,\n",
       "    'y1': 136,\n",
       "    'y2': 275},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 287,\n",
       "    'x2': 433,\n",
       "    'y1': 274,\n",
       "    'y2': 375},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 174,\n",
       "    'x2': 280,\n",
       "    'y1': 312,\n",
       "    'y2': 375},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 179,\n",
       "    'y1': 240,\n",
       "    'y2': 340},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 151,\n",
       "    'y1': 89,\n",
       "    'y2': 240},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 112,\n",
       "    'x2': 213,\n",
       "    'y1': 1,\n",
       "    'y2': 137},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 146,\n",
       "    'x2': 297,\n",
       "    'y1': 44,\n",
       "    'y2': 287}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002231.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 118,\n",
       "    'x2': 174,\n",
       "    'y1': 135,\n",
       "    'y2': 211},\n",
       "   {'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 171,\n",
       "    'x2': 235,\n",
       "    'y1': 114,\n",
       "    'y2': 209}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000558.jpg',\n",
       "  'height': 257,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 273,\n",
       "    'x2': 485,\n",
       "    'y1': 188,\n",
       "    'y2': 305}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006790.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 91,\n",
       "    'x2': 380,\n",
       "    'y1': 37,\n",
       "    'y2': 332},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 132,\n",
       "    'y1': 141,\n",
       "    'y2': 314},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 125,\n",
       "    'x2': 213,\n",
       "    'y1': 94,\n",
       "    'y2': 220}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007957.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 272,\n",
       "    'x2': 359,\n",
       "    'y1': 175,\n",
       "    'y2': 252},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 83,\n",
       "    'x2': 245,\n",
       "    'y1': 121,\n",
       "    'y2': 253}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008028.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 29,\n",
       "    'x2': 475,\n",
       "    'y1': 66,\n",
       "    'y2': 372},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 22,\n",
       "    'y1': 96,\n",
       "    'y2': 238},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': True,\n",
       "    'x1': 351,\n",
       "    'x2': 441,\n",
       "    'y1': 9,\n",
       "    'y2': 145}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004045.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 434,\n",
       "    'y1': 99,\n",
       "    'y2': 316},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 42,\n",
       "    'y1': 23,\n",
       "    'y2': 240}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001542.jpg',\n",
       "  'height': 335,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 167,\n",
       "    'y1': 1,\n",
       "    'y2': 224},\n",
       "   {'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 24,\n",
       "    'x2': 355,\n",
       "    'y1': 3,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003799.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 355},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 79,\n",
       "    'x2': 440,\n",
       "    'y1': 24,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002679.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 97,\n",
       "    'x2': 297,\n",
       "    'y1': 21,\n",
       "    'y2': 375},\n",
       "   {'class': 'dog',\n",
       "    'difficult': True,\n",
       "    'x1': 123,\n",
       "    'x2': 302,\n",
       "    'y1': 237,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000957.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 480,\n",
       "    'y1': 17,\n",
       "    'y2': 372}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005689.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 287,\n",
       "    'x2': 338,\n",
       "    'y1': 251,\n",
       "    'y2': 314},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 344,\n",
       "    'x2': 405,\n",
       "    'y1': 284,\n",
       "    'y2': 323}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007472.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 84,\n",
       "    'x2': 187,\n",
       "    'y1': 128,\n",
       "    'y2': 430},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 84,\n",
       "    'x2': 217,\n",
       "    'y1': 72,\n",
       "    'y2': 301}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004126.jpg',\n",
       "  'height': 480,\n",
       "  'imageset': 'test',\n",
       "  'width': 291},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 4,\n",
       "    'x2': 500,\n",
       "    'y1': 67,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 174,\n",
       "    'x2': 252,\n",
       "    'y1': 92,\n",
       "    'y2': 149}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009475.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 245,\n",
       "    'x2': 390,\n",
       "    'y1': 21,\n",
       "    'y2': 125},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 478,\n",
       "    'y1': 29,\n",
       "    'y2': 305},\n",
       "   {'class': 'horse',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 48,\n",
       "    'y1': 76,\n",
       "    'y2': 306}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001703.jpg',\n",
       "  'height': 319,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 152,\n",
       "    'y1': 89,\n",
       "    'y2': 256},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 164,\n",
       "    'x2': 500,\n",
       "    'y1': 18,\n",
       "    'y2': 333},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 4,\n",
       "    'x2': 178,\n",
       "    'y1': 117,\n",
       "    'y2': 271},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 193,\n",
       "    'x2': 269,\n",
       "    'y1': 35,\n",
       "    'y2': 214}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001411.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 17,\n",
       "    'x2': 430,\n",
       "    'y1': 103,\n",
       "    'y2': 209}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004802.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 75,\n",
       "    'x2': 355,\n",
       "    'y1': 177,\n",
       "    'y2': 257}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004147.jpg',\n",
       "  'height': 385,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 480,\n",
       "    'y1': 50,\n",
       "    'y2': 287}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007867.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 355,\n",
       "    'y1': 72,\n",
       "    'y2': 299},\n",
       "   {'class': 'train',\n",
       "    'difficult': True,\n",
       "    'x1': 323,\n",
       "    'x2': 500,\n",
       "    'y1': 84,\n",
       "    'y2': 269}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008165.jpg',\n",
       "  'height': 335,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 422,\n",
       "    'x2': 473,\n",
       "    'y1': 14,\n",
       "    'y2': 71}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003478.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 24,\n",
       "    'x2': 477,\n",
       "    'y1': 84,\n",
       "    'y2': 276},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 433,\n",
       "    'x2': 500,\n",
       "    'y1': 52,\n",
       "    'y2': 168},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 263,\n",
       "    'x2': 450,\n",
       "    'y1': 45,\n",
       "    'y2': 119},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 143,\n",
       "    'x2': 278,\n",
       "    'y1': 54,\n",
       "    'y2': 100},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 213,\n",
       "    'y1': 38,\n",
       "    'y2': 205}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003357.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 423,\n",
       "    'x2': 446,\n",
       "    'y1': 141,\n",
       "    'y2': 160},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 435,\n",
       "    'x2': 454,\n",
       "    'y1': 160,\n",
       "    'y2': 177},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 445,\n",
       "    'x2': 465,\n",
       "    'y1': 178,\n",
       "    'y2': 198},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 434,\n",
       "    'x2': 453,\n",
       "    'y1': 199,\n",
       "    'y2': 216},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 456,\n",
       "    'x2': 475,\n",
       "    'y1': 200,\n",
       "    'y2': 216},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 475,\n",
       "    'x2': 496,\n",
       "    'y1': 199,\n",
       "    'y2': 215},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 440,\n",
       "    'x2': 459,\n",
       "    'y1': 218,\n",
       "    'y2': 235},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 426,\n",
       "    'x2': 444,\n",
       "    'y1': 237,\n",
       "    'y2': 254},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 414,\n",
       "    'x2': 433,\n",
       "    'y1': 257,\n",
       "    'y2': 273}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009356.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 431,\n",
       "    'y1': 1,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001303.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 242,\n",
       "    'x2': 270,\n",
       "    'y1': 169,\n",
       "    'y2': 215}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005167.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 475,\n",
       "    'y1': 98,\n",
       "    'y2': 363}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009784.jpg',\n",
       "  'height': 385,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 55,\n",
       "    'x2': 456,\n",
       "    'y1': 50,\n",
       "    'y2': 235},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 394,\n",
       "    'x2': 500,\n",
       "    'y1': 163,\n",
       "    'y2': 212}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000260.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 38,\n",
       "    'x2': 288,\n",
       "    'y1': 42,\n",
       "    'y2': 444}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006712.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 21,\n",
       "    'x2': 471,\n",
       "    'y1': 76,\n",
       "    'y2': 276}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001218.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 94,\n",
       "    'x2': 261,\n",
       "    'y1': 281,\n",
       "    'y2': 445},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 77,\n",
       "    'x2': 176,\n",
       "    'y1': 235,\n",
       "    'y2': 363},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 303,\n",
       "    'x2': 333,\n",
       "    'y1': 253,\n",
       "    'y2': 329},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 174,\n",
       "    'x2': 234,\n",
       "    'y1': 257,\n",
       "    'y2': 339},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 41,\n",
       "    'x2': 80,\n",
       "    'y1': 273,\n",
       "    'y2': 319},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 242,\n",
       "    'x2': 270,\n",
       "    'y1': 146,\n",
       "    'y2': 182},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 94,\n",
       "    'x2': 121,\n",
       "    'y1': 175,\n",
       "    'y2': 204},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 21,\n",
       "    'x2': 71,\n",
       "    'y1': 259,\n",
       "    'y2': 302},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 8,\n",
       "    'x2': 38,\n",
       "    'y1': 252,\n",
       "    'y2': 302},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 28,\n",
       "    'x2': 81,\n",
       "    'y1': 157,\n",
       "    'y2': 189},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 91,\n",
       "    'x2': 119,\n",
       "    'y1': 142,\n",
       "    'y2': 173},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 136,\n",
       "    'x2': 164,\n",
       "    'y1': 128,\n",
       "    'y2': 162},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 194,\n",
       "    'x2': 216,\n",
       "    'y1': 132,\n",
       "    'y2': 160},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 212,\n",
       "    'x2': 239,\n",
       "    'y1': 121,\n",
       "    'y2': 151},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 63,\n",
       "    'x2': 102,\n",
       "    'y1': 125,\n",
       "    'y2': 155},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 15,\n",
       "    'x2': 38,\n",
       "    'y1': 56,\n",
       "    'y2': 84},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 14,\n",
       "    'x2': 36,\n",
       "    'y1': 39,\n",
       "    'y2': 61},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 260,\n",
       "    'x2': 299,\n",
       "    'y1': 93,\n",
       "    'y2': 118},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 187,\n",
       "    'x2': 208,\n",
       "    'y1': 60,\n",
       "    'y2': 79},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 209,\n",
       "    'x2': 231,\n",
       "    'y1': 68,\n",
       "    'y2': 89},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 236,\n",
       "    'x2': 258,\n",
       "    'y1': 75,\n",
       "    'y2': 97},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 258,\n",
       "    'x2': 273,\n",
       "    'y1': 80,\n",
       "    'y2': 101},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 234,\n",
       "    'x2': 263,\n",
       "    'y1': 57,\n",
       "    'y2': 73},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 274,\n",
       "    'x2': 293,\n",
       "    'y1': 70,\n",
       "    'y2': 94},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 318,\n",
       "    'x2': 334,\n",
       "    'y1': 65,\n",
       "    'y2': 87},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': True,\n",
       "    'x1': 308,\n",
       "    'x2': 334,\n",
       "    'y1': 207,\n",
       "    'y2': 251}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004827.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 334},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 76,\n",
       "    'x2': 201,\n",
       "    'y1': 6,\n",
       "    'y2': 498},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 4,\n",
       "    'x2': 373,\n",
       "    'y1': 3,\n",
       "    'y2': 446}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001631.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 43,\n",
       "    'x2': 387,\n",
       "    'y1': 213,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 142,\n",
       "    'y1': 224,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 183,\n",
       "    'x2': 352,\n",
       "    'y1': 233,\n",
       "    'y2': 374},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 370,\n",
       "    'x2': 436,\n",
       "    'y1': 209,\n",
       "    'y2': 302},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 352,\n",
       "    'x2': 406,\n",
       "    'y1': 178,\n",
       "    'y2': 233},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 194,\n",
       "    'x2': 245,\n",
       "    'y1': 175,\n",
       "    'y2': 232},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 87,\n",
       "    'x2': 149,\n",
       "    'y1': 186,\n",
       "    'y2': 252}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002724.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 378,\n",
       "    'x2': 496,\n",
       "    'y1': 1,\n",
       "    'y2': 119}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005623.jpg',\n",
       "  'height': 403,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 12,\n",
       "    'x2': 490,\n",
       "    'y1': 105,\n",
       "    'y2': 279}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000415.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 39,\n",
       "    'x2': 473,\n",
       "    'y1': 43,\n",
       "    'y2': 330}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001838.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 320,\n",
       "    'x2': 500,\n",
       "    'y1': 128,\n",
       "    'y2': 260},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 26,\n",
       "    'x2': 140,\n",
       "    'y1': 133,\n",
       "    'y2': 245},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 412,\n",
       "    'x2': 496,\n",
       "    'y1': 49,\n",
       "    'y2': 161},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 72,\n",
       "    'y1': 80,\n",
       "    'y2': 255}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009229.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 7,\n",
       "    'x2': 500,\n",
       "    'y1': 54,\n",
       "    'y2': 338}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001530.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 36,\n",
       "    'x2': 437,\n",
       "    'y1': 54,\n",
       "    'y2': 268}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007880.jpg',\n",
       "  'height': 343,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 498,\n",
       "    'y1': 1,\n",
       "    'y2': 353}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003683.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 99,\n",
       "    'x2': 341,\n",
       "    'y1': 35,\n",
       "    'y2': 243},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000659.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 89,\n",
       "    'x2': 193,\n",
       "    'y1': 54,\n",
       "    'y2': 350},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 271,\n",
       "    'x2': 376,\n",
       "    'y1': 57,\n",
       "    'y2': 364}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001706.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 7,\n",
       "    'x2': 500,\n",
       "    'y1': 16,\n",
       "    'y2': 310}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005820.jpg',\n",
       "  'height': 310,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 119,\n",
       "    'x2': 213,\n",
       "    'y1': 112,\n",
       "    'y2': 429},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 99,\n",
       "    'x2': 237,\n",
       "    'y1': 106,\n",
       "    'y2': 281}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007253.jpg',\n",
       "  'height': 480,\n",
       "  'imageset': 'test',\n",
       "  'width': 318},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 58,\n",
       "    'x2': 270,\n",
       "    'y1': 174,\n",
       "    'y2': 285},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 156,\n",
       "    'y1': 220,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 208,\n",
       "    'x2': 267,\n",
       "    'y1': 139,\n",
       "    'y2': 235}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000097.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 167,\n",
       "    'x2': 265,\n",
       "    'y1': 298,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 265,\n",
       "    'x2': 408,\n",
       "    'y1': 322,\n",
       "    'y2': 375},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 443,\n",
       "    'x2': 500,\n",
       "    'y1': 242,\n",
       "    'y2': 337},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 290,\n",
       "    'x2': 500,\n",
       "    'y1': 297,\n",
       "    'y2': 374},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 345,\n",
       "    'x2': 388,\n",
       "    'y1': 208,\n",
       "    'y2': 305}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001600.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 252,\n",
       "    'y1': 159,\n",
       "    'y2': 251},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 220,\n",
       "    'x2': 391,\n",
       "    'y1': 30,\n",
       "    'y2': 236}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001202.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 5,\n",
       "    'x2': 500,\n",
       "    'y1': 51,\n",
       "    'y2': 344},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 444,\n",
       "    'x2': 465,\n",
       "    'y1': 234,\n",
       "    'y2': 374},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 156,\n",
       "    'x2': 205,\n",
       "    'y1': 128,\n",
       "    'y2': 166}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001705.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 104,\n",
       "    'x2': 375,\n",
       "    'y1': 162,\n",
       "    'y2': 221}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008308.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 186,\n",
       "    'x2': 478,\n",
       "    'y1': 70,\n",
       "    'y2': 367},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 224,\n",
       "    'y1': 60,\n",
       "    'y2': 310},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 18,\n",
       "    'x2': 500,\n",
       "    'y1': 71,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008721.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 64,\n",
       "    'x2': 359,\n",
       "    'y1': 163,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005000.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 245,\n",
       "    'x2': 415,\n",
       "    'y1': 1,\n",
       "    'y2': 197}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001814.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 207,\n",
       "    'x2': 305,\n",
       "    'y1': 118,\n",
       "    'y2': 235},\n",
       "   {'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 302,\n",
       "    'x2': 412,\n",
       "    'y1': 91,\n",
       "    'y2': 246}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000835.jpg',\n",
       "  'height': 335,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 198,\n",
       "    'x2': 283,\n",
       "    'y1': 245,\n",
       "    'y2': 312}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007922.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 153,\n",
       "    'x2': 450,\n",
       "    'y1': 11,\n",
       "    'y2': 353}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009485.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 52,\n",
       "    'x2': 447,\n",
       "    'y1': 11,\n",
       "    'y2': 337}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001339.jpg',\n",
       "  'height': 358,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 29,\n",
       "    'x2': 272,\n",
       "    'y1': 243,\n",
       "    'y2': 441},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 253,\n",
       "    'x2': 296,\n",
       "    'y1': 167,\n",
       "    'y2': 220},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 68,\n",
       "    'x2': 147,\n",
       "    'y1': 131,\n",
       "    'y2': 181},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 46,\n",
       "    'y1': 141,\n",
       "    'y2': 184},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 231,\n",
       "    'x2': 319,\n",
       "    'y1': 126,\n",
       "    'y2': 174},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 297,\n",
       "    'x2': 333,\n",
       "    'y1': 132,\n",
       "    'y2': 174},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 139,\n",
       "    'x2': 259,\n",
       "    'y1': 58,\n",
       "    'y2': 415},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 55,\n",
       "    'x2': 76,\n",
       "    'y1': 138,\n",
       "    'y2': 185}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002141.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 14,\n",
       "    'x2': 449,\n",
       "    'y1': 141,\n",
       "    'y2': 289}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004278.jpg',\n",
       "  'height': 341,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 106,\n",
       "    'x2': 392,\n",
       "    'y1': 121,\n",
       "    'y2': 299}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001458.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 12,\n",
       "    'x2': 24,\n",
       "    'y1': 256,\n",
       "    'y2': 291},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 22,\n",
       "    'x2': 36,\n",
       "    'y1': 255,\n",
       "    'y2': 291},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 43,\n",
       "    'x2': 58,\n",
       "    'y1': 259,\n",
       "    'y2': 292},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 429,\n",
       "    'x2': 443,\n",
       "    'y1': 252,\n",
       "    'y2': 291},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 444,\n",
       "    'x2': 459,\n",
       "    'y1': 255,\n",
       "    'y2': 289},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 475,\n",
       "    'x2': 500,\n",
       "    'y1': 234,\n",
       "    'y2': 298},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 366,\n",
       "    'x2': 427,\n",
       "    'y1': 203,\n",
       "    'y2': 339},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 206,\n",
       "    'x2': 284,\n",
       "    'y1': 203,\n",
       "    'y2': 372},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 160,\n",
       "    'x2': 190,\n",
       "    'y1': 245,\n",
       "    'y2': 307}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005865.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 19,\n",
       "    'x2': 488,\n",
       "    'y1': 43,\n",
       "    'y2': 337}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006479.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 195,\n",
       "    'x2': 335,\n",
       "    'y1': 18,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 34,\n",
       "    'x2': 222,\n",
       "    'y1': 72,\n",
       "    'y2': 500},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 271,\n",
       "    'x2': 375,\n",
       "    'y1': 350,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003541.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 376,\n",
       "    'x2': 460,\n",
       "    'y1': 279,\n",
       "    'y2': 355}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007893.jpg',\n",
       "  'height': 386,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 59,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 316}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005683.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 373,\n",
       "    'y1': 40,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002527.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 111,\n",
       "    'x2': 500,\n",
       "    'y1': 14,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 376,\n",
       "    'y1': 25,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005152.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 100,\n",
       "    'x2': 358,\n",
       "    'y1': 87,\n",
       "    'y2': 260}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005987.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 152,\n",
       "    'x2': 183,\n",
       "    'y1': 153,\n",
       "    'y2': 239},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 44,\n",
       "    'x2': 110,\n",
       "    'y1': 256,\n",
       "    'y2': 396},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 69,\n",
       "    'y1': 206,\n",
       "    'y2': 405}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007719.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 221},\n",
       " {'bboxes': [{'class': 'train',\n",
       "    'difficult': False,\n",
       "    'x1': 70,\n",
       "    'x2': 355,\n",
       "    'y1': 92,\n",
       "    'y2': 287}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009011.jpg',\n",
       "  'height': 351,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 128,\n",
       "    'x2': 234,\n",
       "    'y1': 1,\n",
       "    'y2': 124},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 196,\n",
       "    'x2': 500,\n",
       "    'y1': 75,\n",
       "    'y2': 346},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 499,\n",
       "    'y1': 62,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001065.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 67,\n",
       "    'x2': 477,\n",
       "    'y1': 84,\n",
       "    'y2': 314},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 355,\n",
       "    'x2': 408,\n",
       "    'y1': 137,\n",
       "    'y2': 179}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003016.jpg',\n",
       "  'height': 329,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 82,\n",
       "    'x2': 202,\n",
       "    'y1': 190,\n",
       "    'y2': 418},\n",
       "   {'class': 'horse',\n",
       "    'difficult': True,\n",
       "    'x1': 60,\n",
       "    'x2': 135,\n",
       "    'y1': 157,\n",
       "    'y2': 205},\n",
       "   {'class': 'horse',\n",
       "    'difficult': True,\n",
       "    'x1': 135,\n",
       "    'x2': 221,\n",
       "    'y1': 170,\n",
       "    'y2': 245}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006756.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 322},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 63,\n",
       "    'x2': 366,\n",
       "    'y1': 12,\n",
       "    'y2': 462},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 183,\n",
       "    'y1': 23,\n",
       "    'y2': 433},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 143,\n",
       "    'x2': 308,\n",
       "    'y1': 294,\n",
       "    'y2': 447},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 81,\n",
       "    'y1': 311,\n",
       "    'y2': 417}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005745.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 366},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 208,\n",
       "    'x2': 500,\n",
       "    'y1': 2,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 114,\n",
       "    'y1': 74,\n",
       "    'y2': 375},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 204,\n",
       "    'x2': 303,\n",
       "    'y1': 1,\n",
       "    'y2': 64}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006446.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 75,\n",
       "    'x2': 419,\n",
       "    'y1': 40,\n",
       "    'y2': 321}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001804.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 61,\n",
       "    'x2': 400,\n",
       "    'y1': 43,\n",
       "    'y2': 319}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002309.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 305,\n",
       "    'y1': 27,\n",
       "    'y2': 499}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002400.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 350},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 382,\n",
       "    'x2': 464,\n",
       "    'y1': 152,\n",
       "    'y2': 209},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 283,\n",
       "    'x2': 358,\n",
       "    'y1': 156,\n",
       "    'y2': 211},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 157,\n",
       "    'x2': 241,\n",
       "    'y1': 153,\n",
       "    'y2': 212},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 36,\n",
       "    'x2': 139,\n",
       "    'y1': 153,\n",
       "    'y2': 214},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 334,\n",
       "    'x2': 362,\n",
       "    'y1': 150,\n",
       "    'y2': 164}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006242.jpg',\n",
       "  'height': 374,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 111,\n",
       "    'x2': 345,\n",
       "    'y1': 182,\n",
       "    'y2': 289},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 433,\n",
       "    'x2': 500,\n",
       "    'y1': 203,\n",
       "    'y2': 294},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 420,\n",
       "    'x2': 486,\n",
       "    'y1': 63,\n",
       "    'y2': 207}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004964.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 214,\n",
       "    'x2': 326,\n",
       "    'y1': 282,\n",
       "    'y2': 380},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 280,\n",
       "    'y1': 19,\n",
       "    'y2': 500},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 358,\n",
       "    'x2': 375,\n",
       "    'y1': 322,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002905.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 5,\n",
       "    'x2': 467,\n",
       "    'y1': 48,\n",
       "    'y2': 329}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005201.jpg',\n",
       "  'height': 372,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 124,\n",
       "    'x2': 373,\n",
       "    'y1': 38,\n",
       "    'y2': 330},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 442,\n",
       "    'x2': 500,\n",
       "    'y1': 46,\n",
       "    'y2': 226},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 383,\n",
       "    'x2': 453,\n",
       "    'y1': 2,\n",
       "    'y2': 268},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 313,\n",
       "    'x2': 468,\n",
       "    'y1': 3,\n",
       "    'y2': 268},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 218,\n",
       "    'x2': 317,\n",
       "    'y1': 2,\n",
       "    'y2': 79},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 50,\n",
       "    'x2': 77,\n",
       "    'y1': 25,\n",
       "    'y2': 176},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 43,\n",
       "    'x2': 75,\n",
       "    'y1': 45,\n",
       "    'y2': 227}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007553.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 63,\n",
       "    'x2': 181,\n",
       "    'y1': 131,\n",
       "    'y2': 456}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008565.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 357},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 5,\n",
       "    'x2': 448,\n",
       "    'y1': 71,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004709.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 73,\n",
       "    'x2': 360,\n",
       "    'y1': 64,\n",
       "    'y2': 375},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 174,\n",
       "    'y1': 1,\n",
       "    'y2': 122}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008566.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 453,\n",
       "    'x2': 500,\n",
       "    'y1': 115,\n",
       "    'y2': 231},\n",
       "   {'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 310,\n",
       "    'x2': 454,\n",
       "    'y1': 125,\n",
       "    'y2': 224},\n",
       "   {'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 238,\n",
       "    'x2': 309,\n",
       "    'y1': 153,\n",
       "    'y2': 212}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007156.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 173,\n",
       "    'x2': 219,\n",
       "    'y1': 27,\n",
       "    'y2': 116},\n",
       "   {'class': 'sheep',\n",
       "    'difficult': False,\n",
       "    'x1': 297,\n",
       "    'x2': 363,\n",
       "    'y1': 31,\n",
       "    'y2': 114}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006491.jpg',\n",
       "  'height': 171,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 250,\n",
       "    'x2': 328,\n",
       "    'y1': 184,\n",
       "    'y2': 303},\n",
       "   {'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 394,\n",
       "    'x2': 425,\n",
       "    'y1': 260,\n",
       "    'y2': 293},\n",
       "   {'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 11,\n",
       "    'x2': 28,\n",
       "    'y1': 255,\n",
       "    'y2': 290},\n",
       "   {'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 86,\n",
       "    'x2': 100,\n",
       "    'y1': 256,\n",
       "    'y2': 290}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006205.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 373,\n",
       "    'y1': 9,\n",
       "    'y2': 421}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002275.jpg',\n",
       "  'height': 421,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 481,\n",
       "    'y1': 130,\n",
       "    'y2': 233}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002661.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 33,\n",
       "    'x2': 496,\n",
       "    'y1': 26,\n",
       "    'y2': 313}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001197.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 129,\n",
       "    'x2': 360,\n",
       "    'y1': 165,\n",
       "    'y2': 297}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005472.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 159,\n",
       "    'x2': 500,\n",
       "    'y1': 7,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006044.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 15,\n",
       "    'x2': 144,\n",
       "    'y1': 127,\n",
       "    'y2': 370},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 87,\n",
       "    'x2': 176,\n",
       "    'y1': 92,\n",
       "    'y2': 331},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 157,\n",
       "    'x2': 246,\n",
       "    'y1': 91,\n",
       "    'y2': 322},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 219,\n",
       "    'x2': 305,\n",
       "    'y1': 67,\n",
       "    'y2': 329},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 281,\n",
       "    'x2': 354,\n",
       "    'y1': 73,\n",
       "    'y2': 317},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 339,\n",
       "    'x2': 431,\n",
       "    'y1': 36,\n",
       "    'y2': 316},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 416,\n",
       "    'x2': 500,\n",
       "    'y1': 27,\n",
       "    'y2': 315}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004485.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 209,\n",
       "    'x2': 396,\n",
       "    'y1': 20,\n",
       "    'y2': 74},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 310,\n",
       "    'x2': 400,\n",
       "    'y1': 40,\n",
       "    'y2': 97},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 118,\n",
       "    'x2': 210,\n",
       "    'y1': 59,\n",
       "    'y2': 143},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 132,\n",
       "    'x2': 450,\n",
       "    'y1': 72,\n",
       "    'y2': 323},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 378,\n",
       "    'x2': 500,\n",
       "    'y1': 43,\n",
       "    'y2': 173}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001658.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 165,\n",
       "    'x2': 387,\n",
       "    'y1': 60,\n",
       "    'y2': 334}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000056.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 269,\n",
       "    'x2': 355,\n",
       "    'y1': 221,\n",
       "    'y2': 284}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001697.jpg',\n",
       "  'height': 299,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 35,\n",
       "    'x2': 192,\n",
       "    'y1': 199,\n",
       "    'y2': 308}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007030.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 146,\n",
       "    'x2': 386,\n",
       "    'y1': 52,\n",
       "    'y2': 264},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 69,\n",
       "    'x2': 322,\n",
       "    'y1': 208,\n",
       "    'y2': 360},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 221,\n",
       "    'y1': 1,\n",
       "    'y2': 235},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 382,\n",
       "    'x2': 499,\n",
       "    'y1': 1,\n",
       "    'y2': 212}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003819.jpg',\n",
       "  'height': 376,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 470,\n",
       "    'y1': 57,\n",
       "    'y2': 346}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002078.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 201,\n",
       "    'x2': 453,\n",
       "    'y1': 149,\n",
       "    'y2': 324},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 196,\n",
       "    'x2': 252,\n",
       "    'y1': 133,\n",
       "    'y2': 226},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 156,\n",
       "    'x2': 205,\n",
       "    'y1': 129,\n",
       "    'y2': 220},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 288,\n",
       "    'x2': 460,\n",
       "    'y1': 99,\n",
       "    'y2': 368},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 36,\n",
       "    'x2': 115,\n",
       "    'y1': 50,\n",
       "    'y2': 271}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003115.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 63,\n",
       "    'x2': 480,\n",
       "    'y1': 76,\n",
       "    'y2': 298}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001280.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 25,\n",
       "    'x2': 179,\n",
       "    'y1': 22,\n",
       "    'y2': 466},\n",
       "   {'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 179,\n",
       "    'x2': 300,\n",
       "    'y1': 49,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006640.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 131,\n",
       "    'x2': 455,\n",
       "    'y1': 67,\n",
       "    'y2': 299},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 332,\n",
       "    'x2': 500,\n",
       "    'y1': 200,\n",
       "    'y2': 325},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 210,\n",
       "    'x2': 286,\n",
       "    'y1': 186,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004030.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 17,\n",
       "    'x2': 252,\n",
       "    'y1': 22,\n",
       "    'y2': 207},\n",
       "   {'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 262,\n",
       "    'x2': 486,\n",
       "    'y1': 34,\n",
       "    'y2': 193}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002453.jpg',\n",
       "  'height': 209,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 365,\n",
       "    'x2': 460,\n",
       "    'y1': 115,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 274,\n",
       "    'x2': 349,\n",
       "    'y1': 116,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 137,\n",
       "    'x2': 242,\n",
       "    'y1': 93,\n",
       "    'y2': 368},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 463,\n",
       "    'x2': 500,\n",
       "    'y1': 144,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 26,\n",
       "    'y1': 118,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 17,\n",
       "    'x2': 71,\n",
       "    'y1': 136,\n",
       "    'y2': 222},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 15,\n",
       "    'x2': 98,\n",
       "    'y1': 185,\n",
       "    'y2': 237}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004523.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 39,\n",
       "    'x2': 499,\n",
       "    'y1': 271,\n",
       "    'y2': 373},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 196,\n",
       "    'x2': 446,\n",
       "    'y1': 136,\n",
       "    'y2': 271},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 45,\n",
       "    'y1': 274,\n",
       "    'y2': 374},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 74,\n",
       "    'x2': 93,\n",
       "    'y1': 187,\n",
       "    'y2': 282},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 98,\n",
       "    'x2': 130,\n",
       "    'y1': 183,\n",
       "    'y2': 280},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 140,\n",
       "    'x2': 169,\n",
       "    'y1': 184,\n",
       "    'y2': 275},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 167,\n",
       "    'x2': 211,\n",
       "    'y1': 188,\n",
       "    'y2': 266},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 167,\n",
       "    'x2': 189,\n",
       "    'y1': 173,\n",
       "    'y2': 207},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 116,\n",
       "    'x2': 135,\n",
       "    'y1': 181,\n",
       "    'y2': 278},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 45,\n",
       "    'y1': 169,\n",
       "    'y2': 310},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 377,\n",
       "    'x2': 400,\n",
       "    'y1': 202,\n",
       "    'y2': 228},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 480,\n",
       "    'x2': 500,\n",
       "    'y1': 211,\n",
       "    'y2': 279},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 453,\n",
       "    'x2': 482,\n",
       "    'y1': 217,\n",
       "    'y2': 262},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 453,\n",
       "    'x2': 475,\n",
       "    'y1': 241,\n",
       "    'y2': 271},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 107,\n",
       "    'x2': 150,\n",
       "    'y1': 272,\n",
       "    'y2': 319},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 412,\n",
       "    'x2': 439,\n",
       "    'y1': 202,\n",
       "    'y2': 245},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 202,\n",
       "    'x2': 227,\n",
       "    'y1': 196,\n",
       "    'y2': 241}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009284.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 58,\n",
       "    'x2': 462,\n",
       "    'y1': 106,\n",
       "    'y2': 216}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001547.jpg',\n",
       "  'height': 339,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 17,\n",
       "    'x2': 417,\n",
       "    'y1': 52,\n",
       "    'y2': 291}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004865.jpg',\n",
       "  'height': 304,\n",
       "  'imageset': 'test',\n",
       "  'width': 458},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 333,\n",
       "    'y1': 12,\n",
       "    'y2': 500},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 333,\n",
       "    'y1': 274,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004480.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 334},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 184,\n",
       "    'x2': 207,\n",
       "    'y1': 153,\n",
       "    'y2': 173},\n",
       "   {'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 291,\n",
       "    'x2': 352,\n",
       "    'y1': 147,\n",
       "    'y2': 167},\n",
       "   {'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 143,\n",
       "    'x2': 224,\n",
       "    'y1': 118,\n",
       "    'y2': 165},\n",
       "   {'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 87,\n",
       "    'x2': 138,\n",
       "    'y1': 149,\n",
       "    'y2': 164}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008373.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 82,\n",
       "    'x2': 500,\n",
       "    'y1': 126,\n",
       "    'y2': 295}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006801.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 9,\n",
       "    'x2': 500,\n",
       "    'y1': 19,\n",
       "    'y2': 354}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005188.jpg',\n",
       "  'height': 368,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 6,\n",
       "    'x2': 495,\n",
       "    'y1': 45,\n",
       "    'y2': 276}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002769.jpg',\n",
       "  'height': 339,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 155,\n",
       "    'y1': 27,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 121,\n",
       "    'x2': 246,\n",
       "    'y1': 46,\n",
       "    'y2': 244},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 97,\n",
       "    'x2': 367,\n",
       "    'y1': 133,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 135,\n",
       "    'x2': 500,\n",
       "    'y1': 18,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002878.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 148,\n",
       "    'x2': 323,\n",
       "    'y1': 170,\n",
       "    'y2': 375},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 281,\n",
       "    'x2': 462,\n",
       "    'y1': 174,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 295,\n",
       "    'x2': 433,\n",
       "    'y1': 79,\n",
       "    'y2': 315},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 143,\n",
       "    'x2': 284,\n",
       "    'y1': 42,\n",
       "    'y2': 350}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007658.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 105,\n",
       "    'x2': 377,\n",
       "    'y1': 39,\n",
       "    'y2': 321}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002303.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 422,\n",
       "    'x2': 430,\n",
       "    'y1': 153,\n",
       "    'y2': 177},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 403,\n",
       "    'x2': 412,\n",
       "    'y1': 151,\n",
       "    'y2': 178},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 366,\n",
       "    'x2': 500,\n",
       "    'y1': 184,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003544.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 5,\n",
       "    'x2': 496,\n",
       "    'y1': 121,\n",
       "    'y2': 250}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004645.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 153,\n",
       "    'x2': 454,\n",
       "    'y1': 79,\n",
       "    'y2': 252},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 256,\n",
       "    'y1': 127,\n",
       "    'y2': 317}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005862.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 48,\n",
       "    'x2': 249,\n",
       "    'y1': 18,\n",
       "    'y2': 359},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 182,\n",
       "    'x2': 321,\n",
       "    'y1': 82,\n",
       "    'y2': 332}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003831.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 80,\n",
       "    'x2': 462,\n",
       "    'y1': 55,\n",
       "    'y2': 465},\n",
       "   {'class': 'tvmonitor',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 33,\n",
       "    'y1': 1,\n",
       "    'y2': 48}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009319.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 28,\n",
       "    'x2': 485,\n",
       "    'y1': 115,\n",
       "    'y2': 249},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 19,\n",
       "    'x2': 33,\n",
       "    'y1': 173,\n",
       "    'y2': 214},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 13,\n",
       "    'y1': 174,\n",
       "    'y2': 211},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 342,\n",
       "    'x2': 403,\n",
       "    'y1': 135,\n",
       "    'y2': 221},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 479,\n",
       "    'x2': 500,\n",
       "    'y1': 192,\n",
       "    'y2': 238}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005870.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 287,\n",
       "    'x2': 432,\n",
       "    'y1': 155,\n",
       "    'y2': 266},\n",
       "   {'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 137,\n",
       "    'x2': 204,\n",
       "    'y1': 166,\n",
       "    'y2': 236},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 68,\n",
       "    'x2': 178,\n",
       "    'y1': 130,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000386.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 337,\n",
       "    'x2': 436,\n",
       "    'y1': 184,\n",
       "    'y2': 234},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 455,\n",
       "    'x2': 500,\n",
       "    'y1': 191,\n",
       "    'y2': 235},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 194,\n",
       "    'x2': 295,\n",
       "    'y1': 175,\n",
       "    'y2': 234},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 74,\n",
       "    'y1': 192,\n",
       "    'y2': 262}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009777.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 344,\n",
       "    'x2': 432,\n",
       "    'y1': 176,\n",
       "    'y2': 306},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 297,\n",
       "    'x2': 349,\n",
       "    'y1': 181,\n",
       "    'y2': 266},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 116,\n",
       "    'x2': 189,\n",
       "    'y1': 144,\n",
       "    'y2': 270},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 341,\n",
       "    'x2': 424,\n",
       "    'y1': 79,\n",
       "    'y2': 283},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 290,\n",
       "    'x2': 344,\n",
       "    'y1': 132,\n",
       "    'y2': 262},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 111,\n",
       "    'x2': 186,\n",
       "    'y1': 61,\n",
       "    'y2': 245},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 10,\n",
       "    'x2': 61,\n",
       "    'y1': 75,\n",
       "    'y2': 140}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002239.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 118,\n",
       "    'x2': 196,\n",
       "    'y1': 172,\n",
       "    'y2': 251},\n",
       "   {'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 166,\n",
       "    'x2': 271,\n",
       "    'y1': 130,\n",
       "    'y2': 315}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005997.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 401,\n",
       "    'x2': 440,\n",
       "    'y1': 154,\n",
       "    'y2': 216},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 373,\n",
       "    'x2': 427,\n",
       "    'y1': 163,\n",
       "    'y2': 233},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': True,\n",
       "    'x1': 450,\n",
       "    'x2': 499,\n",
       "    'y1': 122,\n",
       "    'y2': 234},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 450,\n",
       "    'x2': 500,\n",
       "    'y1': 213,\n",
       "    'y2': 269},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 467,\n",
       "    'x2': 500,\n",
       "    'y1': 234,\n",
       "    'y2': 308}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008626.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cow',\n",
       "    'difficult': False,\n",
       "    'x1': 111,\n",
       "    'x2': 335,\n",
       "    'y1': 131,\n",
       "    'y2': 318}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004901.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 325,\n",
       "    'x2': 355,\n",
       "    'y1': 165,\n",
       "    'y2': 192}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001505.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 77,\n",
       "    'x2': 139,\n",
       "    'y1': 112,\n",
       "    'y2': 372},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 117,\n",
       "    'x2': 165,\n",
       "    'y1': 147,\n",
       "    'y2': 373},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 163,\n",
       "    'x2': 220,\n",
       "    'y1': 127,\n",
       "    'y2': 175},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 164,\n",
       "    'x2': 239,\n",
       "    'y1': 137,\n",
       "    'y2': 374},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 235,\n",
       "    'x2': 292,\n",
       "    'y1': 118,\n",
       "    'y2': 373},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 282,\n",
       "    'x2': 366,\n",
       "    'y1': 126,\n",
       "    'y2': 374},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 330,\n",
       "    'x2': 499,\n",
       "    'y1': 72,\n",
       "    'y2': 373}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003234.jpg',\n",
       "  'height': 374,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bird',\n",
       "    'difficult': False,\n",
       "    'x1': 195,\n",
       "    'x2': 346,\n",
       "    'y1': 116,\n",
       "    'y2': 291}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006650.jpg',\n",
       "  'height': 334,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 10,\n",
       "    'x2': 173,\n",
       "    'y1': 239,\n",
       "    'y2': 460},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 173,\n",
       "    'x2': 331,\n",
       "    'y1': 242,\n",
       "    'y2': 454},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 78,\n",
       "    'x2': 201,\n",
       "    'y1': 228,\n",
       "    'y2': 390},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 202,\n",
       "    'x2': 315,\n",
       "    'y1': 226,\n",
       "    'y2': 378},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 70,\n",
       "    'x2': 281,\n",
       "    'y1': 240,\n",
       "    'y2': 411}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008490.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 370},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 362,\n",
       "    'x2': 404,\n",
       "    'y1': 195,\n",
       "    'y2': 246},\n",
       "   {'class': 'boat',\n",
       "    'difficult': True,\n",
       "    'x1': 418,\n",
       "    'x2': 439,\n",
       "    'y1': 159,\n",
       "    'y2': 176}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000295.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 153,\n",
       "    'x2': 241,\n",
       "    'y1': 238,\n",
       "    'y2': 440},\n",
       "   {'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 146,\n",
       "    'x2': 240,\n",
       "    'y1': 348,\n",
       "    'y2': 495}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007320.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 5,\n",
       "    'x2': 135,\n",
       "    'y1': 188,\n",
       "    'y2': 330},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 17,\n",
       "    'x2': 289,\n",
       "    'y1': 228,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 235,\n",
       "    'x2': 500,\n",
       "    'y1': 71,\n",
       "    'y2': 372}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001629.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 22,\n",
       "    'x2': 137,\n",
       "    'y1': 54,\n",
       "    'y2': 142},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 77,\n",
       "    'x2': 325,\n",
       "    'y1': 8,\n",
       "    'y2': 497}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005411.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 8,\n",
       "    'x2': 496,\n",
       "    'y1': 87,\n",
       "    'y2': 219}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002157.jpg',\n",
       "  'height': 329,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bicycle',\n",
       "    'difficult': False,\n",
       "    'x1': 75,\n",
       "    'x2': 289,\n",
       "    'y1': 267,\n",
       "    'y2': 480},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 96,\n",
       "    'x2': 277,\n",
       "    'y1': 114,\n",
       "    'y2': 390}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003976.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 169,\n",
       "    'x2': 277,\n",
       "    'y1': 120,\n",
       "    'y2': 225}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009043.jpg',\n",
       "  'height': 330,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 163,\n",
       "    'x2': 244,\n",
       "    'y1': 72,\n",
       "    'y2': 172},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 94,\n",
       "    'x2': 202,\n",
       "    'y1': 191,\n",
       "    'y2': 289}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006293.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 389,\n",
       "    'x2': 408,\n",
       "    'y1': 219,\n",
       "    'y2': 291},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 381,\n",
       "    'x2': 390,\n",
       "    'y1': 205,\n",
       "    'y2': 241},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 371,\n",
       "    'x2': 386,\n",
       "    'y1': 216,\n",
       "    'y2': 286},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 352,\n",
       "    'x2': 371,\n",
       "    'y1': 223,\n",
       "    'y2': 294},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 343,\n",
       "    'x2': 355,\n",
       "    'y1': 211,\n",
       "    'y2': 289},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 330,\n",
       "    'x2': 344,\n",
       "    'y1': 215,\n",
       "    'y2': 288},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': True,\n",
       "    'x1': 361,\n",
       "    'x2': 468,\n",
       "    'y1': 96,\n",
       "    'y2': 189},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 323,\n",
       "    'x2': 415,\n",
       "    'y1': 143,\n",
       "    'y2': 220},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': True,\n",
       "    'x1': 281,\n",
       "    'x2': 328,\n",
       "    'y1': 142,\n",
       "    'y2': 223},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': True,\n",
       "    'x1': 288,\n",
       "    'x2': 344,\n",
       "    'y1': 109,\n",
       "    'y2': 192}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004422.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 118,\n",
       "    'x2': 227,\n",
       "    'y1': 180,\n",
       "    'y2': 255},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 438,\n",
       "    'x2': 475,\n",
       "    'y1': 159,\n",
       "    'y2': 271},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 467,\n",
       "    'x2': 500,\n",
       "    'y1': 156,\n",
       "    'y2': 273},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 388,\n",
       "    'x2': 429,\n",
       "    'y1': 148,\n",
       "    'y2': 262},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 312,\n",
       "    'x2': 363,\n",
       "    'y1': 147,\n",
       "    'y2': 248},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 378,\n",
       "    'x2': 394,\n",
       "    'y1': 149,\n",
       "    'y2': 255},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 361,\n",
       "    'x2': 382,\n",
       "    'y1': 152,\n",
       "    'y2': 254},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 241,\n",
       "    'x2': 264,\n",
       "    'y1': 161,\n",
       "    'y2': 236},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 277,\n",
       "    'x2': 301,\n",
       "    'y1': 162,\n",
       "    'y2': 238},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 262,\n",
       "    'x2': 279,\n",
       "    'y1': 166,\n",
       "    'y2': 234},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 305,\n",
       "    'x2': 328,\n",
       "    'y1': 166,\n",
       "    'y2': 241},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 212,\n",
       "    'x2': 249,\n",
       "    'y1': 166,\n",
       "    'y2': 234},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 131,\n",
       "    'y1': 117,\n",
       "    'y2': 339},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 332,\n",
       "    'x2': 366,\n",
       "    'y1': 69,\n",
       "    'y2': 129},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 383,\n",
       "    'x2': 415,\n",
       "    'y1': 58,\n",
       "    'y2': 116},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 361,\n",
       "    'x2': 379,\n",
       "    'y1': 66,\n",
       "    'y2': 124},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 375,\n",
       "    'x2': 391,\n",
       "    'y1': 57,\n",
       "    'y2': 120}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009601.jpg',\n",
       "  'height': 339,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 9,\n",
       "    'x2': 494,\n",
       "    'y1': 200,\n",
       "    'y2': 364}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004586.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 444,\n",
       "    'y1': 71,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002970.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 113,\n",
       "    'x2': 229,\n",
       "    'y1': 321,\n",
       "    'y2': 500},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 86,\n",
       "    'x2': 333,\n",
       "    'y1': 1,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002950.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 404,\n",
       "    'x2': 500,\n",
       "    'y1': 4,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 425,\n",
       "    'x2': 464,\n",
       "    'y1': 1,\n",
       "    'y2': 125},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 296,\n",
       "    'x2': 317,\n",
       "    'y1': 1,\n",
       "    'y2': 78},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 317,\n",
       "    'x2': 360,\n",
       "    'y1': 1,\n",
       "    'y2': 72},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 97,\n",
       "    'x2': 203,\n",
       "    'y1': 1,\n",
       "    'y2': 86},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 61,\n",
       "    'x2': 432,\n",
       "    'y1': 42,\n",
       "    'y2': 347},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 270,\n",
       "    'y1': 2,\n",
       "    'y2': 181}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002379.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 188,\n",
       "    'x2': 304,\n",
       "    'y1': 46,\n",
       "    'y2': 208},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 82,\n",
       "    'x2': 388,\n",
       "    'y1': 53,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000330.jpg',\n",
       "  'height': 349,\n",
       "  'imageset': 'test',\n",
       "  'width': 480},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 22,\n",
       "    'x2': 500,\n",
       "    'y1': 33,\n",
       "    'y2': 347},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 266,\n",
       "    'x2': 373,\n",
       "    'y1': 1,\n",
       "    'y2': 50},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 112,\n",
       "    'x2': 144,\n",
       "    'y1': 15,\n",
       "    'y2': 39}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008447.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 257,\n",
       "    'y1': 1,\n",
       "    'y2': 337}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006087.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 458,\n",
       "    'y1': 76,\n",
       "    'y2': 282},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 231,\n",
       "    'x2': 266,\n",
       "    'y1': 204,\n",
       "    'y2': 282},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 409,\n",
       "    'x2': 450,\n",
       "    'y1': 189,\n",
       "    'y2': 310},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 362,\n",
       "    'x2': 401,\n",
       "    'y1': 188,\n",
       "    'y2': 311},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 341,\n",
       "    'x2': 376,\n",
       "    'y1': 190,\n",
       "    'y2': 303},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 472,\n",
       "    'x2': 499,\n",
       "    'y1': 193,\n",
       "    'y2': 274},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 444,\n",
       "    'x2': 474,\n",
       "    'y1': 192,\n",
       "    'y2': 262},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 426,\n",
       "    'x2': 447,\n",
       "    'y1': 186,\n",
       "    'y2': 258},\n",
       "   {'class': 'aeroplane',\n",
       "    'difficult': True,\n",
       "    'x1': 458,\n",
       "    'x2': 500,\n",
       "    'y1': 166,\n",
       "    'y2': 200},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 135,\n",
       "    'x2': 192,\n",
       "    'y1': 204,\n",
       "    'y2': 222}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008104.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 351,\n",
       "    'x2': 500,\n",
       "    'y1': 312,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 387,\n",
       "    'x2': 500,\n",
       "    'y1': 207,\n",
       "    'y2': 335},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 373,\n",
       "    'x2': 404,\n",
       "    'y1': 163,\n",
       "    'y2': 201},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 127,\n",
       "    'x2': 206,\n",
       "    'y1': 148,\n",
       "    'y2': 202},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 39,\n",
       "    'x2': 62,\n",
       "    'y1': 114,\n",
       "    'y2': 130},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 114,\n",
       "    'x2': 393,\n",
       "    'y1': 186,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 390,\n",
       "    'x2': 494,\n",
       "    'y1': 114,\n",
       "    'y2': 319},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 317,\n",
       "    'x2': 387,\n",
       "    'y1': 141,\n",
       "    'y2': 242},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 140,\n",
       "    'y1': 160,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 47,\n",
       "    'y1': 129,\n",
       "    'y2': 238},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 69,\n",
       "    'x2': 125,\n",
       "    'y1': 107,\n",
       "    'y2': 191},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 132,\n",
       "    'x2': 176,\n",
       "    'y1': 100,\n",
       "    'y2': 164},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 132,\n",
       "    'x2': 160,\n",
       "    'y1': 67,\n",
       "    'y2': 139},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 301,\n",
       "    'x2': 328,\n",
       "    'y1': 204,\n",
       "    'y2': 284}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003459.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 8,\n",
       "    'x2': 482,\n",
       "    'y1': 3,\n",
       "    'y2': 331},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 398,\n",
       "    'x2': 500,\n",
       "    'y1': 14,\n",
       "    'y2': 186},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 12,\n",
       "    'x2': 110,\n",
       "    'y1': 30,\n",
       "    'y2': 132}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000769.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 151,\n",
       "    'x2': 201,\n",
       "    'y1': 239,\n",
       "    'y2': 283}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006211.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 301},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 208,\n",
       "    'x2': 365,\n",
       "    'y1': 104,\n",
       "    'y2': 330},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 31,\n",
       "    'x2': 79,\n",
       "    'y1': 181,\n",
       "    'y2': 227},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 18,\n",
       "    'y1': 176,\n",
       "    'y2': 235},\n",
       "   {'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 499,\n",
       "    'y1': 171,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003483.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 211,\n",
       "    'x2': 309,\n",
       "    'y1': 209,\n",
       "    'y2': 349},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 320,\n",
       "    'x2': 500,\n",
       "    'y1': 2,\n",
       "    'y2': 241},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 181,\n",
       "    'x2': 288,\n",
       "    'y1': 39,\n",
       "    'y2': 235},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 135,\n",
       "    'x2': 189,\n",
       "    'y1': 27,\n",
       "    'y2': 229},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 65,\n",
       "    'x2': 134,\n",
       "    'y1': 26,\n",
       "    'y2': 230},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 16,\n",
       "    'x2': 105,\n",
       "    'y1': 42,\n",
       "    'y2': 237},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 411,\n",
       "    'x2': 465,\n",
       "    'y1': 9,\n",
       "    'y2': 72},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 299,\n",
       "    'x2': 360,\n",
       "    'y1': 23,\n",
       "    'y2': 237},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 259,\n",
       "    'x2': 315,\n",
       "    'y1': 38,\n",
       "    'y2': 237},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 40,\n",
       "    'y1': 48,\n",
       "    'y2': 126}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001228.jpg',\n",
       "  'height': 374,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 47,\n",
       "    'x2': 344,\n",
       "    'y1': 195,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 175,\n",
       "    'x2': 257,\n",
       "    'y1': 162,\n",
       "    'y2': 243},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 296,\n",
       "    'x2': 383,\n",
       "    'y1': 158,\n",
       "    'y2': 248},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 427,\n",
       "    'x2': 456,\n",
       "    'y1': 28,\n",
       "    'y2': 65},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': True,\n",
       "    'x1': 456,\n",
       "    'x2': 476,\n",
       "    'y1': 39,\n",
       "    'y2': 64}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005266.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 46,\n",
       "    'x2': 375,\n",
       "    'y1': 18,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001098.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 91,\n",
       "    'x2': 482,\n",
       "    'y1': 33,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005178.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 275,\n",
       "    'x2': 308,\n",
       "    'y1': 216,\n",
       "    'y2': 225},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 320,\n",
       "    'x2': 339,\n",
       "    'y1': 226,\n",
       "    'y2': 318},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 221,\n",
       "    'x2': 236,\n",
       "    'y1': 217,\n",
       "    'y2': 235},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 242,\n",
       "    'x2': 288,\n",
       "    'y1': 232,\n",
       "    'y2': 332},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 220,\n",
       "    'x2': 330,\n",
       "    'y1': 223,\n",
       "    'y2': 325},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 150,\n",
       "    'x2': 210,\n",
       "    'y1': 248,\n",
       "    'y2': 282},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 4,\n",
       "    'x2': 43,\n",
       "    'y1': 261,\n",
       "    'y2': 304},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 231,\n",
       "    'x2': 270,\n",
       "    'y1': 282,\n",
       "    'y2': 376},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 158,\n",
       "    'x2': 235,\n",
       "    'y1': 307,\n",
       "    'y2': 376},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 263,\n",
       "    'y1': 268,\n",
       "    'y2': 376},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': True,\n",
       "    'x1': 89,\n",
       "    'x2': 135,\n",
       "    'y1': 97,\n",
       "    'y2': 137}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007722.jpg',\n",
       "  'height': 376,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 334,\n",
       "    'x2': 498,\n",
       "    'y1': 45,\n",
       "    'y2': 284},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 378,\n",
       "    'y1': 52,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001173.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 316,\n",
       "    'x2': 500,\n",
       "    'y1': 14,\n",
       "    'y2': 211}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007635.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 340,\n",
       "    'x2': 470,\n",
       "    'y1': 91,\n",
       "    'y2': 266},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 217,\n",
       "    'x2': 266,\n",
       "    'y1': 93,\n",
       "    'y2': 198}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008089.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bus',\n",
       "    'difficult': False,\n",
       "    'x1': 41,\n",
       "    'x2': 443,\n",
       "    'y1': 122,\n",
       "    'y2': 231}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006913.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 464,\n",
       "    'y1': 8,\n",
       "    'y2': 321}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005309.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'boat',\n",
       "    'difficult': False,\n",
       "    'x1': 78,\n",
       "    'x2': 373,\n",
       "    'y1': 6,\n",
       "    'y2': 354}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004914.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'aeroplane',\n",
       "    'difficult': False,\n",
       "    'x1': 79,\n",
       "    'x2': 500,\n",
       "    'y1': 47,\n",
       "    'y2': 333},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 149,\n",
       "    'x2': 184,\n",
       "    'y1': 228,\n",
       "    'y2': 260},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 178,\n",
       "    'x2': 201,\n",
       "    'y1': 240,\n",
       "    'y2': 259},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 111,\n",
       "    'x2': 136,\n",
       "    'y1': 233,\n",
       "    'y2': 259},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 15,\n",
       "    'x2': 68,\n",
       "    'y1': 238,\n",
       "    'y2': 257},\n",
       "   {'class': 'car',\n",
       "    'difficult': True,\n",
       "    'x1': 46,\n",
       "    'x2': 67,\n",
       "    'y1': 245,\n",
       "    'y2': 263},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 82,\n",
       "    'x2': 88,\n",
       "    'y1': 232,\n",
       "    'y2': 252},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 69,\n",
       "    'x2': 82,\n",
       "    'y1': 233,\n",
       "    'y2': 267},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 65,\n",
       "    'x2': 74,\n",
       "    'y1': 231,\n",
       "    'y2': 257},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 23,\n",
       "    'y1': 246,\n",
       "    'y2': 270}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007676.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 142,\n",
       "    'x2': 213,\n",
       "    'y1': 206,\n",
       "    'y2': 261},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 271,\n",
       "    'x2': 313,\n",
       "    'y1': 192,\n",
       "    'y2': 273},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 347,\n",
       "    'x2': 374,\n",
       "    'y1': 266,\n",
       "    'y2': 359},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 3,\n",
       "    'x2': 97,\n",
       "    'y1': 431,\n",
       "    'y2': 500},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 32,\n",
       "    'x2': 64,\n",
       "    'y1': 186,\n",
       "    'y2': 249},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 37,\n",
       "    'y1': 153,\n",
       "    'y2': 249}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000397.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 12,\n",
       "    'x2': 72,\n",
       "    'y1': 138,\n",
       "    'y2': 216},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 98,\n",
       "    'x2': 178,\n",
       "    'y1': 127,\n",
       "    'y2': 271}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008167.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 23,\n",
       "    'x2': 480,\n",
       "    'y1': 82,\n",
       "    'y2': 305}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009341.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 247,\n",
       "    'y1': 97,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 206,\n",
       "    'x2': 476,\n",
       "    'y1': 51,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002588.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 108,\n",
       "    'x2': 306,\n",
       "    'y1': 156,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 210,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 317}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004297.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 76,\n",
       "    'x2': 103,\n",
       "    'y1': 380,\n",
       "    'y2': 480},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 107,\n",
       "    'x2': 131,\n",
       "    'y1': 384,\n",
       "    'y2': 479},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 129,\n",
       "    'x2': 159,\n",
       "    'y1': 377,\n",
       "    'y2': 478},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 160,\n",
       "    'x2': 183,\n",
       "    'y1': 384,\n",
       "    'y2': 482},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 182,\n",
       "    'x2': 208,\n",
       "    'y1': 389,\n",
       "    'y2': 480},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 208,\n",
       "    'x2': 234,\n",
       "    'y1': 392,\n",
       "    'y2': 480},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 238,\n",
       "    'x2': 264,\n",
       "    'y1': 396,\n",
       "    'y2': 480},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 263,\n",
       "    'x2': 292,\n",
       "    'y1': 405,\n",
       "    'y2': 490},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 289,\n",
       "    'x2': 321,\n",
       "    'y1': 397,\n",
       "    'y2': 490},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 69,\n",
       "    'x2': 110,\n",
       "    'y1': 336,\n",
       "    'y2': 413},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 103,\n",
       "    'x2': 149,\n",
       "    'y1': 334,\n",
       "    'y2': 417}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004162.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 135,\n",
       "    'x2': 170,\n",
       "    'y1': 159,\n",
       "    'y2': 250},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 90,\n",
       "    'x2': 143,\n",
       "    'y1': 160,\n",
       "    'y2': 250},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 180,\n",
       "    'x2': 229,\n",
       "    'y1': 158,\n",
       "    'y2': 189},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 226,\n",
       "    'x2': 298,\n",
       "    'y1': 131,\n",
       "    'y2': 172},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 332,\n",
       "    'x2': 493,\n",
       "    'y1': 103,\n",
       "    'y2': 161}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009931.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 423,\n",
       "    'y1': 84,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008289.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 113,\n",
       "    'x2': 270,\n",
       "    'y1': 4,\n",
       "    'y2': 244},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 153,\n",
       "    'y1': 30,\n",
       "    'y2': 312},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 235,\n",
       "    'x2': 270,\n",
       "    'y1': 59,\n",
       "    'y2': 113},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 133,\n",
       "    'x2': 147,\n",
       "    'y1': 98,\n",
       "    'y2': 111},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 111,\n",
       "    'x2': 126,\n",
       "    'y1': 100,\n",
       "    'y2': 117},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 93,\n",
       "    'x2': 111,\n",
       "    'y1': 101,\n",
       "    'y2': 119},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 6,\n",
       "    'x2': 270,\n",
       "    'y1': 225,\n",
       "    'y2': 356}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005612.jpg',\n",
       "  'height': 360,\n",
       "  'imageset': 'test',\n",
       "  'width': 270},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 102,\n",
       "    'x2': 170,\n",
       "    'y1': 241,\n",
       "    'y2': 348},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 5,\n",
       "    'x2': 330,\n",
       "    'y1': 319,\n",
       "    'y2': 500}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002552.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 375},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 73,\n",
       "    'x2': 355,\n",
       "    'y1': 141,\n",
       "    'y2': 298},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 335,\n",
       "    'x2': 500,\n",
       "    'y1': 231,\n",
       "    'y2': 375},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 118,\n",
       "    'x2': 308,\n",
       "    'y1': 261,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003755.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 128,\n",
       "    'x2': 182,\n",
       "    'y1': 312,\n",
       "    'y2': 427},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 33,\n",
       "    'x2': 210,\n",
       "    'y1': 27,\n",
       "    'y2': 411},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 256,\n",
       "    'x2': 317,\n",
       "    'y1': 55,\n",
       "    'y2': 228},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 47,\n",
       "    'y1': 40,\n",
       "    'y2': 171},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 22,\n",
       "    'x2': 64,\n",
       "    'y1': 66,\n",
       "    'y2': 197},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 234,\n",
       "    'x2': 270,\n",
       "    'y1': 64,\n",
       "    'y2': 112}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002964.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 333},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 214,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 256},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 345,\n",
       "    'x2': 407,\n",
       "    'y1': 277,\n",
       "    'y2': 329}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003558.jpg',\n",
       "  'height': 374,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 192,\n",
       "    'x2': 305,\n",
       "    'y1': 35,\n",
       "    'y2': 188},\n",
       "   {'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 60,\n",
       "    'x2': 407,\n",
       "    'y1': 101,\n",
       "    'y2': 282}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007766.jpg',\n",
       "  'height': 373,\n",
       "  'imageset': 'test',\n",
       "  'width': 480},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 453,\n",
       "    'x2': 500,\n",
       "    'y1': 184,\n",
       "    'y2': 314}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002581.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 175,\n",
       "    'x2': 500,\n",
       "    'y1': 87,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004619.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 111,\n",
       "    'x2': 137,\n",
       "    'y1': 193,\n",
       "    'y2': 243},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 142,\n",
       "    'x2': 166,\n",
       "    'y1': 191,\n",
       "    'y2': 240},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 170,\n",
       "    'x2': 187,\n",
       "    'y1': 190,\n",
       "    'y2': 244},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 187,\n",
       "    'x2': 214,\n",
       "    'y1': 191,\n",
       "    'y2': 237},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 86,\n",
       "    'x2': 114,\n",
       "    'y1': 187,\n",
       "    'y2': 232},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 115,\n",
       "    'x2': 135,\n",
       "    'y1': 178,\n",
       "    'y2': 196},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 99,\n",
       "    'x2': 111,\n",
       "    'y1': 183,\n",
       "    'y2': 199},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 140,\n",
       "    'x2': 156,\n",
       "    'y1': 182,\n",
       "    'y2': 198},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 163,\n",
       "    'x2': 178,\n",
       "    'y1': 179,\n",
       "    'y2': 203},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 195,\n",
       "    'x2': 207,\n",
       "    'y1': 185,\n",
       "    'y2': 201},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 243,\n",
       "    'x2': 259,\n",
       "    'y1': 179,\n",
       "    'y2': 218},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 259,\n",
       "    'x2': 268,\n",
       "    'y1': 184,\n",
       "    'y2': 224},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 270,\n",
       "    'x2': 281,\n",
       "    'y1': 187,\n",
       "    'y2': 224}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/005302.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 10,\n",
       "    'x2': 112,\n",
       "    'y1': 105,\n",
       "    'y2': 357},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 228,\n",
       "    'x2': 341,\n",
       "    'y1': 112,\n",
       "    'y2': 357},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 314,\n",
       "    'x2': 483,\n",
       "    'y1': 24,\n",
       "    'y2': 357}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004238.jpg',\n",
       "  'height': 357,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 137,\n",
       "    'x2': 271,\n",
       "    'y1': 46,\n",
       "    'y2': 496},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 176,\n",
       "    'x2': 321,\n",
       "    'y1': 252,\n",
       "    'y2': 473}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007268.jpg',\n",
       "  'height': 500,\n",
       "  'imageset': 'test',\n",
       "  'width': 368},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 96,\n",
       "    'x2': 379,\n",
       "    'y1': 163,\n",
       "    'y2': 331},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 181,\n",
       "    'x2': 299,\n",
       "    'y1': 178,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009201.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 172,\n",
       "    'x2': 210,\n",
       "    'y1': 223,\n",
       "    'y2': 266},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 207,\n",
       "    'x2': 236,\n",
       "    'y1': 224,\n",
       "    'y2': 265},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 281,\n",
       "    'x2': 313,\n",
       "    'y1': 223,\n",
       "    'y2': 261},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 248,\n",
       "    'x2': 283,\n",
       "    'y1': 223,\n",
       "    'y2': 262},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 121,\n",
       "    'x2': 175,\n",
       "    'y1': 182,\n",
       "    'y2': 268},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 320,\n",
       "    'x2': 339,\n",
       "    'y1': 224,\n",
       "    'y2': 259},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 221,\n",
       "    'x2': 288,\n",
       "    'y1': 197,\n",
       "    'y2': 259},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 43,\n",
       "    'x2': 85,\n",
       "    'y1': 188,\n",
       "    'y2': 298}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/008039.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 223,\n",
       "    'x2': 407,\n",
       "    'y1': 148,\n",
       "    'y2': 231},\n",
       "   {'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 58,\n",
       "    'x2': 112,\n",
       "    'y1': 147,\n",
       "    'y2': 284}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001075.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 217,\n",
       "    'x2': 422,\n",
       "    'y1': 123,\n",
       "    'y2': 375}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003938.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': True,\n",
       "    'x1': 43,\n",
       "    'x2': 363,\n",
       "    'y1': 298,\n",
       "    'y2': 375},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 96,\n",
       "    'x2': 345,\n",
       "    'y1': 188,\n",
       "    'y2': 316},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 185,\n",
       "    'x2': 298,\n",
       "    'y1': 114,\n",
       "    'y2': 189},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 257,\n",
       "    'x2': 377,\n",
       "    'y1': 100,\n",
       "    'y2': 236},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 313,\n",
       "    'x2': 415,\n",
       "    'y1': 125,\n",
       "    'y2': 299},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 244,\n",
       "    'x2': 500,\n",
       "    'y1': 117,\n",
       "    'y2': 375},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 77,\n",
       "    'x2': 172,\n",
       "    'y1': 106,\n",
       "    'y2': 239},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 48,\n",
       "    'x2': 90,\n",
       "    'y1': 78,\n",
       "    'y2': 114},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 115,\n",
       "    'y1': 102,\n",
       "    'y2': 331},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 334,\n",
       "    'x2': 360,\n",
       "    'y1': 11,\n",
       "    'y2': 77},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 184,\n",
       "    'x2': 216,\n",
       "    'y1': 320,\n",
       "    'y2': 375},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 153,\n",
       "    'x2': 189,\n",
       "    'y1': 319,\n",
       "    'y2': 375},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 213,\n",
       "    'x2': 236,\n",
       "    'y1': 192,\n",
       "    'y2': 256},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 196,\n",
       "    'x2': 220,\n",
       "    'y1': 195,\n",
       "    'y2': 255}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004469.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 22,\n",
       "    'x2': 125,\n",
       "    'y1': 187,\n",
       "    'y2': 351},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': True,\n",
       "    'x1': 401,\n",
       "    'x2': 500,\n",
       "    'y1': 264,\n",
       "    'y2': 375},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 222,\n",
       "    'x2': 268,\n",
       "    'y1': 104,\n",
       "    'y2': 135}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/000953.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 400,\n",
       "    'x2': 453,\n",
       "    'y1': 171,\n",
       "    'y2': 253},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 107,\n",
       "    'x2': 276,\n",
       "    'y1': 3,\n",
       "    'y2': 331},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 334,\n",
       "    'x2': 500,\n",
       "    'y1': 212,\n",
       "    'y2': 332}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006036.jpg',\n",
       "  'height': 332,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'horse',\n",
       "    'difficult': False,\n",
       "    'x1': 16,\n",
       "    'x2': 181,\n",
       "    'y1': 11,\n",
       "    'y2': 254}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001317.jpg',\n",
       "  'height': 264,\n",
       "  'imageset': 'test',\n",
       "  'width': 194},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 174,\n",
       "    'x2': 488,\n",
       "    'y1': 121,\n",
       "    'y2': 329},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 177,\n",
       "    'y1': 127,\n",
       "    'y2': 271},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 270,\n",
       "    'x2': 291,\n",
       "    'y1': 101,\n",
       "    'y2': 128},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 245,\n",
       "    'x2': 274,\n",
       "    'y1': 90,\n",
       "    'y2': 112},\n",
       "   {'class': 'chair',\n",
       "    'difficult': True,\n",
       "    'x1': 167,\n",
       "    'x2': 195,\n",
       "    'y1': 91,\n",
       "    'y2': 117},\n",
       "   {'class': 'chair',\n",
       "    'difficult': False,\n",
       "    'x1': 178,\n",
       "    'x2': 220,\n",
       "    'y1': 102,\n",
       "    'y2': 183},\n",
       "   {'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 160,\n",
       "    'x2': 277,\n",
       "    'y1': 102,\n",
       "    'y2': 160},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': False,\n",
       "    'x1': 143,\n",
       "    'x2': 174,\n",
       "    'y1': 4,\n",
       "    'y2': 103}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/002510.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': True,\n",
       "    'x1': 208,\n",
       "    'x2': 408,\n",
       "    'y1': 173,\n",
       "    'y2': 291},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 126,\n",
       "    'x2': 229,\n",
       "    'y1': 125,\n",
       "    'y2': 332},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 135,\n",
       "    'x2': 366,\n",
       "    'y1': 112,\n",
       "    'y2': 331},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 362,\n",
       "    'x2': 479,\n",
       "    'y1': 200,\n",
       "    'y2': 333}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001040.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 52,\n",
       "    'x2': 415,\n",
       "    'y1': 55,\n",
       "    'y2': 275},\n",
       "   {'class': 'dog',\n",
       "    'difficult': True,\n",
       "    'x1': 391,\n",
       "    'x2': 500,\n",
       "    'y1': 254,\n",
       "    'y2': 335},\n",
       "   {'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 500,\n",
       "    'y1': 2,\n",
       "    'y2': 335}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/003264.jpg',\n",
       "  'height': 335,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 106,\n",
       "    'y1': 174,\n",
       "    'y2': 308},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 85,\n",
       "    'x2': 213,\n",
       "    'y1': 164,\n",
       "    'y2': 291},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 174,\n",
       "    'x2': 263,\n",
       "    'y1': 163,\n",
       "    'y2': 261},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 235,\n",
       "    'x2': 334,\n",
       "    'y1': 156,\n",
       "    'y2': 244},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 305,\n",
       "    'x2': 402,\n",
       "    'y1': 136,\n",
       "    'y2': 230},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 372,\n",
       "    'x2': 426,\n",
       "    'y1': 161,\n",
       "    'y2': 215},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 456,\n",
       "    'x2': 500,\n",
       "    'y1': 132,\n",
       "    'y2': 181},\n",
       "   {'class': 'motorbike',\n",
       "    'difficult': False,\n",
       "    'x1': 423,\n",
       "    'x2': 465,\n",
       "    'y1': 132,\n",
       "    'y2': 196},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 47,\n",
       "    'x2': 91,\n",
       "    'y1': 117,\n",
       "    'y2': 244},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 454,\n",
       "    'x2': 472,\n",
       "    'y1': 114,\n",
       "    'y2': 146},\n",
       "   {'class': 'person',\n",
       "    'difficult': True,\n",
       "    'x1': 433,\n",
       "    'x2': 458,\n",
       "    'y1': 120,\n",
       "    'y2': 151},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 405,\n",
       "    'x2': 425,\n",
       "    'y1': 120,\n",
       "    'y2': 155}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/004243.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 500,\n",
       "    'y1': 128,\n",
       "    'y2': 374}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/007542.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'sofa',\n",
       "    'difficult': False,\n",
       "    'x1': 23,\n",
       "    'x2': 480,\n",
       "    'y1': 138,\n",
       "    'y2': 328},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 312,\n",
       "    'x2': 356,\n",
       "    'y1': 145,\n",
       "    'y2': 227},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 252,\n",
       "    'x2': 331,\n",
       "    'y1': 179,\n",
       "    'y2': 290}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006257.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'car',\n",
       "    'difficult': False,\n",
       "    'x1': 57,\n",
       "    'x2': 500,\n",
       "    'y1': 61,\n",
       "    'y2': 354},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 3,\n",
       "    'x2': 30,\n",
       "    'y1': 83,\n",
       "    'y2': 180}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/009536.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'diningtable',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 242,\n",
       "    'y1': 146,\n",
       "    'y2': 350},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 296,\n",
       "    'x2': 423,\n",
       "    'y1': 64,\n",
       "    'y2': 333},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 210,\n",
       "    'x2': 323,\n",
       "    'y1': 56,\n",
       "    'y2': 341},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 89,\n",
       "    'y1': 6,\n",
       "    'y2': 170},\n",
       "   {'class': 'pottedplant',\n",
       "    'difficult': True,\n",
       "    'x1': 141,\n",
       "    'x2': 174,\n",
       "    'y1': 117,\n",
       "    'y2': 151},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 8,\n",
       "    'x2': 22,\n",
       "    'y1': 115,\n",
       "    'y2': 185}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001035.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 288,\n",
       "    'x2': 330,\n",
       "    'y1': 224,\n",
       "    'y2': 328},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 233,\n",
       "    'x2': 270,\n",
       "    'y1': 216,\n",
       "    'y2': 314},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 186,\n",
       "    'x2': 224,\n",
       "    'y1': 207,\n",
       "    'y2': 297},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 146,\n",
       "    'x2': 183,\n",
       "    'y1': 200,\n",
       "    'y2': 285},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 111,\n",
       "    'x2': 144,\n",
       "    'y1': 195,\n",
       "    'y2': 273},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 69,\n",
       "    'x2': 108,\n",
       "    'y1': 161,\n",
       "    'y2': 266},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 34,\n",
       "    'x2': 72,\n",
       "    'y1': 156,\n",
       "    'y2': 257},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 11,\n",
       "    'x2': 40,\n",
       "    'y1': 155,\n",
       "    'y2': 250},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 1,\n",
       "    'x2': 19,\n",
       "    'y1': 151,\n",
       "    'y2': 241},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 371,\n",
       "    'x2': 415,\n",
       "    'y1': 95,\n",
       "    'y2': 217},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 326,\n",
       "    'x2': 367,\n",
       "    'y1': 94,\n",
       "    'y2': 213},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 289,\n",
       "    'x2': 327,\n",
       "    'y1': 94,\n",
       "    'y2': 203},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 252,\n",
       "    'x2': 290,\n",
       "    'y1': 92,\n",
       "    'y2': 202},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 225,\n",
       "    'x2': 257,\n",
       "    'y1': 95,\n",
       "    'y2': 188},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 190,\n",
       "    'x2': 225,\n",
       "    'y1': 93,\n",
       "    'y2': 191},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 167,\n",
       "    'x2': 195,\n",
       "    'y1': 96,\n",
       "    'y2': 185},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 141,\n",
       "    'x2': 169,\n",
       "    'y1': 94,\n",
       "    'y2': 186},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 107,\n",
       "    'x2': 142,\n",
       "    'y1': 98,\n",
       "    'y2': 179},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 290,\n",
       "    'x2': 332,\n",
       "    'y1': 171,\n",
       "    'y2': 231},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 210,\n",
       "    'x2': 247,\n",
       "    'y1': 161,\n",
       "    'y2': 282},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 154,\n",
       "    'x2': 197,\n",
       "    'y1': 158,\n",
       "    'y2': 232},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 110,\n",
       "    'x2': 149,\n",
       "    'y1': 153,\n",
       "    'y2': 224},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 86,\n",
       "    'x2': 114,\n",
       "    'y1': 100,\n",
       "    'y2': 178},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 63,\n",
       "    'x2': 94,\n",
       "    'y1': 98,\n",
       "    'y2': 176},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 46,\n",
       "    'x2': 69,\n",
       "    'y1': 99,\n",
       "    'y2': 151},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 27,\n",
       "    'x2': 51,\n",
       "    'y1': 96,\n",
       "    'y2': 149},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 12,\n",
       "    'x2': 33,\n",
       "    'y1': 96,\n",
       "    'y2': 146},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 1,\n",
       "    'x2': 16,\n",
       "    'y1': 99,\n",
       "    'y2': 170},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 384,\n",
       "    'x2': 429,\n",
       "    'y1': 1,\n",
       "    'y2': 128},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 338,\n",
       "    'x2': 382,\n",
       "    'y1': 1,\n",
       "    'y2': 128},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 295,\n",
       "    'x2': 344,\n",
       "    'y1': 1,\n",
       "    'y2': 132},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 252,\n",
       "    'x2': 288,\n",
       "    'y1': 1,\n",
       "    'y2': 128},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 213,\n",
       "    'x2': 249,\n",
       "    'y1': 1,\n",
       "    'y2': 125},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 177,\n",
       "    'x2': 213,\n",
       "    'y1': 3,\n",
       "    'y2': 123},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 149,\n",
       "    'x2': 179,\n",
       "    'y1': 6,\n",
       "    'y2': 124},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 127,\n",
       "    'x2': 156,\n",
       "    'y1': 9,\n",
       "    'y2': 125},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 106,\n",
       "    'x2': 132,\n",
       "    'y1': 11,\n",
       "    'y2': 121},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 81,\n",
       "    'x2': 111,\n",
       "    'y1': 11,\n",
       "    'y2': 119},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 61,\n",
       "    'x2': 88,\n",
       "    'y1': 11,\n",
       "    'y2': 120},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': True,\n",
       "    'x1': 36,\n",
       "    'x2': 65,\n",
       "    'y1': 18,\n",
       "    'y2': 100},\n",
       "   {'class': 'bottle',\n",
       "    'difficult': False,\n",
       "    'x1': 13,\n",
       "    'x2': 40,\n",
       "    'y1': 19,\n",
       "    'y2': 98}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/006500.jpg',\n",
       "  'height': 333,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'dog',\n",
       "    'difficult': False,\n",
       "    'x1': 2,\n",
       "    'x2': 500,\n",
       "    'y1': 1,\n",
       "    'y2': 325}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001000.jpg',\n",
       "  'height': 325,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " {'bboxes': [{'class': 'tvmonitor',\n",
       "    'difficult': False,\n",
       "    'x1': 382,\n",
       "    'x2': 500,\n",
       "    'y1': 18,\n",
       "    'y2': 186},\n",
       "   {'class': 'cat',\n",
       "    'difficult': False,\n",
       "    'x1': 46,\n",
       "    'x2': 486,\n",
       "    'y1': 64,\n",
       "    'y2': 329},\n",
       "   {'class': 'person',\n",
       "    'difficult': False,\n",
       "    'x1': 433,\n",
       "    'x2': 500,\n",
       "    'y1': 45,\n",
       "    'y2': 179}],\n",
       "  'filepath': './input/dataset/VOCdevkit2007/VOC2007/JPEGImages/001392.jpg',\n",
       "  'height': 375,\n",
       "  'imageset': 'test',\n",
       "  'width': 500},\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_train = data_generators.get_anchor_gt(train_imgs, classes_count, C, nn.get_img_output_length, K.image_dim_ordering(), mode='train')\n",
    "data_gen_val = data_generators.get_anchor_gt(val_imgs, classes_count, C, nn.get_img_output_length,K.image_dim_ordering(), mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_img = (None, None, 3)\n",
    "\n",
    "img_input = Input(shape=input_shape_img)\n",
    "roi_input = Input(shape=(None, 4))\n",
    "\n",
    "# define the base network (resnet here, can be VGG, Inception, etc)\n",
    "shared_layers = nn.nn_base(img_input, trainable=True)\n",
    "\n",
    "# define the RPN, built on the base layers\n",
    "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n",
    "rpn = nn.rpn(shared_layers, num_anchors)\n",
    "\n",
    "classifier = nn.classifier(shared_layers, roi_input, C.num_rois, nb_classes=len(classes_count), trainable=True)\n",
    "\n",
    "model_rpn = Model(img_input, rpn[:2])\n",
    "model_classifier = Model([img_input, roi_input], classifier)\n",
    "\n",
    "# this is a model that holds both the RPN and the classifier, used to load/save weights for the models\n",
    "model_all = Model([img_input, roi_input], rpn[:2] + classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from ./input/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\tprint('loading weights from {}'.format(C.base_net_weights))\n",
    "\tmodel_rpn.load_weights(C.base_net_weights,by_name=True)\n",
    "\tmodel_classifier.load_weights(C.base_net_weights, by_name=True)\n",
    "except:\n",
    "\tprint('Could not load pretrained model weights. Weights can be found in the keras application folder \\\n",
    "\t\thttps://github.com/fchollet/keras/tree/master/keras/applications')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-5)\n",
    "optimizer_classifier = Adam(lr=1e-5)\n",
    "model_rpn.compile(optimizer=optimizer, loss=[losses.rpn_loss_cls(num_anchors), losses.rpn_loss_regr(num_anchors)])\n",
    "model_classifier.compile(optimizer=optimizer_classifier, loss=[losses.class_loss_cls, losses.class_loss_regr(len(classes_count)-1)], metrics={'dense_class_{}'.format(len(classes_count)): 'accuracy'})\n",
    "model_all.compile(optimizer='sgd', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_length = 1000\n",
    "num_epochs = 2000\n",
    "iter_num = 0\n",
    "\n",
    "losses = np.zeros((epoch_length, 5))\n",
    "rpn_accuracy_rpn_monitor = []\n",
    "rpn_accuracy_for_epoch = []\n",
    "#start_time = time.time()\n",
    "\n",
    "best_loss = np.Inf\n",
    "\n",
    "class_mapping_inv = {v: k for k, v in class_mapping.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, img_data = next(data_gen_train)\n",
    "loss_rpn = model_rpn.train_on_batch(X, Y)\n",
    "P_rpn = model_rpn.predict_on_batch(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = roi_helpers.rpn_to_roi(P_rpn[0], P_rpn[1], C, K.image_dim_ordering(), use_regr=True, overlap_thresh=0.7, max_boxes=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, Y1, Y2, IouS = roi_helpers.calc_iou(R, img_data, C, class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_samples = np.where(Y1[0, :, -1] == 1)\n",
    "pos_samples = np.where(Y1[0, :, -1] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 22,  24,  43,  89,  92, 117, 121, 151, 178]),)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[34, 10,  8,  8],\n",
       "        [ 6, 11,  8,  8],\n",
       "        [15, 20,  8,  8],\n",
       "        [22,  7, 11, 23],\n",
       "        [13, 13, 11, 23],\n",
       "        [ 8, 11,  8,  8],\n",
       "        [40, 10,  8,  8],\n",
       "        [13, 23,  8,  8],\n",
       "        [25, 11,  6, 11],\n",
       "        [37, 10,  8,  8],\n",
       "        [26,  6, 23, 11],\n",
       "        [34, 12,  8,  8],\n",
       "        [15, 23,  8,  8],\n",
       "        [33, 11,  8,  8],\n",
       "        [35, 11,  8,  8],\n",
       "        [36, 12,  8,  8],\n",
       "        [13, 21,  8,  8],\n",
       "        [11, 16, 11, 20],\n",
       "        [ 7, 12,  8,  8],\n",
       "        [14, 22,  8,  8],\n",
       "        [35, 13,  8,  8],\n",
       "        [17, 17,  8,  8],\n",
       "        [19, 15, 23, 11],\n",
       "        [30, 10, 19, 11],\n",
       "        [24, 14, 23, 11],\n",
       "        [37, 15,  8,  8],\n",
       "        [18,  4, 31, 32],\n",
       "        [28, 12, 21, 11],\n",
       "        [13,  2, 32, 32],\n",
       "        [32, 11, 11,  6],\n",
       "        [ 0,  0, 19, 31],\n",
       "        [30,  7, 19, 11],\n",
       "        [14, 24,  8,  8],\n",
       "        [24, 16, 23, 11],\n",
       "        [20,  7, 11, 23],\n",
       "        [16, 22,  8,  8],\n",
       "        [30,  2, 11, 23],\n",
       "        [ 0,  9, 19, 11],\n",
       "        [31, 17,  8,  8],\n",
       "        [16, 18,  8,  8],\n",
       "        [ 8, 20, 23, 11],\n",
       "        [31, 20,  8,  8],\n",
       "        [27, 16,  8,  8],\n",
       "        [ 1, 14, 32, 22],\n",
       "        [12,  2, 11, 23],\n",
       "        [ 0, 14,  6,  8],\n",
       "        [ 8,  2, 11, 23],\n",
       "        [28, 14,  8,  8],\n",
       "        [32, 19,  8,  8],\n",
       "        [26, 12,  6, 11],\n",
       "        [23, 11,  6, 11],\n",
       "        [28, 11,  8,  8],\n",
       "        [10,  2, 11, 23],\n",
       "        [ 0,  0, 28, 31],\n",
       "        [30, 18,  8,  8],\n",
       "        [16, 16,  8,  8],\n",
       "        [25,  8, 11, 23],\n",
       "        [24, 12,  6, 11],\n",
       "        [36, 14,  8,  8],\n",
       "        [16, 14,  8,  8],\n",
       "        [ 7, 18, 23, 11],\n",
       "        [36,  9,  8,  8],\n",
       "        [37, 13,  8,  8],\n",
       "        [16, 21, 11, 15],\n",
       "        [32, 10,  8,  8],\n",
       "        [32, 21,  8,  8],\n",
       "        [33, 20,  8,  8],\n",
       "        [34, 10, 11, 23],\n",
       "        [25, 15,  8,  8],\n",
       "        [41, 11,  8,  8],\n",
       "        [15, 17,  8,  8],\n",
       "        [35,  6, 14, 11],\n",
       "        [34,  8, 15, 11],\n",
       "        [29, 10,  8,  8],\n",
       "        [ 0, 11, 13, 25],\n",
       "        [24, 18, 23, 11],\n",
       "        [33, 18,  8,  8],\n",
       "        [25,  0, 11, 20],\n",
       "        [12, 22,  8,  8],\n",
       "        [30, 14, 19, 11],\n",
       "        [15, 19,  6, 11],\n",
       "        [34,  0, 11, 23],\n",
       "        [ 9, 18, 16, 16],\n",
       "        [ 0, 20, 17, 16],\n",
       "        [34, 17,  8,  8],\n",
       "        [37, 14,  6, 11],\n",
       "        [12, 25,  8,  8],\n",
       "        [16, 18,  6, 11],\n",
       "        [29,  0, 20, 18],\n",
       "        [24, 11, 23, 11],\n",
       "        [31, 15,  8,  8],\n",
       "        [36,  8, 11, 23],\n",
       "        [29, 11, 11, 23],\n",
       "        [15, 21,  6, 11],\n",
       "        [38, 12,  6, 11],\n",
       "        [10, 11,  8,  8],\n",
       "        [42, 10,  7,  8],\n",
       "        [ 9, 24,  8,  8],\n",
       "        [29, 13,  8,  8],\n",
       "        [33, 13,  8,  8],\n",
       "        [28, 15, 11, 21],\n",
       "        [16,  4, 11, 23],\n",
       "        [ 5, 12,  8,  8],\n",
       "        [ 2,  3, 11, 23],\n",
       "        [23, 11, 11, 23],\n",
       "        [34,  5, 11, 23],\n",
       "        [ 3,  5, 23, 31],\n",
       "        [ 8,  9, 23, 11],\n",
       "        [33, 15,  8,  8],\n",
       "        [24, 19,  8,  8],\n",
       "        [24, 12,  8,  8],\n",
       "        [14, 18,  8,  8],\n",
       "        [13,  6, 11, 23],\n",
       "        [17, 23,  8,  8],\n",
       "        [41,  9,  8,  8],\n",
       "        [ 9, 16, 23, 11],\n",
       "        [27,  0, 22, 36],\n",
       "        [ 0, 17, 24, 19],\n",
       "        [31, 11,  8,  8],\n",
       "        [31, 12, 16, 16],\n",
       "        [12, 20, 11, 16],\n",
       "        [19, 11, 23, 11],\n",
       "        [32,  4, 11, 23],\n",
       "        [21,  4, 23, 11],\n",
       "        [ 6, 17, 11, 19],\n",
       "        [12,  9, 32, 27],\n",
       "        [27, 14,  6, 11],\n",
       "        [32,  7,  8,  8],\n",
       "        [23, 20,  8,  8],\n",
       "        [10, 20, 11, 16],\n",
       "        [ 7, 11, 23, 11],\n",
       "        [29, 15,  8,  8],\n",
       "        [ 0,  4, 11, 23],\n",
       "        [12, 20,  8,  8],\n",
       "        [30, 14,  8,  8],\n",
       "        [18, 17, 23, 11],\n",
       "        [31,  9,  8,  8],\n",
       "        [ 0,  9,  8, 23],\n",
       "        [17,  0, 23, 36],\n",
       "        [16,  0, 32, 23],\n",
       "        [32, 16,  8,  8],\n",
       "        [11, 24,  8,  8],\n",
       "        [35,  7,  8,  8],\n",
       "        [36, 16,  8,  8],\n",
       "        [36, 12,  6, 11],\n",
       "        [ 0, 24, 27, 12],\n",
       "        [ 6,  0, 32, 30],\n",
       "        [ 0, 27, 12,  9],\n",
       "        [ 5, 28, 23,  8],\n",
       "        [ 0, 13,  8,  8],\n",
       "        [17, 13,  8,  8],\n",
       "        [18, 13, 23, 11],\n",
       "        [24, 10,  6, 11],\n",
       "        [ 9, 14, 11, 22],\n",
       "        [39, 11,  6, 11],\n",
       "        [ 3, 15, 11, 21],\n",
       "        [28, 16, 16, 16],\n",
       "        [ 0, 23,  7, 13],\n",
       "        [ 8, 23,  8,  8],\n",
       "        [ 5,  8, 23, 11],\n",
       "        [ 0,  6, 15, 11],\n",
       "        [ 0,  4,  7, 23],\n",
       "        [13, 26,  8,  8],\n",
       "        [29, 17,  8,  8],\n",
       "        [21,  0, 28, 30],\n",
       "        [12, 13,  8,  8],\n",
       "        [12, 20, 16, 16],\n",
       "        [30, 21,  8,  8],\n",
       "        [30, 15,  6, 11],\n",
       "        [ 9, 14, 23, 11],\n",
       "        [ 8, 26, 23, 10],\n",
       "        [24, 16, 16, 16],\n",
       "        [22, 12,  8,  8],\n",
       "        [ 2, 13, 11,  6],\n",
       "        [17, 19,  8,  8],\n",
       "        [29, 19,  8,  8],\n",
       "        [31, 14, 11, 22],\n",
       "        [26, 10,  6, 11],\n",
       "        [27,  8, 11, 23],\n",
       "        [17, 19, 23, 11],\n",
       "        [31, 10, 11,  6],\n",
       "        [37, 20,  8,  8],\n",
       "        [12, 10, 11, 23],\n",
       "        [11, 19,  8,  8],\n",
       "        [40,  7,  8,  8],\n",
       "        [16, 12,  8,  8],\n",
       "        [ 0, 15,  7,  8],\n",
       "        [ 9, 22,  8,  8],\n",
       "        [14, 20, 11, 16],\n",
       "        [32, 12,  8,  8],\n",
       "        [10,  0, 23, 36],\n",
       "        [32, 14,  8,  8],\n",
       "        [ 0,  7,  8, 16],\n",
       "        [ 0, 12, 16, 11],\n",
       "        [39, 11,  8,  8],\n",
       "        [25, 21, 11, 15],\n",
       "        [14,  9, 11, 23],\n",
       "        [27, 11,  6, 11],\n",
       "        [ 9, 12,  8,  8],\n",
       "        [38,  9,  8,  8],\n",
       "        [ 5,  5, 32, 31],\n",
       "        [13, 19,  8,  8],\n",
       "        [14, 16,  8,  8],\n",
       "        [10, 23,  8,  8],\n",
       "        [ 4, 19, 11, 17],\n",
       "        [22, 16,  8,  8],\n",
       "        [ 0,  7,  6, 23],\n",
       "        [28,  1, 11, 23],\n",
       "        [32, 11, 11, 23],\n",
       "        [ 4, 13,  8,  8],\n",
       "        [23, 11,  8,  8],\n",
       "        [25, 20, 23, 11],\n",
       "        [ 2, 10, 23, 11],\n",
       "        [33, 22,  8,  8],\n",
       "        [15, 15, 11, 21],\n",
       "        [ 6, 13,  8,  8],\n",
       "        [30, 12,  8,  8],\n",
       "        [10, 10,  6, 11],\n",
       "        [16, 24,  8,  8],\n",
       "        [33, 14, 16, 16],\n",
       "        [14,  1, 11, 23],\n",
       "        [ 7,  7, 11, 23],\n",
       "        [35, 20,  8,  8]]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch 1/2000\n",
      "iter_num    = 0\n",
      "loss_rpn1   = 7.063937\n",
      "loss_rpn2   = 0.190339\n",
      "loss_class1 = 3.044523\n",
      "loss_class2 = 0.552696\n",
      "loss_class3 = 0.000000\n",
      "iter_num    = 1\n",
      "loss_rpn1   = 5.691202\n",
      "loss_rpn2   = 0.463145\n",
      "loss_class1 = 2.955662\n",
      "loss_class2 = 0.465231\n",
      "loss_class3 = 0.750000\n",
      "iter_num    = 2\n",
      "loss_rpn1   = 5.827634\n",
      "loss_rpn2   = 0.210163\n",
      "loss_class1 = 2.796956\n",
      "loss_class2 = 0.543838\n",
      "loss_class3 = 0.875000\n",
      "iter_num    = 3\n",
      "loss_rpn1   = 4.655982\n",
      "loss_rpn2   = 0.220306\n",
      "loss_class1 = 2.792784\n",
      "loss_class2 = 0.773137\n",
      "loss_class3 = 0.500000\n",
      "iter_num    = 4\n",
      "loss_rpn1   = 6.717597\n",
      "loss_rpn2   = 0.067981\n",
      "loss_class1 = 2.452368\n",
      "loss_class2 = 0.439869\n",
      "loss_class3 = 0.750000\n",
      "iter_num    = 5\n",
      "loss_rpn1   = 6.313916\n",
      "loss_rpn2   = 0.100959\n",
      "loss_class1 = 2.055731\n",
      "loss_class2 = 0.598408\n",
      "loss_class3 = 0.750000\n",
      "iter_num    = 6\n",
      "loss_rpn1   = 8.675983\n",
      "loss_rpn2   = 0.436199\n",
      "loss_class1 = 1.947717\n",
      "loss_class2 = 0.421698\n",
      "loss_class3 = 0.781250\n",
      "iter_num    = 7\n",
      "loss_rpn1   = 12.322211\n",
      "loss_rpn2   = 0.251368\n",
      "loss_class1 = 1.860116\n",
      "loss_class2 = 0.655158\n",
      "loss_class3 = 0.531250\n",
      "iter_num    = 8\n",
      "loss_rpn1   = 2.398729\n",
      "loss_rpn2   = 0.706345\n",
      "loss_class1 = 0.025583\n",
      "loss_class2 = 0.000000\n",
      "loss_class3 = 1.000000\n",
      "iter_num    = 9\n",
      "loss_rpn1   = 5.820332\n",
      "loss_rpn2   = 0.438964\n",
      "loss_class1 = 2.019300\n",
      "loss_class2 = 0.596330\n",
      "loss_class3 = 0.500000\n",
      "iter_num    = 10\n",
      "loss_rpn1   = 8.491593\n",
      "loss_rpn2   = 0.356474\n",
      "loss_class1 = 3.306805\n",
      "loss_class2 = 0.547230\n",
      "loss_class3 = 0.500000\n",
      "iter_num    = 11\n",
      "loss_rpn1   = 4.126702\n",
      "loss_rpn2   = 1.309353\n",
      "loss_class1 = 0.595224\n",
      "loss_class2 = 0.716974\n",
      "loss_class3 = 0.968750\n",
      "iter_num    = 12\n",
      "loss_rpn1   = 9.351831\n",
      "loss_rpn2   = 0.191734\n",
      "loss_class1 = 1.908621\n",
      "loss_class2 = 0.322232\n",
      "loss_class3 = 0.750000\n",
      "iter_num    = 13\n",
      "loss_rpn1   = 3.591336\n",
      "loss_rpn2   = 0.068006\n",
      "loss_class1 = 2.407422\n",
      "loss_class2 = 0.325865\n",
      "loss_class3 = 0.625000\n",
      "iter_num    = 14\n",
      "loss_rpn1   = 6.530281\n",
      "loss_rpn2   = 0.129721\n",
      "loss_class1 = 1.704907\n",
      "loss_class2 = 0.455276\n",
      "loss_class3 = 0.687500\n",
      "iter_num    = 15\n",
      "loss_rpn1   = 5.797787\n",
      "loss_rpn2   = 0.138682\n",
      "loss_class1 = 1.304811\n",
      "loss_class2 = 0.412119\n",
      "loss_class3 = 0.843750\n",
      "iter_num    = 16\n",
      "loss_rpn1   = 9.079034\n",
      "loss_rpn2   = 0.292657\n",
      "loss_class1 = 2.427951\n",
      "loss_class2 = 0.416620\n",
      "loss_class3 = 0.500000\n",
      "iter_num    = 17\n",
      "loss_rpn1   = 4.129132\n",
      "loss_rpn2   = 0.134270\n",
      "loss_class1 = 1.339239\n",
      "loss_class2 = 0.516529\n",
      "loss_class3 = 0.781250\n",
      "iter_num    = 18\n",
      "loss_rpn1   = 8.521625\n",
      "loss_rpn2   = 0.218272\n",
      "loss_class1 = 1.220131\n",
      "loss_class2 = 0.475668\n",
      "loss_class3 = 0.875000\n",
      "iter_num    = 19\n",
      "loss_rpn1   = 4.678265\n",
      "loss_rpn2   = 0.142667\n",
      "loss_class1 = 1.833099\n",
      "loss_class2 = 0.527198\n",
      "loss_class3 = 0.718750\n",
      "iter_num    = 20\n",
      "loss_rpn1   = 7.805375\n",
      "loss_rpn2   = 0.130886\n",
      "loss_class1 = 1.802528\n",
      "loss_class2 = 0.505087\n",
      "loss_class3 = 0.656250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-27ceae8a94b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                         \u001b[0mloss_rpn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_rpn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                         \u001b[0mP_rpn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_rpn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                         \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroi_helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn_to_roi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP_rpn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP_rpn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_dim_ordering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_regr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlap_thresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_boxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1943\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1944\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1945\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1946\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1947\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Starting training')\n",
    "\n",
    "vis = True\n",
    "\n",
    "for epoch_num in range(num_epochs):\n",
    "\n",
    "\t#progbar = generic_utils.Progbar(epoch_length)\n",
    "\tprint('Epoch {}/{}'.format(epoch_num + 1, num_epochs))\n",
    "\n",
    "\twhile True:\n",
    "\t\ttry:\n",
    "\n",
    "\t\t\tif len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n",
    "\t\t\t\tmean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
    "\t\t\t\trpn_accuracy_rpn_monitor = []\n",
    "\t\t\t\tprint('Average number of overlapping bounding boxes from RPN = {} for {} previous iterations'.format(mean_overlapping_bboxes, epoch_length))\n",
    "\t\t\t\tif mean_overlapping_bboxes == 0:\n",
    "\t\t\t\t\tprint('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n",
    "\n",
    "\t\t\tX, Y, img_data = next(data_gen_train)\n",
    "\n",
    "\t\t\tloss_rpn = model_rpn.train_on_batch(X, Y)\n",
    "\n",
    "\t\t\tP_rpn = model_rpn.predict_on_batch(X)\n",
    "\n",
    "\t\t\tR = roi_helpers.rpn_to_roi(P_rpn[0], P_rpn[1], C, K.image_dim_ordering(), use_regr=True, overlap_thresh=0.7, max_boxes=300)\n",
    "\t\t\t# note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
    "\t\t\tX2, Y1, Y2, IouS = roi_helpers.calc_iou(R, img_data, C, class_mapping)\n",
    "\n",
    "\t\t\tif X2 is None:\n",
    "\t\t\t\trpn_accuracy_rpn_monitor.append(0)\n",
    "\t\t\t\trpn_accuracy_for_epoch.append(0)\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tneg_samples = np.where(Y1[0, :, -1] == 1)\n",
    "\t\t\tpos_samples = np.where(Y1[0, :, -1] == 0)\n",
    "\n",
    "\t\t\tif len(neg_samples) > 0:\n",
    "\t\t\t\tneg_samples = neg_samples[0]\n",
    "\t\t\telse:\n",
    "\t\t\t\tneg_samples = []\n",
    "\n",
    "\t\t\tif len(pos_samples) > 0:\n",
    "\t\t\t\tpos_samples = pos_samples[0]\n",
    "\t\t\telse:\n",
    "\t\t\t\tpos_samples = []\n",
    "\t\t\t\n",
    "\t\t\trpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
    "\t\t\trpn_accuracy_for_epoch.append((len(pos_samples)))\n",
    "\n",
    "\t\t\tif C.num_rois > 1:\n",
    "\t\t\t\tif len(pos_samples) < C.num_rois//2:\n",
    "\t\t\t\t\tselected_pos_samples = pos_samples.tolist()\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tselected_pos_samples = np.random.choice(pos_samples, C.num_rois//2, replace=False).tolist()\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tselected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tselected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
    "\n",
    "\t\t\t\tsel_samples = selected_pos_samples + selected_neg_samples\n",
    "\t\t\telse:\n",
    "\t\t\t\t# in the extreme case where num_rois = 1, we pick a random pos or neg sample\n",
    "\t\t\t\tselected_pos_samples = pos_samples.tolist()\n",
    "\t\t\t\tselected_neg_samples = neg_samples.tolist()\n",
    "\t\t\t\tif np.random.randint(0, 2):\n",
    "\t\t\t\t\tsel_samples = random.choice(neg_samples)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tsel_samples = random.choice(pos_samples)\n",
    "\n",
    "\t\t\tloss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
    "\n",
    "\t\t\tlosses[iter_num, 0] = loss_rpn[1]\n",
    "\t\t\tlosses[iter_num, 1] = loss_rpn[2]\n",
    "\n",
    "\t\t\tlosses[iter_num, 2] = loss_class[1]\n",
    "\t\t\tlosses[iter_num, 3] = loss_class[2]\n",
    "\t\t\tlosses[iter_num, 4] = loss_class[3]\n",
    "            \n",
    "\t\t\tprint(\"iter_num    = %d\" % iter_num)\n",
    "\t\t\tprint(\"loss_rpn1   = %f\" % loss_rpn[1])\n",
    "\t\t\tprint(\"loss_rpn2   = %f\" % loss_rpn[2])\n",
    "\t\t\tprint(\"loss_class1 = %f\" % loss_class[1])\n",
    "\t\t\tprint(\"loss_class2 = %f\" % loss_class[2])\n",
    "\t\t\tprint(\"loss_class3 = %f\" % loss_class[3])\n",
    "\n",
    "\t\t\titer_num += 1\n",
    "\n",
    "\t\t\t#progbar.update(iter_num, [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
    "\t\t\t\t\t\t\t\t\t  #('detector_cls', np.mean(losses[:iter_num, 2])), ('detector_regr', np.mean(losses[:iter_num, 3]))])\n",
    "\n",
    "\t\t\tif iter_num == epoch_length:\n",
    "\t\t\t\tloss_rpn_cls = np.mean(losses[:, 0])\n",
    "\t\t\t\tloss_rpn_regr = np.mean(losses[:, 1])\n",
    "\t\t\t\tloss_class_cls = np.mean(losses[:, 2])\n",
    "\t\t\t\tloss_class_regr = np.mean(losses[:, 3])\n",
    "\t\t\t\tclass_acc = np.mean(losses[:, 4])\n",
    "\n",
    "\t\t\t\tmean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
    "\t\t\t\trpn_accuracy_for_epoch = []\n",
    "\n",
    "\t\t\t\tif C.verbose:\n",
    "\t\t\t\t\tprint('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
    "\t\t\t\t\tprint('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
    "\t\t\t\t\tprint('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
    "\t\t\t\t\tprint('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
    "\t\t\t\t\tprint('Loss Detector classifier: {}'.format(loss_class_cls))\n",
    "\t\t\t\t\tprint('Loss Detector regression: {}'.format(loss_class_regr))\n",
    "\t\t\t\t\tprint('Elapsed time: {}'.format(time.time() - start_time))\n",
    "\n",
    "\t\t\t\tcurr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
    "\t\t\t\titer_num = 0\n",
    "\t\t\t\tstart_time = time.time()\n",
    "\n",
    "\t\t\t\tif curr_loss < best_loss:\n",
    "\t\t\t\t\tif C.verbose:\n",
    "\t\t\t\t\t\tprint('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n",
    "\t\t\t\t\tbest_loss = curr_loss\n",
    "\t\t\t\t\tmodel_all.save_weights(C.model_path)\n",
    "\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint('Exception: {}'.format(e))\n",
    "\t\t\tcontinue\n",
    "\n",
    "print('Training complete, exiting.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
